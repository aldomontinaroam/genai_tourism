"#",Jurisdiction,Kind,Display Key,Lens ID,Publication Date,Publication Year,Application Number,Application Date,Priority Numbers,Earliest Priority Date,Title,Abstract,Applicants,Inventors,Owners,URL,Document Type,Has Full Text,Cites Patent Count,Cited by Patent Count,Simple Family Size,Extended Family Size,Sequence Count,CPC Classifications,IPCR Classifications,US Classifications,NPL Citation Count,NPL Resolved Citation Count,NPL Resolved Lens ID(s),NPL Resolved External ID(s),NPL Citations,Legal Status
1,EP,B1,EP 3857543 B1,160-688-684-972-038,2024-04-24,2024,EP 19865011 A,2019-09-24,US 201816146924 A;;US 2019/0052648 W,2018-09-28,CONVERSATIONAL AGENT PIPELINE TRAINED ON SYNTHETIC DATA,,IBM,AREL ITAMAR;;LOOKS JOSHUA BENJAMIN;;ZIAEI ALI;;LEFKOWITZ MICHAEL,INTERNATIONAL BUSINESS MACHINES CORPORATION (2022-01-12),https://lens.org/160-688-684-972-038,Granted Patent,yes,4,0,9,9,0,G10L13/00;;G06N3/006;;G06N20/20;;G10L15/063;;G10L2015/025;;G10L15/193;;G06F40/56;;G06F40/237;;G10L15/1822;;G06N5/01;;G06N3/047;;G06N7/01;;G06N3/045;;G06N3/044;;G10L15/063;;G10L15/02;;G10L2015/025;;G10L15/193;;G10L15/16;;G10L15/1815;;G06N20/00;;G10L13/00;;G06N3/006;;G06N20/20;;G06F40/56;;G06F40/237;;G06N3/044;;G06N3/045;;G06N3/047;;G06N5/01;;G06N7/01,G10L15/06;;G06F40/237;;G06F40/56;;G06N3/006;;G06N3/044;;G06N3/045;;G06N3/047;;G06N5/01;;G06N7/01;;G06N20/20;;G06N99/00;;G10L13/00;;G10L15/02;;G10L15/18;;G10L15/193,,1,0,,,"SUN XIAO ET AL: ""A multi-granularity data augmentation based fusion neural network model for short text sentiment analysis"", 2017 SEVENTH INTERNATIONAL CONFERENCE ON AFFECTIVE COMPUTING AND INTELLIGENT INTERACTION WORKSHOPS AND DEMOS (ACIIW), IEEE, 23 October 2017 (2017-10-23), pages 12-17, XP033309050, DOI: 10.1109/ACIIW.2017.8272616 [retrieved on 2018-01-29]",ACTIVE
2,EP,A1,EP 4358025 A1,005-397-577-893-158,2024-04-24,2024,EP 22883739 A,2022-08-17,KR 20210142133 A;;KR 2022012226 W,2021-10-22,"ELECTRONIC APPARATUS FOR REAL-TIME HUMAN DETECTION AND TRACKING SYSTEM, AND CONTROL METHOD THEREFOR","An electronic apparatus is disclosed. The electronic apparatus includes a first sensor configured to obtain a color image, a second sensor configured to obtain a depth image, a memory storing a neural network model, and a processor configured to, based on a first color image being received from the first sensor, obtain a first region of interest by inputting the first color image to the neural network model, and identify whether a distance between an object included in the first region of interest and the electronic apparatus is less than a threshold distance.",SAMSUNG ELECTRONICS CO LTD,LIM YUSUN,,https://lens.org/005-397-577-893-158,Patent Application,yes,0,0,2,4,0,G06V20/64;;G06V10/82;;G06V40/20;;G06V20/52;;G06V10/25;;G06V10/751;;G06T2207/30196;;G06T2207/10024;;G06T2207/20084;;G06T2207/10021;;G06T2207/20081;;G06T7/20;;G06T7/70;;G06T7/11;;G06T7/136;;G06T7/174;;G06T7/246;;G06T7/292;;G06T7/521;;H04N7/18;;G06T7/11;;G06T7/136;;G06T7/174;;G06T7/246;;G06T7/292;;G06T7/521;;G06T2207/10028;;G06T2207/30232;;G06V10/25;;H04N7/18;;G06T7/70;;G06T7/20;;G06T7/50;;G06T2207/30196;;G06V10/761;;G06V10/82;;G06T2207/10024;;G06V10/25,G06T7/174;;G06T7/11;;G06T7/136;;G06T7/246;;G06T7/292;;G06T7/521;;G06V10/25;;H04N7/18,,0,0,,,,PENDING
3,EP,A1,EP 4354887 A1,187-902-613-761-844,2024-04-17,2024,EP 21945256 A,2021-06-07,KR 2021007064 W,2021-06-07,"ARTIFICIAL INTELLIGENCE DEVICE, AND METHOD FOR OPERATING ARTIFICIAL INTELLIGENCE DEVICE","The present disclosure provides an artificial intelligence device comprising: a communication unit for communicating with the outside; an input/output unit for receiving a signal from a user and outputting a process result; and a control unit. The control unit: outputs a conversational interface for conversation with the user when the user accesses a video editing system; receives, through the conversational interface, a video uploaded by the user; outputs, through the conversational interface, a conversation for editing the video; extracts, from the conversation, a keyword for editing the video; and edits the video on the basis of the extracted keyword.",LG ELECTRONICS INC,KIM YEJIN;;OH JINSOO;;YOO SUNGEUN;;LEE JUNWOO,,https://lens.org/187-902-613-761-844,Patent Application,yes,0,0,3,3,0,H04N21/47205;;H04N21/4666;;H04N21/47205;;H04N21/854;;H04N21/4312;;H04N21/2743,H04N21/472;;H04N21/2743;;H04N21/431;;H04N21/482;;H04N21/854,,0,0,,,,PENDING
4,EP,B1,EP 3676831 B1,152-247-417-202-991,2024-04-17,2024,EP 19702760 A,2019-01-11,US 201815884907 A;;US 2019/0013239 W,2018-01-31,NATURAL LANGUAGE USER INPUT PROCESSING RESTRICTION,,AMAZON TECH INC,BAO YU,,https://lens.org/152-247-417-202-991,Granted Patent,yes,6,0,5,5,0,G10L15/18;;G10L15/22;;G06F21/31;;G06F21/629;;G06F40/30;;G06F3/167;;G10L15/19;;H04L12/2829;;G10L15/18;;G06F21/629;;G06F21/31;;G10L15/22;;G06F40/30;;G10L15/26;;G10L17/00,G10L15/22;;G06F21/31;;G06F21/62;;G10L15/18,,0,0,,,,ACTIVE
5,EP,A2,EP 4349250 A2,134-180-602-849-248,2024-04-10,2024,EP 24159813 A,2018-12-21,US 201762610013 P;;EP 18833244 A;;EP 2018086764 W,2017-12-22,"APPARATUS, SYSTEM, AND METHOD FOR MOTION SENSING","The present invention discloses a processor-readable medium, having stored thereon processor-executable instructions which, when executed by a processor of an interactive audio device, cause the processor to detect physiological movement of a user, the processor-executable instructions comprising: instructions to control producing, via a transceiver of a radio frequency sensor coupled to the interactive audio device, a radio frequency (RF) signal in a vicinity of the interactive audio device; instructions to control sensing, via the transceiver of the radio frequency sensor coupled to the interactive audio device, a reflected radio frequency (RF) signal from the vicinity; instructions to derive a physiological movement signal with at least a portion of the sensed reflected RF signal and a signal representative of at least a portion of the RF signal; instructions to generate an output based on an evaluation of at least a portion of the derived physiological movement signal; and wherein the generated output comprises an interactive query and response presentation, wherein the generated interactive query and response presentation is effected by way of a speaker, and further comprising the processor-executable instructions to evaluate, via a microphone coupled to the interactive audio device, a sensed audible verbal communication; and wherein the instructions to generate the output are configured to generate the output in response to the sensed audible verbal communication.",RESMED SENSOR TECH LTD,The designation of the inventor has not yet been filed,,https://lens.org/134-180-602-849-248,Patent Application,yes,23,0,13,13,0,A61B5/0053;;A61B5/024;;A61B5/1113;;A61B5/113;;A61B5/4806;;A61B5/4818;;A61B5/6898;;A61B5/7228;;A61B5/749;;A61B8/02;;G06F21/32;;G08B21/0423;;G08B21/0469;;G08B21/06;;G08B21/22;;G08B27/005;;G08B5/222;;G10L25/51;;G10L25/78;;A61M2021/0083;;A61M21/00;;A61B5/0053;;A61B5/024;;A61B5/7228;;A61B8/02;;A61B8/0883;;A61B5/4806;;A61B5/6898;;A61B5/113;;A61B5/4806;;A61B5/4818;;A61B5/7228;;A61B5/6898;;A61B5/1113;;A61B5/113;;A61B8/0883;;A61B8/02;;A61B5/749;;A61M21/00;;A61M2021/0083;;G06F21/32;;G08B5/222;;G08B21/0423;;G08B21/0469;;G08B21/06;;G08B21/22;;G08B27/005;;G10L25/51;;G10L25/78,A61B5/00,,0,0,,,,PENDING
6,EP,A1,EP 4345830 A1,139-185-037-582-265,2024-04-03,2024,EP 23200125 A,2023-09-27,US 202217935945 A;;EP 22465554 A,2022-09-28,AUTOMATIC PLANNING AND GUIDANCE OF LIVER TUMOR THERMAL ABLATION USING AI AGENTS TRAINED WITH DEEP REINFORCEMENT LEARNING,"Systems and methods for determining an optimal position of one or more ablation electrodes are provided. A current state of an environment is defined based on a mask of one or more anatomical objects and one or more current positions of one or more ablation electrodes. The one or more anatomical objects comprise one or more tumors. For each particular AI (artificial intelligence) agent of one or more AI agents, one or more actions for updating the one or more current positions of a respective ablation electrode of the one or more ablation electrodes in the environment are determined based on the current state using the particular AI agent. A next state of the environment is defined based on the mask and the one or more updated positions of the respective ablation electrode. The steps of determining the one or more actions and defining the next state are repeated for a plurality of iterations using 1) the next state as the current state and 2) the one or more updated positions as the one or more current positions to determine one or more final positions of the respective ablation electrode for performing a thermal ablation on the one or more tumors. The one or more final positions of each respective ablation electrode are output.",SIEMENS HEALTHINEERS AG,CHAITANYA KRISHNA;;AUDIGIER CHLOÉ;;PAILLARD JOSEPH;;BALASCUTA LAURA ELENA;;GHESU FLORIN-CRISTIAN;;COMANICIU DORIN;;MANSI TOMMASO,,https://lens.org/139-185-037-582-265,Patent Application,yes,0,0,1,3,0,G16H20/40;;G16H40/63;;A61B34/10;;A61B2034/105;;A61B2034/107;;A61B2018/00577;;A61B2018/00642;;A61B2018/00529;;G06N3/045;;G06N3/092;;G06N3/084;;G06N3/0464,G16H20/40;;A61B34/10;;G16H40/63,,2,0,,,"CHAITANYA KRISHNA ET AL: ""Automatic planning of liver tumor thermal ablation using deep reinforcement learning"", 28 February 2022 (2022-02-28), pages 1 - 12, XP093094005, Retrieved from the Internet <URL:https://openreview.net/pdf?id=ehsvFoQaz-W> [retrieved on 20231023];;CHAITANYA KRISHNA ET AL: ""Automatic planning of liver tumor thermal ablation using deep reinforcement learning | OpenReview"", OPENREVIEW.NET FORUM, 28 February 2022 (2022-02-28), XP093124563, Retrieved from the Internet <URL:https://openreview.net/forum?id=ehsvFoQaz-W> [retrieved on 20240126]",PENDING
7,EP,A1,EP 4345743 A1,059-444-321-222-842,2024-04-03,2024,EP 23197132 A,2023-09-13,US 202217932311 A,2022-09-15,MEDICAL IMAGING DATA NORMALIZATION FOR ANIMAL STUDIES,"Systems and methods that normalize medical imaging data (160) between different species and breeds of animals in order to allow for cross-species and crossbreed usage of machine trained models (195). Image data of a non-human subject is acquired, registered using a standardized model (190), and segmented using a machine trained model.",SIEMENS HEALTHINEERS AG,GEIGER BERNHARD,,https://lens.org/059-444-321-222-842,Patent Application,yes,1,0,2,2,0,G06T7/11;;G06T7/0014;;G06T2207/20081;;G06T2207/20084;;G06T2207/20128;;G06T7/11;;G06T7/33;;G06T7/35;;G06V10/243;;G06V2201/031;;G06V10/82;;G06V10/774;;G06V10/764;;A61D99/00;;A61N5/1039,G06T7/00;;G06T7/11,,2,2,133-309-586-024-358;;011-122-458-332-926,18287264;;10.2967/jnumed.107.046722;;pmc8450455;;10.3389/fvets.2021.721612;;34552975,"PADILLA LAURA ET AL: ""Canine Anatomic Phantom for Preclinical Dosimetry in Internal Emitter Therapy"", THE JOURNAL OF NUCLEAR MEDICINE, vol. 49, no. 3, 1 March 2008 (2008-03-01), US, pages 446 - 452, XP093132715, ISSN: 0161-5505, Retrieved from the Internet <URL:https://jnm.snmjournals.org/content/jnumed/49/3/446.full.pdf> DOI: 10.2967/jnumed.107.046722;;PARK JEONGSU ET AL: ""Deep-Learning-Based Automatic Segmentation of Head and Neck Organs for Radiation Therapy in Dogs"", FRONTIERS IN VETERINARY SCIENCE, vol. 8, 6 September 2021 (2021-09-06), Lausanne, XP093132752, ISSN: 2297-1769, Retrieved from the Internet <URL:https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8450455/pdf/fvets-08-721612.pdf> DOI: 10.3389/fvets.2021.721612",PENDING
8,EP,A2,EP 4343660 A2,023-615-018-518-015,2024-03-27,2024,EP 24156257 A,2019-05-07,US 201862669182 P;;EP 19798921 A;;US 2019/0031185 W,2018-05-09,METHODS AND SYSTEMS FOR GENERATING AND PROVIDING PROGRAM GUIDES AND CONTENT,"Systems and methods for identifying, assembling, and transmitting content are described in the illustrative context of electronic program guides and program channels. Data is received over a network from a first user terminal that enables identification of the first user. Program information for a digital program is accessed. A determination is made as to how many interstitials are to be presented during a playback of the digital program. A prediction model is selected and executed to generate predictions of user responses to one or more placements of program interstitials. The user response predictions are used to determine positioning of interstitials with respect to the program. The interstitials are enabled to be displayed on the first user terminal in accordance with the determined positioning.",PLUTO INC,HOU CHAN V,,https://lens.org/023-615-018-518-015,Patent Application,yes,1,0,11,20,0,H04N21/2407;;H04N21/251;;H04N21/2668;;H04N21/25866;;H04N21/4722;;H04N21/4316;;G06Q30/0241;;G06N3/08;;G06N3/126;;G06N5/022;;G06F21/316;;G06N3/047;;G06N3/045;;H04N21/251;;H04N21/2668;;H04N21/2407,G06Q30/0241,,0,0,,,,PENDING
9,EP,A2,EP 4339905 A2,086-561-249-616-370,2024-03-20,2024,EP 24154963 A,2019-07-17,US 201862699669 P;;EP 19746415 A;;US 2019/0042225 W,2018-07-17,REGRESSION-BASED LINE DETECTION FOR AUTONOMOUS DRIVING MACHINES,"In various examples, systems and methods are disclosed that preserve rich spatial information from an input resolution of a machine learning model to regress on lines in an input image. The machine learning model may be trained to predict, in deployment, distances for each pixel of the input image at an input resolution to a line pixel determined to correspond to a line in the input image. The machine learning model may further be trained to predict angles and label classes of the line. An embedding algorithm may be used to train the machine learning model to predict clusters of line pixels that each correspond to a respective line in the input image. In deployment, the predictions of the machine learning model may be used as an aid for understanding the surrounding environment - e.g., for updating a world model - in a variety of autonomous machine applications.",NVIDIA CORP,PARK MINWOO;;LIN XIAOLIN;;SEO HAE-JONG;;NISTER DAVID;;CVIJETIC NEDA,,https://lens.org/086-561-249-616-370,Patent Application,yes,1,0,13,13,0,G05D1/0077;;G05D1/0088;;G05D1/0246;;G06N3/08;;G06V20/588;;G06V10/955;;G06V10/48;;G06V10/457;;G06V10/82;;G06V10/776;;G06V10/764;;G06N3/045;;G06V10/766;;G05D1/0088;;G05D1/0077;;G06N3/0418;;G06V20/588;;G06F18/2155;;G06F18/23;;G06F18/2411;;G06V10/764;;G06V10/776;;G06V10/82;;G06V10/457;;G06V10/48;;G06V10/955;;G06V10/751;;G05D1/228,G06V20/56,,0,0,,,,PENDING
10,EP,B1,EP 3791599 B1,066-701-463-770-076,2024-03-20,2024,EP 19798921 A,2019-05-07,US 201862669182 P;;US 2019/0031185 W,2018-05-09,METHODS AND SYSTEMS FOR GENERATING AND PROVIDING PROGRAM GUIDES AND CONTENT,,PLUTO INC,HOU CHAN V,PLUTO INC. (2022-11-02),https://lens.org/066-701-463-770-076,Granted Patent,yes,8,0,11,20,0,H04N21/2407;;H04N21/251;;H04N21/2668;;H04N21/25866;;H04N21/4722;;H04N21/4316;;G06Q30/0241;;G06N3/08;;G06N3/126;;G06N5/022;;G06F21/316;;G06N3/047;;G06N3/045;;H04N21/251;;H04N21/2668;;H04N21/2407,H04N21/24;;G06F21/31;;G06N3/08;;G06Q30/0241;;H04N21/25;;H04N21/258;;H04N21/2668;;H04N21/431;;H04N21/4722,,0,0,,,,ACTIVE
11,EP,B1,EP 3906508 B1,080-191-499-815-272,2024-03-13,2024,EP 19907690 A,2019-04-23,US 201862786941 P;;US 2019/0028687 W,2018-12-31,SECURING SYSTEMS EMPLOYING ARTIFICIAL INTELLIGENCE,,INTEL CORP,POGORELIK OLEG;;NAYSHTUT ALEX;;BEN-SHALOM OMER;;KLIMOV DENIS;;KELLERMANN RAIZY;;BARNHART-MAGEN GUY;;SUKHOMLINOV VADIM,,https://lens.org/080-191-499-815-272,Granted Patent,yes,3,0,10,10,0,G06N3/04;;G06N20/00;;G06F21/554;;G06N7/01;;G06N3/094;;G06N3/084;;G06N3/04;;G06N20/00;;G06N20/00;;G06F21/554;;G06F2221/034;;G06N5/04,G06N20/00;;G06F21/55;;G06N3/04;;G06N7/00,,5,0,,,"MIKA JUUTI ET AL: ""PRADA: Protecting against DNN Model Stealing Attacks"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 7 May 2018 (2018-05-07), XP081425461,;;TAESUNG LEE ET AL: ""Defending Against Model Stealing Attacks Using Deceptive Perturbations"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 31 May 2018 (2018-05-31), XP081076040,;;Derks G.A.F: ""Hardening Neural Network Models Against Stealing"", , 20 November 2018 (2018-11-20), XP055778264, Retrieved from the Internet: URL:https://pure.tue.nl/ws/portalfiles/por tal/126148852/0850067_Derks_G.A.F._thesis. pdf [retrieved on 2021-02-22];;MINSUK KAHNG et al.: ""GAN Lab: Understanding Complex Deep Generative Models using Interactive Visual Experimentation"", arXiv:1809.01587v1, 5 September 2018 (2018-09-05), XP081187569, Retrieved from the Internet: URL:<https://arxiv.org/abs/1809.01587v1> [retrieved on 2019-09-02];;NICOLAS PAPERNOT et al.: ""Practical Black-Box Attacks against Machine Learning"", arXiv:1602.02697v4 , 19 March 2017 (2017-03-19), XP080682288, Retrieved from the Internet: URL:<https://arxiv.org/abs/1602.02697v4> [retrieved on 2019-09-02]",ACTIVE
12,EP,B1,EP 3687193 B1,074-225-888-957-43X,2024-03-06,2024,EP 19807568 A,2019-04-10,JP 2018099553 A;;JP 2019015710 W,2018-05-24,INFORMATION PROCESSING DEVICE AND INFORMATION PROCESSING METHOD,,SONY GROUP CORP,IGARASHI GO;;SUZUKI JUNYA;;NUMAOKA CHISATO,SONY GROUP CORPORATION (2021-07-28),https://lens.org/074-225-888-957-43X,Granted Patent,yes,6,0,13,13,0,G10K11/178;;H04R1/1016;;H04S7/304;;H04S3/004;;H04S2400/11;;G09B21/006;;H04S1/002;;G01S15/06;;H04R1/1016;;H04R2420/07,H04S1/00;;G09B21/00;;H04R1/10;;H04S3/00;;H04S7/00,,0,0,,,,ACTIVE
13,EP,A1,EP 4332885 A1,160-356-897-894-992,2024-03-06,2024,EP 22795545 A,2022-04-07,JP 2021075343 A;;JP 2022017279 W,2021-04-27,"ELECTRONIC DEVICE, CONTROL METHOD FOR ELECTRONIC DEVICE, AND PROGRAM","An electronic device includes an encoder and a decoder. The encoder is configured to estimate an unknown value on the basis of first biological information including a line of sight of a subject extracted from an image of the subject, subject's attribute information representing an attribute of the subject, and subject's internal state information representing an internal state of the subject. The decoder is configured to estimate second biological information including the line of sight of the subject on the basis of the unknown value, the subject's attribute information, and the subject's internal state information. The electronic device adjusts parameters of the encoder and the decoder on the basis of reproducibility of the first biological information from the second biological information.",KYOCERA CORP,MIYAZAKI JUNGO;;NISHII YUSUKE,,https://lens.org/160-356-897-894-992,Patent Application,yes,0,0,4,4,0,G06T7/00;;A61B3/113,G06T7/00;;A61B3/113,,0,0,,,,PENDING
14,EP,A1,EP 4332886 A1,166-330-046-803-32X,2024-03-06,2024,EP 22795546 A,2022-04-07,JP 2021075345 A;;JP 2022017280 W,2021-04-27,"ELECTRONIC DEVICE, METHOD FOR CONTROLLING ELECTRONIC DEVICE, AND PROGRAM","An electronic device includes an encoder and a decoder. The encoder is configured to estimate an unknown value on the basis of first biological information including a line of sight of a subject extracted from an image of the subject, subject's environmental information representing an environment of the subject, and subject's internal state information representing an internal state of the subject. The decoder is configured to estimate second biological information including the line of sight of the subject on the basis of the unknown value, the subject's environmental information, and the subject's internal state information. The electronic device adjusts parameters of the encoder and the decoder on the basis of reproducibility of the first biological information from the second biological information.",KYOCERA CORP,NISHII YUSUKE;;MIYAZAKI JUNGO,,https://lens.org/166-330-046-803-32X,Patent Application,yes,0,0,4,4,0,G06T7/00;;A61B3/113,G06T7/00;;A61B3/113,,0,0,,,,PENDING
15,EP,B1,EP 3824408 B1,082-020-829-129-23X,2024-03-06,2024,EP 19746415 A,2019-07-17,US 2019/0042225 W;;US 201862699669 P,2018-07-17,REGRESSION-BASED LINE DETECTION FOR AUTONOMOUS DRIVING MACHINES,,NVIDIA CORP,PARK MINWOO;;LIN XIAOLIN;;SEO HAE-JONG;;NISTER DAVID;;CVIJETIC NEDA,,https://lens.org/082-020-829-129-23X,Granted Patent,yes,1,0,13,13,0,G05D1/0077;;G05D1/0088;;G05D1/0246;;G06N3/08;;G06V20/588;;G06V10/955;;G06V10/48;;G06V10/457;;G06V10/82;;G06V10/776;;G06V10/764;;G06N3/045;;G06V10/766;;G05D1/0088;;G05D1/0077;;G06N3/0418;;G06V20/588;;G06F18/2155;;G06F18/23;;G06F18/2411;;G06V10/764;;G06V10/776;;G06V10/82;;G06V10/457;;G06V10/48;;G06V10/955;;G06V10/751;;G05D1/228,G06V10/44;;G06V10/48;;G06V10/764;;G06V10/766;;G06V10/82;;G06V20/56,,2,0,,,"Iasonas Kokkinos: ""PUSHING THE BOUNDARIES OF BOUNDARY DETEC- TION USING DEEP LEARNING"", , 23 November 2015 (2015-11-23), XP055269419, http://arxiv.org/abs/1511.07386 Retrieved from the Internet: URL:http://arxiv.org/pdf/1511.07386v2.pdf [retrieved on 2016-04-28];;CHENG GUANGLIANG ET AL: ""Automatic Road Detection and Centerline Extraction via Cascaded End-to-End Convolutional Neural Network"", IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, IEEE SERVICE CENTER, PISCATAWAY, NJ, US, vol. 55, no. 6, 1 June 2017 (2017-06-01), pages 3322-3337, XP011650403, ISSN: 0196-2892, DOI: 10.1109/TGRS.2017.2669341 [retrieved on 2017-05-19]",ACTIVE
16,EP,B1,EP 4041721 B1,100-001-210-678-558,2024-03-06,2024,EP 20789924 A,2020-10-08,EP 19202288 A;;EP 2020078252 W,2019-10-09,NOVEL HETEROARYL-TRIAZOLE COMPOUNDS AS PESTICIDES,,BAYER AG,JESCHKE PETER;;SCHWARZ HANS-GEORG;;ARLT ALEXANDER;;FÜSSLEIN MARTIN;;CANCHO GRANDE YOLANDA;;TELSER JOACHIM;;PAZENOK SERGII;;LÖSEL PETER;;LINKA MARC;;EBBINGHAUS-KINTSCHER ULRICH;;DAMIJONAITIS ARUNAS JONAS;;HEISLER IRING;;TURBERG ANDREAS,,https://lens.org/100-001-210-678-558,Granted Patent,yes,2,0,15,15,0,C07D401/04;;C07D401/14;;C07D403/04;;A01N43/653;;C07D403/04;;C07D401/04;;C07D401/14;;A01N43/653;;A61K31/506;;A61K31/4439;;A61P33/14;;A01P7/04;;A01P7/02;;A01N25/06;;A01N43/653;;C07D401/04;;C07D401/14;;C07D403/04,C07D401/04;;A01N43/653;;A01P7/02;;A01P7/04;;A61K31/44;;A61K31/506;;A61P33/14;;C07D401/14;;C07D403/04,,0,0,,,,ACTIVE
17,EP,B1,EP 3727135 B1,035-079-178-540-122,2024-02-28,2024,EP 18833244 A,2018-12-21,US 201762610013 P;;EP 2018086764 W,2017-12-22,"APPARATUS, SYSTEM, AND METHOD FOR MOTION SENSING",,RESMED SENSOR TECH LTD,SHOULDICE REDMOND;;MCMAHON STEPHEN;;WREN MICHAEL,RESMED SENSOR TECHNOLOGIES LIMITED (2024-01-31),https://lens.org/035-079-178-540-122,Granted Patent,yes,3,0,13,13,0,A61B5/0053;;A61B5/024;;A61B5/1113;;A61B5/113;;A61B5/4806;;A61B5/4818;;A61B5/6898;;A61B5/7228;;A61B5/749;;A61B8/02;;G06F21/32;;G08B21/0423;;G08B21/0469;;G08B21/06;;G08B21/22;;G08B27/005;;G08B5/222;;G10L25/51;;G10L25/78;;A61M2021/0083;;A61M21/00;;A61B5/0053;;A61B5/024;;A61B5/7228;;A61B8/02;;A61B8/0883;;A61B5/4806;;A61B5/6898;;A61B5/113;;A61B5/4806;;A61B5/4818;;A61B5/7228;;A61B5/6898;;A61B5/1113;;A61B5/113;;A61B8/0883;;A61B8/02;;A61B5/749;;A61M21/00;;A61M2021/0083;;G06F21/32;;G08B5/222;;G08B21/0423;;G08B21/0469;;G08B21/06;;G08B21/22;;G08B27/005;;G10L25/51;;G10L25/78,A61B5/00,,0,0,,,,ACTIVE
18,EP,B1,EP 3647936 B1,145-569-399-730-683,2024-02-21,2024,EP 19206720 A,2019-11-01,KR 20180132717 A;;KR 20190129837 A,2018-11-01,ELECTRONIC APPARATUS AND CONTROL METHOD THEREOF,,SAMSUNG ELECTRONICS CO LTD,LEE YEONHO;;LEE KYENGHUN;;JANG SAEBOM;;JEON SILAS,,https://lens.org/145-569-399-730-683,Granted Patent,yes,3,0,5,9,0,G06F3/167;;G10L17/00;;G06N5/022;;G06N5/041;;G06N3/088;;G06N5/027;;G06N20/00;;G06N3/006;;G06N3/047;;G06N7/01;;G06N3/044;;G06N3/045;;G10L15/22;;G10L15/30;;G10L2015/227,G06F3/16;;G06N3/006;;G06N3/088;;G06N5/02;;G06N5/022;;G06N5/04;;G10L15/22;;G10L17/00,,0,0,,,,ACTIVE
19,EP,A1,EP 4318974 A1,035-561-589-489-443,2024-02-07,2024,EP 23189807 A,2023-08-04,US 202263395456 P,2022-08-05,RANDOM ACCESS IN NON-TERRESTRIAL NETWORK,"One or more wireless devices may determine whether to initiate repetition of a transmission, based on characteristics of communications link, such as in a non-terrestrial network (NTN). Characteristics of the communications link may comprise, for example, distance/length, propagation delay, elevation angle, and/or reference signal received power (RSRP). Different random access resources may be used to indicate whether repetition is initiated.",COMCAST CABLE COMM LLC,DASHTAKI MOHAMMAD GHADIR KHOSHKHOLGH;;CIRIK ALI CAGATAY;;DINAN ESMAEL HEJAZI;;ZHOU HUA;;PRASAD GAUTHAM,,https://lens.org/035-561-589-489-443,Patent Application,yes,5,0,3,3,0,H04W56/0045;;H04W74/0833;;H04B7/18513;;H04W74/006;;H04L1/08;;H04L1/189;;H04L1/1874;;H04L1/1671;;H04L1/0026;;H04L1/0025;;H04L1/0028;;H04B17/328;;H04B7/18513;;H04W74/0833,H04B7/185,,0,0,,,,PENDING
20,EP,B1,EP 3727145 B1,134-597-349-998-189,2024-01-24,2024,EP 18833058 A,2018-12-21,US 201762609998 P;;EP 2018086765 W,2017-12-22,"APPARATUS, SYSTEM, AND METHOD FOR PHYSIOLOGICAL SENSING IN VEHICLES",,RESMED SENSOR TECH LTD,SHOULDICE REDMOND;;MCMAHON STEPHEN,RESMED SENSOR TECHNOLOGIES LIMITED (2023-12-27),https://lens.org/134-597-349-998-189,Granted Patent,yes,6,0,11,11,0,A61B5/6893;;A61B5/7267;;A61B5/02416;;A61B5/05;;A61B5/0816;;A61B5/1102;;A61B5/113;;A61B5/117;;A61B5/18;;B60W40/08;;A61M2021/0027;;A61B5/163;;A61B5/0205;;A61B2503/22;;A61M21/02;;A61M2021/0083;;A61M2205/3375;;A61M2230/63;;B60W2040/0872;;B60W40/00;;B60W50/14;;G01C21/3407;;G05D1/0061;;G05D1/0088;;B60W40/08;;B60W50/14;;B60W60/001;;B60W60/0053;;A61B5/18;;A61B5/4809;;A61B5/0205;;A61B5/02416;;A61B5/0816;;A61B5/1102;;A61B5/113;;A61B5/6893;;A61M21/02;;G01C21/3407;;B60H1/00821;;B60W2040/0872;;B60W2050/0005;;B60W2050/0057;;B60W2420/40;;B60W2420/54;;B60W2040/0881;;B60W2540/18;;B60W2556/50;;B60W2040/0827;;B60W2050/0052;;A61M2021/0027;;A61M2021/0083;;A61B2503/22;;A61M2205/3375;;A61M2230/63;;A61B5/0205;;A61B5/0816;;A61B5/113;;A61B2562/0219;;A61M21/02;;A61M2205/3375;;A61M2230/63,A61B5/024;;A61B5/00;;A61B5/0205;;A61B5/05;;A61B5/08;;A61B5/11;;A61B5/113;;A61B5/117;;A61B5/18;;A61B8/02;;A61M21/02;;B60W40/00;;B60W40/08;;B60W50/14;;G01C21/34,,0,0,,,,ACTIVE
21,EP,A1,EP 4306041 A1,065-989-792-219-17X,2024-01-17,2024,EP 23196226 A,2016-01-06,AU 2015/900015 A;;EP 16701198 A;;IB 2016050042 W,2015-01-06,MOBILE WEARABLE MONITORING SYSTEMS,"This document describes a number of inventions comprising of one or more wearable devices (i.e. attached or applied to limbs, body, head or other body extremities but also applicable to implanted or physiologically attachable systems). These systems have a means of enabling diagnostic or prognostic monitoring applicable to monitoring relevant parameters and corresponding analysis determination and characterisation applicable to the onset or detection of events or health conditions of interest. One application relates to sleep monitoring and associate EEG sensors.",BURTON DAVID,BURTON DAVID,,https://lens.org/065-989-792-219-17X,Patent Application,yes,4,0,29,29,0,A61B5/14551;;A61B5/4806;;A61B5/4809;;A61B5/4818;;A61B5/6802;;A61B5/6803;;A61B5/681;;A61B5/16;;A61B5/72;;A61B5/112;;A61B3/16;;A61B8/06;;A61B8/02;;A61B8/4427;;A61B8/488;;A61B2560/0242;;A61B5/0002;;A61B5/0205;;A61B5/024;;A61B5/11;;A61B5/1123;;A61B5/14551;;A61B5/4806;;A61B5/6814;;A61B5/6824;;G16H40/63;;G16H40/67;;A61B5/4815;;Y02A90/10;;A61B5/291;;A61B5/398;;A61B5/389;;A61B5/369;;A61B5/4082;;G16H50/20;;A61N2/00;;A61N2005/0626;;A61N5/06;;A61B5/4806;;A61B5/4836;;A61B5/4815;;A61B5/0205;;A61B5/14551;;A61B5/4812;;A61B5/369;;A61B5/389;;A61B5/398;;A61B5/681;;A61B5/6824;;G16H50/20;;G16H40/63;;G16H40/67,A61B5/00;;A61B5/0205;;A61B5/024;;A61B5/11;;A61B5/1455;;A61B5/291;;A61B5/369;;A61B5/389;;A61B5/398;;A61N2/00,,4,4,134-554-893-575-307;;067-985-880-695-912;;044-092-241-647-41X;;076-246-304-992-916,18495500;;10.1016/j.seizure.2008.04.005;;17223384;;10.1016/j.clinph.2006.11.008;;17442009;;10.1111/j.1528-1167.2007.01073.x;;10.1177/155005940103200203;;11360721,"SANTIAGO-RODRIGUEZ E ET AL: ""Repetitive transcranial magnetic stimulation decreases the number of seizures in patients with focal neocortical epilepsy"", SEIZURE, BAILLIERE TINDALL, LONDON, GB, vol. 17, no. 8, 1 December 2008 (2008-12-01), pages 677 - 683, XP025642370, ISSN: 1059-1311, [retrieved on 20080520], DOI: 10.1016/J.SEIZURE.2008.04.005;;JOO ET AL: ""Antiepileptic effects of low-frequency repetitive transcranial magnetic stimulation by different stimulation durations and locations"", CLINICAL NEUROPHYSIOLOGY, ELSEVIER, AMSTERDAM, NL, vol. 118, no. 3, 7 February 2007 (2007-02-07), pages 702 - 708, XP005896489, ISSN: 1388-2457, DOI: 10.1016/J.CLINPH.2006.11.008;;MUSTAFA EFKAN COLPAN ET AL: ""Proportional Feedback Stimulation for Seizure Control in Rats"", EPILEPSIA, RAVEN PRESS LTD, NEW YORK , US, vol. 48, no. 8, 18 April 2007 (2007-04-18), pages 1594 - 1603, XP071209988, ISSN: 0013-9580, DOI: 10.1111/J.1528-1167.2007.01073.X;;BOSCH-BAYARD J. ET AL: ""3D Statistical Parametric Mapping of EEG Source Spectra by Means of Variable Resolution Electromagnetic Tomography (VARETA)"", CLINICAL ELECTROENCEPHALOGRAPHY, vol. 32, no. 2, 27 April 2001 (2001-04-27), US, pages 47 - 61, XP093103630, ISSN: 0009-9155, Retrieved from the Internet <URL:http://journals.sagepub.com/doi/full-xml/10.1177/155005940103200203> DOI: 10.1177/155005940103200203",PENDING
22,EP,A1,EP 4307217 A1,102-274-391-585-436,2024-01-17,2024,EP 21937741 A,2021-12-18,CN 202110423683 A;;CN 202110914815 A;;CN 2021139429 W,2021-04-20,FAULT IMAGE GENERATION METHOD AND APPARATUS,"A fault image generation method and apparatus are provided. The fault image generation method includes: obtaining a non-fault image and a first fault image, where the non-fault image records a first object that is not faulty, the first fault image records a second object that is faulty, and a type of the first object is different from a type of the second object; and migrating a fault pattern of the second object in the first fault image to the first object in the non-fault image, to obtain a second fault image, where the second fault image presents the first object in a faulty state. A part of an image of a specific type of object is replaced by using a fault pattern that records another type of object, to obtain a second fault image of the specific type of object. This improves universality and flexibility of obtaining the fault pattern, and increases diversity of fault types in the second fault image.",HUAWEI CLOUD COMPUTING TECH CO LTD,DU CHANGDE;;JIN XIN;;JIANG HUAJIE;;TU DANDAN,,https://lens.org/102-274-391-585-436,Patent Application,yes,0,0,3,4,0,G06T2207/20081;;G06T7/001;;G06T2207/20084;;G06V10/82;;G06V10/774;;G06T7/0004;;G06T2207/20081;;G06T2207/20084,G06T7/00,,0,0,,,,PENDING
23,EP,B1,EP 3951646 B1,092-872-973-970-755,2024-01-10,2024,EP 20784955 A,2020-03-18,CN 201910262855 A;;CN 2020080002 W,2019-04-02,"IMAGE RECOGNITION NETWORK MODEL TRAINING METHOD, IMAGE RECOGNITION METHOD AND DEVICE",,TENCENT TECH SHENZHEN CO LTD,GE ZHENG;;JIE ZEQUN;;WANG HAO;;LI ZHIFENG;;GONG DIHONG;;LIU WEI,TENCENT TECHNOLOGY (SHENZHEN) COMPANY LIMITED (2022-07-20),https://lens.org/092-872-973-970-755,Granted Patent,yes,2,0,7,7,0,G06V40/172;;G06F18/2415;;G06F18/214;;G06V40/172;;G06V10/82;;G06N3/084;;G06N3/088;;G06V10/774;;G06N3/047;;G06N3/045;;G06N3/088;;G06V40/172;;G06F18/214;;G06F18/2415;;G06N3/045;;G06V10/774;;G06V10/82,G06N3/084,,0,0,,,,ACTIVE
24,EP,A1,EP 4303851 A1,127-236-526-410-159,2024-01-10,2024,EP 23173537 A,2023-05-16,US 202217664187 A,2022-05-19,SYSTEM AND COMPUTER-IMPLEMENTED METHOD FOR REAL-TIME AIRCRAFT FLIGHT DELAY PREDICTION,"Examples are disclosed that related to providing flight-delay estimations of airborne flights in a real-time environment. In one example, an aircraft information message for a current aircraft flight is received. The aircraft information message has a designated format consumable by a machine learning model previously trained to assess delay predictions for aircraft flights. The aircraft information message includes one or more aircraft flight-plan parameters, one or more aircraft surveillance parameters, and one or more weather parameters for the current aircraft flight. The aircraft information message is provided as input to the machine learning model to assess a real-time delay prediction for the current aircraft flight based at least on the one or more flight-plan parameters, the one or more aircraft surveillance parameters, and the one or more weather parameters included in the aircraft information message.",BOEING CO,HERNANDEZ ANDRES MUNOZ;;MORALES MANUEL POLAINA;;JIMÉNEZ ALEJANDRO GÜEMES,,https://lens.org/127-236-526-410-159,Patent Application,yes,1,0,4,4,0,G06Q10/04;;G06N20/00;;G06F9/5027;;G08G5/00;;G06N20/00;;G08G5/0091;;G06Q10/04;;G06Q50/40;;G08G5/0013;;G08G5/0026;;G08G5/0043;;G08G5/0082;;G06N20/00;;G08G5/0013;;G08G5/003;;G08G5/0043;;G08G5/0082;;G08G5/0091,G08G5/00;;G06N20/00;;G06Q10/0833,,2,2,041-697-807-097-836;;085-386-840-379-884,10.1109/ipccc50635.2020.9391561;;10.1109/tvt.2019.2954094,"ZHANG KAI ET AL: ""Spatio-Temporal Data Mining for Aviation Delay Prediction"", 2020 IEEE 39TH INTERNATIONAL PERFORMANCE COMPUTING AND COMMUNICATIONS CONFERENCE (IPCCC), IEEE, 6 November 2020 (2020-11-06), pages 1 - 7, XP033894583, DOI: 10.1109/IPCCC50635.2020.9391561;;GUI GUAN ET AL: ""Flight Delay Prediction Based on Aviation Big Data and Machine Learning"", IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, IEEE, USA, vol. 69, no. 1, 16 November 2019 (2019-11-16), pages 140 - 150, XP011766802, ISSN: 0018-9545, [retrieved on 20200116], DOI: 10.1109/TVT.2019.2954094",PENDING
25,EP,A1,EP 4300513 A1,068-750-300-629-047,2024-01-03,2024,EP 23194971 A,2014-10-29,US 201361898052 P;;EP 14858118 A;;US 2014/0062946 W,2013-10-31,COMPUTING TECHNOLOGIES FOR DIAGNOSIS AND THERAPY OF LANGUAGE-RELATED DISORDERS,"The present disclosure relates to computing technologies for diagnosis and therapy of language-related disorders. Such technologies enable computer-generated diagnosis and computer-generated therapy delivered over a network to at least one computing device. The diagnosis and therapy are customized for each patient through a comprehensive analysis of the patient's production and reception errors, as obtained from the patient over the network, together with a set of correct responses at each phase of evaluation and therapy.
",HARUTA PAU SAN;;HARUTA CHARISSE SI FEI;;HARUTA KIERAN BING FEI,HARUTA PAU-SAN;;HARUTA CHARISSE SI-FEI;;HARUTA KIERAN BING-FEI,,https://lens.org/068-750-300-629-047,Patent Application,yes,5,0,26,26,0,G09B19/04;;A61B5/16;;G09B5/00;;G09B7/00;;G16H20/70;;G16H50/20;;G09B19/04;;A61B5/16;;G09B5/00;;G09B7/00;;G16H10/00;;G16H50/20;;G09B19/04;;A61B5/4088;;G09B5/00;;G09B7/00;;G16H20/70;;G16H50/20,G16H50/20;;A61B5/16;;G09B5/00;;G09B7/00;;G09B19/00;;G09B19/04;;G16H10/60;;G16H20/70,,0,0,,,,PENDING
26,EP,A1,EP 4300225 A1,190-722-265-222-341,2024-01-03,2024,EP 22181643 A,2022-06-28,EP 22181643 A,2022-06-28,METHOD AND SYSTEM FOR OPTIMIZING USE OF COORDINATE MEASURING DEVICES,"The invention pertains to a method (100) for optimizing simultaneous use of a multitude of coordinate measuring devices at a multitude of locations, the method comprising: obtaining job information (110) about a multitude of coordinate measuring jobs at the multitude of locations, each job involving one or more of the devices and one or more objects to be measured, the job information comprising the position of the one or more objects, a time for performing the job, required capabilities of the involved devices, and required certifications and/or calibrations for the involved devices; determining an actual position (120) and a condition (130) of each device, the condition comprising a measuring precision and a measuring speed, individual conditions of a plurality of components of the device, a maintenance status and a certification and/or calibration status; performing a job analysis (140) involving the obtained job information and the determined positions and conditions; and performing, based on a result of the analysis, an assignment optimization (150) for assigning at least a subset of the devices to the jobs, the assignment optimization including at least an optimization regarding usage and maintenance for each device, and paths between the positions of the objects to be measured and the positions of the devices.
",LEICA GEOSYSTEMS AG,STEINER MARKUS,,https://lens.org/190-722-265-222-341,Patent Application,yes,3,0,3,3,0,G01B11/005;;G06F17/10;;G05B19/41865;;G05B2219/37193;;G05B2219/32283;;G01B21/04;;G01B2210/58,G05B19/418,,0,0,,,,PENDING
27,EP,B1,EP 4136349 B1,111-553-578-999-434,2024-01-03,2024,EP 21728047 A,2021-05-21,EP 20179807 A;;EP 2021063637 W,2020-06-12,REPAIR SYSTEM AND METHOD FOR PERFORMING AT LEAST ONE REPAIR TASK IN A WIND TURBINE,,SIEMENS GAMESA RENEWABLE ENERGY GMBH & CO KG,GOLLNICK BERT,,https://lens.org/111-553-578-999-434,Granted Patent,yes,3,0,7,7,0,F03D80/50;;F05B2230/80;;Y02E10/72;;Y02P70/50;;F03D80/50;;F05B2230/80,F03D80/50,,0,0,,,,ACTIVE
28,EP,A1,EP 4296913 A1,024-799-149-678-022,2023-12-27,2023,EP 23180704 A,2023-06-21,US 202263353861 P;;US 202318211818 A,2022-06-21,SYSTEM AND METHOD FOR DETERMINING THE ENVIRONMENTAL IMPACT AND SUSTAINABILITY SCORE OF A FOOD ITEM USING A FOOD INGREDIENT REPOSITORY,"Methods, devices, and system for determining and generating environmental impact and sustainability score (EISS) labels and certificates for a food item. A computing device may be configured to receive a food item description, determine one or more food ingredients based on the received food item description, determine a food ingredient EISS value for each of the determined food ingredients based on information retrieved from a food ingredient repository, and determine a food item EISS value based on the determined food ingredient EISS values. The computing device may generate an EISS label based on the determined food item EISS value, such as by generating an encrypted label information structure and/or an EISS digital certificate (EISSDC).",NUTRITICS LTD,O KELLY DAMIAN;;O KELLY CIARAN;;HOGEN SINEAD,,https://lens.org/024-799-149-678-022,Patent Application,yes,2,0,2,2,0,G06Q10/00;;G06Q10/08;;G06Q10/0832;;G06Q10/0833;;G06Q10/0835;;A23L33/40;;A23V2002/00;;G06Q20/1235;;G06Q20/389;;G06Q30/0206,G06Q10/00;;G06Q10/08;;G06Q10/0832;;G06Q10/0833;;G06Q10/0835,,0,0,,,,PENDING
29,EP,A1,EP 4290498 A1,135-921-844-425-60X,2023-12-13,2023,EP 23175266 A,2023-05-25,IN 202211032277 A;;US 202217814701 A,2022-06-06,VEHICLE SYSTEMS AND RELATED MESSAGE PRIORITIZATION METHODS,"Methods and systems are provided for assisting operation of a vehicle by intelligently prioritizing messages relevant to a route for the vehicle. One method involves analyzing textual content of the message to automatically identify values for a plurality of fields of information specified by the message and obtaining current values for one or more of those fields from one or more data sources associated with the vehicle. In response to identifying a difference between a specified value and the corresponding current value for a field of information, the method automatically assigns a priority level to the message based at least in part on the difference and provides graphical indicia of the priority level assigned to the message and the specified value for the field.",HONEYWELL INT INC,RAO SUJAYA;;SINHA PRIYANSHU;;KAR SATYANARAYAN,,https://lens.org/135-921-844-425-60X,Patent Application,yes,5,0,1,2,0,G08G5/0021;;G08G5/0013;;G08G5/0039;;G08G5/006;;G08G5/0078;;G08G5/0091,G08G5/00,,0,0,,,,PENDING
30,EP,A1,EP 4290185 A1,164-495-512-243-01X,2023-12-13,2023,EP 22842431 A,2022-07-12,US 202163221467 P;;KR 2022010139 W,2021-07-13,MIXED REALITY-BASED DISPLAY DEVICE AND ROUTE GUIDE SYSTEM,"The present invention relates to a display device comprising: a communication unit for communicating with a cloud server; an interface unit for obtaining an image of the periphery of a vehicle by means of a camera, and receiving sensing information collected from at least one sensor; an MR module for rendering MR information, comprising a virtual object, on the basis of the sensing information and map information received from the cloud server; and a processor extracting an image, corresponding to a lateral surface of a building around the vehicle, from the obtained image, generating a texture image corresponding to the lateral surface of the building from the extracted image and transmitting same to the cloud server, receiving, from the cloud server, map information comprising models of buildings to which building textures on the basis of texture images are mapped, and displaying MR information rendered on the basis of the map information on a display provided in the vehicle.",LG ELECTRONICS INC,CHOI SUNGHWAN;;JANG YUJUNG;;LEE KIHYUNG;;KIM SEUNGMAN,,https://lens.org/164-495-512-243-01X,Patent Application,yes,0,0,20,20,0,H04N21/414;;G06T17/00;;G06T2210/61;;G06T2210/04;;G06Q50/40;;H04N21/44008;;G06V20/56;;G06V20/647;;G06V10/82;;G01C21/3635;;G01C21/365;;G01C21/3811;;G06N3/0475;;G06N3/045;;G06N3/094;;B60K2360/177;;B60K35/23;;B60K2360/166;;G06Q50/10;;B60W50/14;;G06F3/04815;;G06T19/00;;G01C21/36;;G06Q50/40;;H04N21/414,G01C21/36;;G01C21/00;;G06T15/00;;G06T17/05;;G06T19/00,,0,0,,,,PENDING
31,EP,A1,EP 4290478 A1,154-930-357-311-027,2023-12-13,2023,EP 23761742 A,2023-02-14,KR 20220035465 A;;KR 20220178036 A;;KR 2023002098 W,2022-03-22,"METHOD FOR PROCESSING IMAGE ACQUIRED FROM IMAGING DEVICE LINKED WITH COMPUTING DEVICE, AND SYSTEM USING SAME","A method of processing an image, performed by a computing apparatus including a processor, according to some exemplary embodiments of the present disclosure, may include: obtaining an image; obtaining, from the image, analysis information corresponding to an object included in the image by using an object analysis model; and obtaining, from the analysis information corresponding to the object, a character contained in the object by using an OCR model. The representative drawing",LEE CHOONG RYUL,LEE CHOONG RYUL,,https://lens.org/154-930-357-311-027,Patent Application,yes,0,0,3,7,0,H04N23/69;;H04N23/611;;G06V30/1448;;G06V30/1444;;G06V10/82;;G06V10/25;;G06V30/10;;G06V30/14;;G06V30/1444;;G06T7/136;;G03B17/56;;H04N23/69,G06V30/10;;G03B17/56;;G06T7/136;;G06V30/14;;H04N23/69,,0,0,,,,PENDING
32,EP,B1,EP 4038753 B1,036-014-943-535-785,2023-12-06,2023,EP 19784016 A,2019-10-03,EP 2019076792 W,2019-10-03,RECEPTION AND DECODING OF DATA IN A RADIO NETWORK,,ERICSSON TELEFON AB L M,RAMIREZ-GUTIERREZ RAYMUNDO,,https://lens.org/036-014-943-535-785,Granted Patent,yes,1,0,5,5,0,H04L25/0202;;H04B7/0695;;H04L25/0224;;H04L25/0254;;H04L25/0202;;H04W28/0226,H04B7/06;;H04L25/02,,3,0,,,"XIAOFENG LI ET AL: ""Generative Adversarial Estimation of Channel Covariance in Vehicular Millimeter Wave Systems"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 7 August 2018 (2018-08-07), XP081412891,;;QI SHI ET AL: ""Channel Estimation for WiFi Prototype Systems with Super-Resolution Image Recovery"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 25 February 2019 (2019-02-25), XP081032848,;;HENGTAO HE ET AL: ""Deep Learning-based Channel Estimation for Beamspace mmWave Massive MIMO Systems"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 5 February 2018 (2018-02-05), XP081214929,",ACTIVE
33,EP,A1,EP 4287081 A1,105-696-074-448-859,2023-12-06,2023,EP 21923011 A,2021-09-14,JP 2021013294 A;;JP 2021033723 W,2021-01-29,"MODEL GENERATION DEVICE, ESTIMATION DEVICE, MODEL GENERATION METHOD, AND MODEL GENERATION PROGRAM","A purpose of the present invention is to improve precision when estimating the solution to a task expressed in a graph. A model generation device according to one embodiment of the present invention performs machine learning of an estimation module provided with a feature-incorporated network and an estimator. The feature-incorporated network is provided with a plurality of feature-incorporated layers. An encoder for each feature-incorporated layer is configured so as to incorporate the feature amount of the outflow edge and inflow edge of each vertex after reflecting the relationship with other vertices. Moreover, the encoder for each feature-incorporated layer is configured so as to derive the relative feature amount for each edge based on the feature amount for all of the edges inputted for a target vertex, without calculating the weighted sum of the features of the edges adjacent to each vertex.",OMRON TATEISI ELECTRONICS CO,SONE SHUSAKU;;HASHIMOTO ATSUSHI;;MA JIAXIN,,https://lens.org/105-696-074-448-859,Patent Application,yes,0,0,5,5,0,G06N3/084;;G06N3/0442;;G06N3/0464;;G06N3/0475;;G06N20/00,G06N20/00,,1,0,,,See references of WO 2022163003A1,PENDING
34,EP,B1,EP 3600109 B1,190-767-480-725-506,2023-12-06,2023,EP 18776885 A,2018-03-31,US 201762480294 P;;US 2018/0025608 W,2017-03-31,SYSTEMS FOR OCULAR LASER SURGERY AND THERAPEUTIC TREATMENTS,,HIPSLEY ANNMARIE,HIPSLEY ANNMARIE,,https://lens.org/190-767-480-725-506,Granted Patent,yes,7,0,29,29,0,A61F9/00825;;A61B18/203;;A61B2018/00577;;A61B2018/00642;;A61B2018/00785;;A61B2018/00904;;A61B2018/20359;;A61F9/008;;A61F9/00838;;A61F2009/00846;;A61F2009/00865;;A61F2009/0088;;A61F2009/00882;;A61F2009/00895;;A61F2009/00897;;A61F9/008;;A61B18/203;;A61B2018/00577;;A61B2018/00613;;A61B2018/00642;;A61B2018/00785;;A61B2018/00904;;A61B2018/20355;;A61B2018/20359;;A61F9/0017;;A61F9/00802;;A61F9/00825;;A61F9/00838;;A61F2009/00846;;A61F2009/00851;;A61F2009/00865;;A61F2009/0088;;A61F2009/00882;;A61F2009/00895;;A61F2009/00897;;A61B18/20;;A61F9/00802;;A61B18/203;;A61B2018/00577;;A61B2018/00613;;A61B2018/00642;;A61B2018/00785;;A61B2018/00904;;A61B2018/20355;;A61B2018/20359;;A61F9/0017;;A61F9/008;;A61F9/00825;;A61F9/00838;;A61F2009/00846;;A61F2009/00851;;A61F2009/00865;;A61F2009/00878;;A61F2009/0088;;A61F2009/00882;;A61F2009/00895;;A61F2009/00897,A61B18/20;;A61F9/008,,0,0,,,,ACTIVE
35,EP,A1,EP 4283628 A1,137-114-366-826-848,2023-11-29,2023,EP 21920987 A,2021-01-21,JP 2021001976 W,2021-01-21,"INFORMATION PROCESSING APPARATUS, INFORMATION PROCESSING METHOD, AND PROGRAM","An information processing apparatus includes an estimation unit that estimates stress applied to a user based on schedule information of the user, and a determination unit that makes a determination of a feedback related to a schedule of the user based on an estimation result of the stress.",SONY GROUP CORP,TOKUTAKE KENJI;;FUJITA SHUJI;;TAKAHASHI TOMOTAKA,,https://lens.org/137-114-366-826-848,Patent Application,yes,0,0,3,3,0,G16H50/30;;G16H20/70;;A61B5/16;;A61B5/02438;;A61B5/7275;;A61B5/681;;A61B5/01;;A61B5/0531;;A61B5/7264;;A61B5/021;;A61B5/0205;;A61B5/0816;;G16H50/70;;G16H40/63;;G16H40/67,G16H20/70;;A61B5/16;;G16H50/30,,0,0,,,,PENDING
36,EP,A2,EP 4282272 A2,100-413-318-626-195,2023-11-29,2023,EP 23194346 A,2014-09-30,US 201361891729 P;;US 201361884369 P;;US 201361893003 P;;EP 14790850 A;;US 2014/0058340 W,2013-09-30,METHOD OF DELIVERING AN AGRICULTURALLY ACTIVE INGREDIENT,"Foamable formulations of agriculturally active ingredients are provided, as well as methods for using them. The formulations allow improved delivery active ingredients by the ability to deliver high amounts of active ingredient with a low volume of formulation used.",FMC CORP,GRANT SHAWN;;DESTEFANO NEIL;;PRESTEGORD ADAM;;HARPER MICHAEL,,https://lens.org/100-413-318-626-195,Patent Application,yes,3,0,44,49,0,A01N53/00;;A01N25/16;;B01F23/232;;B65D83/005;;A01N25/16;;A01N25/00;;A01N25/30;;A01N53/00;;B01F23/232;;A01N25/16;;A01N53/00;;B01F23/232;;A01N25/16;;A01N25/22;;A01N37/08;;A01N53/00;;B01F23/232;;B01F23/235,A01P7/00;;C05G3/60,,0,0,,,,PENDING
37,EP,A1,EP 4276732 A1,129-128-943-102-979,2023-11-15,2023,EP 23171591 A,2023-05-04,US 202217662727 A,2022-05-10,ARTIFICIAL INTELLIGENCE ENABLED VEHICLE SECURITY ASSESSMENT,"Techniques regarding vehicle security assessments are provided. For example, one or more embodiments described herein can comprise a system, which can further comprise a processor that can execute computer executable components stored in memory. The system can also comprise a security component that can determine a risk metric associated with a vehicle at a defined time based on an artificial intelligence model. The risk metric can characterize a probability that the vehicle, or an entity in proximity to the vehicle, will be subject to a security risk based on sensory data collected by the vehicle.",VOLVO CAR CORP,KOPPISETTY ASHOK CHAITANYA;;NILSSON ROBERT,,https://lens.org/129-128-943-102-979,Patent Application,yes,3,0,3,3,0,G06V20/56;;G06V20/52;;G06F11/3003;;G06Q10/0635;;G06N20/00;;G06Q50/265;;B60R25/31;;B60R25/32;;B60R25/33;;G06N5/022;;G07C5/02,G06Q50/26;;B60R25/31,,0,0,,,,PENDING
38,EP,A2,EP 4276769 A2,038-636-968-215-103,2023-11-15,2023,EP 23195503 A,2020-03-21,US 201962821602 P;;US 201962821618 P;;US 201962821681 P;;NL 2023310 A;;US 201962821724 P;;US 201962821766 P;;NL 2023311 A;;NL 2023312 A;;NL 2023314 A;;NL 2023316 A;;US 202016825987 A;;US 202016825991 A;;US 202016826126 A;;US 202016826134 A;;EP 20719053 A;;US 2020/0024090 W,2019-03-21,TRAINING DATA GENERATION FOR ARTIFICIAL INTELLIGENCE-BASED SEQUENCING,"The technology disclosed relates to generating ground truth training data to train a neural network-based template generator for cluster metadata determination task. In particular, it relates to accessing sequencing images, obtaining, from a base caller, a base call classifying each subpixel in the sequencing images as one of four bases (A, C, T, and G), generating a cluster map that identifies clusters as disjointed regions of contiguous subpixels which share a substantially matching base call sequence, determining cluster metadata based on the disjointed regions in the cluster map, and using the cluster metadata to generate the ground truth training data for training the neural network-based template generator for the cluster metadata determination task.",ILLUMINA INC,The designation of the inventor has not yet been filed,,https://lens.org/038-636-968-215-103,Patent Application,yes,96,0,55,76,0,G06N3/084;;G16B30/00;;G16B40/10;;C12Q1/6874;;G06F18/241;;G06F16/58;;G06N3/084;;G06V10/454;;G06V10/993;;G16B30/20;;G16B40/20;;G06V10/82;;G06V10/267;;G06V20/47;;G06V20/69;;G06V2201/03;;G16B40/10;;G06V10/7715;;G06V10/763;;G06V10/7784;;G06V10/764;;G06N3/048;;G06N3/044;;G06N3/045;;G06F18/23211;;G06F18/213;;G06N3/084;;G06N3/08;;G16B40/20;;G16B40/10;;G06V20/69;;G06V20/47;;G06V10/267;;G06V10/454;;G06V2201/03;;G06N3/044;;G06N3/045;;G06F18/23211;;G06F18/24;;G16B40/20;;G16B30/10;;G06V20/69;;G06V10/267;;G06V10/454;;G06N3/044;;G06N3/045;;G06F18/23211;;G06F18/24;;G06N3/084;;G06V20/47;;G06V2201/03;;G16B40/10;;G06N3/042;;G06F16/907;;G16B40/00;;G06N3/04;;G06N3/08;;G06N3/084;;G06N5/046;;G06F18/23;;G06F18/24;;G06F18/214;;G06F18/217;;G06F18/2415;;G06F18/2431;;G06F18/23211;;G06N7/01;;G16B40/20;;G06V10/763;;G06V10/764;;G06V10/7715;;G06V10/7784;;G06V10/82;;G06V10/454;;G06V10/267;;G06V10/993;;G06V20/69;;G06V20/47;;G06V10/751;;G06F18/213,G06V10/82,,47,18,028-029-054-514-038;;081-115-790-154-352;;083-269-166-444-078;;121-255-147-667-419;;042-240-098-526-453;;021-244-676-740-862;;020-233-013-143-936;;013-156-255-523-712;;042-508-572-167-166;;020-233-013-143-936;;139-552-118-652-140;;079-310-940-223-758;;058-296-969-136-48X;;041-314-165-476-904;;001-221-012-281-432;;077-993-735-854-975;;168-150-402-262-991;;018-565-258-437-405,10.1007/s10766-017-0495-0;;10.1109/mwscas.2018.8623988;;10.1109/tbcas.2019.2958049;;31825872;;10.1109/cvpr.2013.163;;10.1109/cvpr.2017.195;;10.1109/cvpr.2018.00716;;10.1109/cvpr.2016.90;;10.1109/cvpr.2017.634;;10.1109/icip.2018.8451355;;10.1109/cvpr.2016.90;;10.1109/cvpr.2017.243;;10.1109/cvpr.2015.7298594;;10.1007/978-3-319-52280-7_9;;10.1109/tpami.2016.2572683;;10.1109/cvpr.2015.7298965;;27244717;;10.1080/21681163.2016.1149104;;pmc5226438;;28090601;;10.1007/978-3-319-24574-4_43;;18987683;;10.1038/nature07517;;18987734;;pmc2581791;;12857956;;pmc166396;;10.1073/pnas.1133470100,"LIU PHEMANI APAUL KWEIS CJUNG MWEHN N: ""3D-Stacked Many-Core Architecture for Biological Sequence Analysis Problems"", INT J PARALLEL PROG, vol. 45, no. 6, 2017, pages 1420 - 60, XP036325442, DOI: 10.1007/s10766-017-0495-0;;Z. WUK. HAMMADR. MITTMANNS. MAGIEROWSKIE. GHAFAR-ZADEHX. ZHONG: ""FPGA-Based DNA Basecalling Hardware Acceleration"", PROC. IEEE 61ST INT. MIDWEST SYMP. CIRCUITS SYST, August 2018 (2018-08-01), pages 1098 - 1101, XP033508770, DOI: 10.1109/MWSCAS.2018.8623988;;Z. WUK. HAMMADE. GHAFAR-ZADEHS. MAGIEROWSKI: ""FPGA-Accelerated 3rd Generation DNA Sequencing"", IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS, vol. 14, February 2020 (2020-02-01), pages 65 - 74, XP011771041, DOI: 10.1109/TBCAS.2019.2958049;;PRABHAKAR ET AL.: ""Plasticine: A Reconfigurable Architecture for Parallel Patterns"", vol. 17, 24 June 2017, ISCA;;M. LINQ. CHENS. YAN: ""Network in Network"", PROC. OF ICLR, 2014;;L. SIFRE: ""Rigid-motion Scattering for Image Classification"", PH D. THESIS, 2014;;L. SIFRES. MALLAT: ""Rotation, Scaling and Deformation Invariant Scattering for Texture Discrimination"", PROC. OF CVPR, 2013;;F. CHOLLET: ""Xception: Deep Learning with Depthwise Separable Convolutions"", PROC. OF CVPR, 2017;;X. ZHANGX. ZHOUM. LINJ. SUN: ""ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices"", ARXIV: 1707.01083, 2017;;K. HEX. ZHANGS. RENJ. SUN: ""Deep Residual Learning for Image Recognition"", PROC. OF CVPR, 2016;;S. XIER. GIRSHICKP. DOLLARZ. TUK. HE: ""Aggregated Residual Transformations for Deep Neural Networks"", IN PROC. OF CVPR, 2017;;A. G. HOWARDM. ZHUB. CHEND. KALENICHENKOW. WANGT. WEYANDM. ANDREETTOH. ADAM: ""Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications"", ARXIV: 1704.04861, 2017;;M. SANDLERA. HOWARDM. ZHUA. ZHMOGINOVL. CHEN: ""MobileNetV2: Inverted Residuals and Linear Bottlenecks"", ARXIV:1801.04381V3, 2018;;Z. QINZ. ZHANGX. CHENY. PENG: ""FD-MobileNet: Improved MobileNet with a Fast Downsampling Strategy"", ARXIV:1802.037S0, 2018;;LIANG-CHIEH CHENGEORGE PAPANDREOUFLORIAN SCHROFFHARTWIG ADAM: ""Rethinking atrous convolution for semantic image segmentation"", CORR, ABS/1706.05587, 2017;;J. HUANGV. RATHODC. SUNM. ZHUA. KORATTIKARAA. FATHII. FISCHERZ. WOJNAY. SONGS. GUADARRAMA ET AL.: ""Speed/accuracy trade-offs for modern convolutional object detectors"", ARXIV PREPRINT ARXIV, vol. 1611, 2016, pages 10012;;S. DIELEMANH. ZENK. SIMONYANO. VINYALSA. GRAVESN. KALCHBRENNERA. SENIOK. KAVUKCUOGLU: ""WAVENET: A GENERATIVE MODEL FOR RAW AUDIO"", ARXIV: 1609.03499, 2016;;S. Ö. ARIKM. CHRZANOWSKIA. COATESG. DIAMOSA. GIBIANSKYY. KANGX. LIJ. MILLEA. NGJ. RAIMAN: ""DEEP VOICE: REAL-TIME NEURAL TEXT-TO-SPEECH"", ARXIV: 1702.07825, 2017;;F. YUV. KOLTUN: ""MULTI-SCALE CONTEXT AGGREGATION BY DILATED CONVOLUTIONS"", ARXIV: 1511.07122, 2016;;K. HEX. ZHANGS. RENJ. SUN: ""DEEP RESIDUAL LEARNING FOR IMAGE RECOGNITION"", ARXIV: 1512.03385, 2015;;R.K. SNVASTAVAK. GREFFJ. SCHMIDHUBER: ""HIGHWAY NETWORKS"", ARXIV: 1505.00387, 2015;;G. HUANGZ. LIUL. VAN DER MAATENK. Q. WEINBERGER: ""DENSELY CONNECTED CONVOLUTIONAL NETWORKS"", ARXIV: 1608.06993, 2017;;C. SZEGEDYW. LIUY. JIAP. SERMANETS. REEDD. ANGUELOVD. ERHANV. VANHOUCKEA. RABINOVICH: ""GOING DEEPER WITH CONVOLUTIONS"", ARXIV: 1409 4842, 2014;;S. IOFFEC. SZEGEDY: ""BATCH NORMALIZATION ACCELERATING DEEP NETWORK TRAINING BY REDUCING INTERNAL COVARIATE SHIFT"", ARXIV: 1502 03167, 2015;;J. M. WOLTERINK, T. LEINER, M. A. VIERGEVER, AND 1. ISGUM: ""DILATED CONVOLUTIONAL NEURAL NETWORKS FOR CARDIOVASCULAR MR SEGMENTATION IN CONGENITAL HEART DISEASE"", ARXIV:1704.03669, 2017;;L. C. PIQUERAS: ""AUTOREGRESSIVE MODEL BASED ON A DEEP CONVOLUTIONAL NEURAL NETWORK FOR AUDIO GENERATION"", TAMPERE UNIVERSITY OF TECHNOLOGY, 2016;;J. WU: ""Introduction to Convolutional Neural Networks"", NANJING UNIVERSITY, 2017;;""Illumina CMOS Chip and One-Channel SBS Chemistry"", ILLUMINA, INC, 2018, pages 2;;""skikit-image/peak.py at maste"", GITHUB, 5 PAGES, 16 November 2018 (2018-11-16), Retrieved from the Internet <URL:https://github.com/scikit-image/scikit-image/blob/master/skimage/feature/peak.py#L25>>;;""3.3.9.1 l.. Watershed and random walker for segmentation"", SCIPY LECTURE NOTES, 13 November 2018 (2018-11-13), pages 2, Retrieved from the Internet <URL:http://scipy-lectures.org/packages/scikit-image/auto_examples/plot_segmentations.html>>;;MORDVINTSEV, ALEXANDERREVISION, ABID K: ""Image Segmentation with Watershed Algorithm"", REVISION 43532856, 13 November 2018 (2018-11-13), pages 6;;MZUR, WATERSHED.PY, 25 October 2017 (2017-10-25), pages 3, Retrieved from the Internet <URL:https://github.com/mzur/watershed/blob/master/Watershed.py>>;;THAKUR, PRATIBHA: ""A Survey of Image Segmentation Techniques"", INTERNATIONAL JOURNAL OF RESEARCH IN COMPUTER APPLICATIONS AND ROBOTICS, vol. 2, no. 4, April 2014 (2014-04-01), pages 158 - 165;;LONG, JONATHAN: ""Fully Convolutional Networks for Semantic Segmentation"", IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, vol. 39, no. 4, 1 April 2017 (2017-04-01), pages 10, XP055865277, DOI: 10.1109/TPAMI.2016.2572683;;RONNEBERGER, OLAF: ""U-net: Convolutional networks for biomedical image segmentation"", IN INTERNATIONAL CONFERENCE ON MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION, 18 May 2015 (2015-05-18), pages 8;;XIE, W: ""Microscopy cell counting and detection with fully convolutional regression networks"", COMPUTER METHODS IN BIOMECHANICS AND BIOMEDICAL ENGINEERING: IMAGING & VISUALIZATION, vol. 6, no. 3, 2018, pages 283 - 292, XP055551866, DOI: 10.1080/21681163.2016.1149104;;XIE, YUANPU ET AL.: ""Beyond classification: structured regression for robust cell detection using convolutional neural network"", INTERNATIONAL CONFERENCE ON MEDICAL IMAGE COMPUTING AND COMPUTER-ASSISTED INTERVENTION, October 2015 (2015-10-01), pages 12;;SNUVERINK, I. A. F: ""Deep Learning for Pixelwise Classification of Hyperspectral Images"", MASTER OF SCIENCE T ESIS, DELFT UNIVERSITY OF TECHNOLOGY, 23 November 2017 (2017-11-23), pages 19;;SHEVCHENKO, A, KERAS WEIGHTED CATEGORICAL_CROSSENTROPY, 15 January 2019 (2019-01-15), pages 1, Retrieved from the Internet <URL:https://gist.github.com/skeeet/cad06d584548fb45eece1d4e28cfa98b>>;;VAN DEN ASSEM, D.C.F: ""Predicting periodic and chaotic signals using Wavenets"", MASTER OF SCIENCE T ESIS, DELFT UNIVERSITY OF TECHNOLOGY, 18 August 2017 (2017-08-18), pages 3 - 38;;I. J. GOODFELLOWD. WARDE-FARLEYM. MIRZAA. COURVILLEY. BENGIO: ""Deep Learning"", 2016, MIT PRESS, article ""CONVOLUTIONAL NETWORKS"";;J. GUZ. WANGJ. KUENL. MAA. SHAHROUDYB. SHUAT. LIUX. WANGG. WANG: ""RECENT ADVANCES IN CONVOLUTIONAL NEURAL NETWORKS"", ARXIV: 1512.07108, 2017;;BENTLEY ET AL., NATURE, vol. 456, 2008, pages 53 - 59;;J. LONGE. SLVΕ.LLWNΕ.RT. DARRELL: ""Fully convolutional networks for semantic segmentation"", CVPR, 2015;;RONNEBERGER OFISCHER PBROX T: ""U-net: Convolutional networks for biomedical image segmentation"", MED. IMAGE COMPUT. COMPUT. ASSIST. INTERV, 2015, Retrieved from the Internet <URL:http://link.springer.com/chapter/10.1007/978-3-319-24574-4_28>;;BENTLEY ET AL., NATURE, vol. 456, no. 78, pages 53 - 59;;DRESSMAN ET AL., PROC. NATL. ACAD. SCI. USA, vol. 100, 2003, pages 8817 - 8822",PENDING
39,EP,A2,EP 4274268 A2,007-937-901-675-193,2023-11-08,2023,EP 23199127 A,2021-02-05,US 202062970482 P;;US 202063085515 P;;EP 21155627 A,2020-02-05,SYSTEM AND METHOD FOR PRIVACY-AWARE ANALYSIS OF VIDEO STREAMS,"A method and system for privacy-aware movement tracking includes receiving a series of images of a field of view, such as captured by a camera. The images containing movement of an unidentified person within the field of view. A body region corresponding to the person is detected within the images. A movement dataset for the unidentified person is generated based on tracking movement of the body region over the fired of view within the images is generated. A characterizing feature set is determined for the unidentified person. The set is associated within the movement dataset to form a first track entry. Anonymizing of the body region can be applied to remove identifying features while or prior to determining the characterizing feature set. A second track entry can be generated from a second series of images and match between the track entries can be determined. A method and system for privacy-aware operation and learning of a computer-implemented classification module is also contemplated.",C2RO CLOUD ROBOTICS INC,BADALONE RICCARDO;;FAROKHI SOODEH;;HAJI ABOLHASSANI AMIR ABBAS;;DUGUAY FELIX-OLIVIER;;BARRETT NEIL;;ERFANI MOSTAFA;;VARGAS MORENO ALDO ENRIQUE,,https://lens.org/007-937-901-675-193,Patent Application,yes,3,0,11,13,0,G06F21/60;;H04W12/02;;H04W4/029;;G06V20/52;;G06V10/22;;H04N7/181;;G06Q30/0201;;G06F16/784;;G06F16/73;;G06F21/6254;;G06V20/48;;G06V40/167;;G06F21/60;;G06V10/22;;G06V20/52,H04W4/029,,0,0,,,,PENDING
40,EP,A2,EP 4273655 A2,009-271-585-391-299,2023-11-08,2023,EP 23188804 A,2017-11-08,GB 201618809 A;;EP 17817016 A;;GB 2017053367 W,2016-11-08,A ROBOTIC FRUIT PICKING SYSTEM,"A robotic fruit picking system comprising an autonomous robot that includes a positioning subsystem that enables autonomous positioning of the robot using a computer vision guidance system. The robot also includes at least one picking arm and at least one picking head, or other type of end effector, mounted on each picking arm to either cut a stem or branch for a specific fruit or bunch of fruits or pluck that fruit or bunch. A computer vision subsystem analyses images of the fruit to be picked or stored and a control subsystem is programmed with or learns picking strategies or algorithms. A quality control (QC) subsystem monitors the quality of fruit and grades that fruit according to size and/or quality. The QC subsystem is separate from the picking arm. The robot has a storage subsystem configured to receive the picked fruit and to store that fruit in containers for storage or transportation, or in punnets for retail.",DOGTOOTH TECH LIMITED,ROBERTSON DUNCAN;;COOK MATTHEW;;HERBERT EDWARD;;TULLY FRANK,,https://lens.org/009-271-585-391-299,Patent Application,yes,0,0,17,17,0,G05D1/0094;;A01G9/143;;A01D46/30;;Y02A40/25;;B25J5/005;;B25J9/0084;;B25J11/00;;B25J9/1697;;G05D1/0219;;A01D46/22;;A01D46/243;;A01D46/253;;A01D46/30;;B25J9/1679;;B25J9/1697;;B25J11/00;;B25J15/0019;;G05B2219/45003;;G06T7/50;;G06T7/11;;G06T7/90;;G06T7/70;;A01D46/28;;B25J9/0084;;B25J9/06;;B25J15/0033;;G06Q30/0283;;G06T7/0004;;G06T7/60;;G06T2207/10048;;G06T2207/20081;;G06T2207/20084;;G06T2207/30128;;A01G9/143;;Y02A40/25;;G06V20/10;;G06V20/68;;G06F18/2148;;G06F18/24323;;G06F18/24765,G05D1/00,,0,0,,,,PENDING
41,EP,B1,EP 3862902 B1,034-806-016-261-501,2023-11-01,2023,EP 21155627 A,2021-02-05,US 202062970482 P;;US 202063085515 P,2020-02-05,SYSTEM AND METHOD FOR PRIVACY-AWARE ANALYSIS OF VIDEO STREAMS,,C2RO CLOUD ROBOTICS INC,BADALONE RICCARDO;;FAROKHI SOODEH;;HAJI ABOLHASSANI AMIR ABBAS;;DUGUAY FELIX-OLIVIER;;BARRETT NEIL;;ERFANI MOSTAFA;;VARGAS MORENO ALDO ENRIQUE,,https://lens.org/034-806-016-261-501,Granted Patent,yes,3,0,11,13,0,G06F21/60;;H04W12/02;;H04W4/029;;G06V20/52;;G06V10/22;;H04N7/181;;G06Q30/0201;;G06F16/784;;G06F16/73;;G06F21/6254;;G06V20/48;;G06V40/167;;G06F21/60;;G06V10/22;;G06V20/52,G06F21/60;;G06V10/22;;G06V20/52;;H04W4/029;;H04W12/02,,0,0,,,,ACTIVE
42,EP,B1,EP 3051944 B1,165-827-929-656-885,2023-11-01,2023,EP 14790850 A,2014-09-30,US 201361884369 P;;US 201361891729 P;;US 201361893003 P;;US 2014/0058340 W,2013-09-30,METHOD OF DELIVERING AN AGRICULTURALLY ACTIVE INGREDIENT,,FMC CORP,MARTIN TIMOTHY M;;GRANT SHAWN;;DESTEFANO NEIL;;PRESTEGORD ADAM;;HARPER MICHAEL,FMC CORPORATION (2018-04-04),https://lens.org/165-827-929-656-885,Granted Patent,yes,5,0,44,49,0,A01N53/00;;A01N25/16;;B01F23/232;;B65D83/005;;A01N25/16;;A01N25/00;;A01N25/30;;A01N53/00;;B01F23/232;;A01N25/16;;A01N53/00;;B01F23/232;;A01N25/16;;A01N25/22;;A01N37/08;;A01N53/00;;B01F23/232;;B01F23/235,A01N25/00;;A01N25/16;;A01N25/30;;A01N53/00;;A01P7/00;;C05G3/60,,0,0,,,,ACTIVE
43,EP,B1,EP 3841967 B1,187-991-100-412-953,2023-10-25,2023,EP 21155403 A,2016-01-06,AU 2015/900015 A;;EP 16701198 A;;IB 2016050042 W,2015-01-06,MOBILE WEARABLE MONITORING SYSTEMS,,BURTON DAVID,BURTON DAVID,,https://lens.org/187-991-100-412-953,Granted Patent,yes,2,1,29,29,0,A61B5/14551;;A61B5/4806;;A61B5/4809;;A61B5/4818;;A61B5/6802;;A61B5/6803;;A61B5/681;;A61B5/16;;A61B5/72;;A61B5/112;;A61B3/16;;A61B8/06;;A61B8/02;;A61B8/4427;;A61B8/488;;A61B2560/0242;;A61B5/0002;;A61B5/0205;;A61B5/024;;A61B5/11;;A61B5/1123;;A61B5/14551;;A61B5/4806;;A61B5/6814;;A61B5/6824;;G16H40/63;;G16H40/67;;A61B5/4815;;Y02A90/10;;A61B5/291;;A61B5/398;;A61B5/389;;A61B5/369;;A61B5/4082;;G16H50/20;;A61N2/00;;A61N2005/0626;;A61N5/06;;A61B5/4806;;A61B5/4836;;A61B5/4815;;A61B5/0205;;A61B5/14551;;A61B5/4812;;A61B5/369;;A61B5/389;;A61B5/398;;A61B5/681;;A61B5/6824;;G16H50/20;;G16H40/63;;G16H40/67,A61B5/00;;A61B5/0205;;A61B5/024;;A61B5/11;;A61B5/1455;;A61B5/291;;A61B5/369;;A61B5/389;;A61B5/398,,3,0,,,"FANTINI M L ET AL: ""Idiopathic rapid eye movement sleep behaviour disorder"", NEUROLOGICAL SCIENCES ; OFFICIAL JOURNAL OF THE ITALIAN NEUROLOGICAL SOCIETY, SPRINGER-VERLAG, MI, vol. 28, no. 1, 1 January 2007 (2007-01-01), pages S15-S20, XP019462608, ISSN: 1590-3478, DOI: 10.1007/S10072-007-0734-Z;;BENNINGER DAVID H ET AL: ""REM sleep behavior disorder is not linked to postural instability and gait dysfunction in Parkinson."", MOVEMENT DISORDERS : OFFICIAL JOURNAL OF THE MOVEMENT DISORDER SOCIETY 15 AUG 2010, vol. 25, no. 11, 15 August 2010 (2010-08-15), pages 1597-1604, XP00952691, ISSN: 1531-8257;;POSTUMA ET AL: ""Potential early markers of Parkinson disease in idiopathic REM sleep behavior disorder"", NEUROLOGY, LIPPINCOTT WILLIAMS & WILKINS , PHILADELPHIA, US , vol. 66, no. 6 28 March 2006 (2006-03-28), pages 845-851, XP009526919, ISSN: 0028-3878, DOI: 10.1212/01.WNL.0000203648.80727.5B Retrieved from the Internet: URL:https://n.neurology.org/content/66/6/8 45",ACTIVE
44,EP,A1,EP 4261735 A1,061-776-101-221-496,2023-10-18,2023,EP 22167932 A,2022-04-12,EP 22167932 A,2022-04-12,NATURAL LANGUAGE PROCESSING BY MEANS OF A QUANTUM RANDOM NUMBER GENERATOR,"A method for natural language processing comprises: receiving a sample comprising natural language; processing the sample, wherein processing the sample comprises generating a plurality of response hypotheses and generating a plurality of confidence values, wherein each response hypothesis is associated with the corresponding confidence value; and selecting a response, comprising selecting the response randomly among the plurality of response hypotheses based at least in part on the corresponding confidence value by means of a quantum random number generator.",TERRA QUANTUM AG,LESOVIK GORDEY;;MARCHENKO ARTEMIY;;VINOKOUR VALERII;;MALINOVSKII VLADIMIR;;KHORUZHII KIRILL;;IGNATOV FEDOR;;MATRENOK SEMEN;;KIRAKOSYAN DAVIT;;TERENTEV VLADIMIR,,https://lens.org/061-776-101-221-496,Patent Application,yes,1,0,7,7,0,G06F16/3329;;G06F7/588;;G06N10/20;;G06F40/35;;G06F40/253;;G06F40/232;;G06F40/289;;G06F40/295;;G06F40/216;;G06N10/40;;G06N3/0475;;G06N3/0455;;G06N20/20;;G06F16/3329;;G06F16/3344;;G06F16/338;;H04L51/02;;G06F7/588;;G06N10/00;;G06F7/588,G06F40/35;;G06F7/58;;G06F40/216;;G06F40/232;;G06F40/253;;G06F40/289;;G06F40/295;;G06N10/00,,10,6,132-139-065-308-085;;132-139-065-308-085;;008-708-960-845-751;;067-108-767-777-225;;048-915-547-176-171;;134-213-804-511-155,10.1103/revmodphys.89.015004;;10.1103/revmodphys.89.015004;;10.1145/365153.365168;;10.18653/v1/2020.findings-emnlp.196;;10.1214/aos/1013203451;;10.1109/icdar.1995.598994,"HERRERO-COLLANTES MIGUEL ET AL: ""Quantum random number generators"", REVIEWS OF MODERN PHYSICS, vol. 89, no. 1, 21 October 2016 (2016-10-21), XP055822716, ISSN: 0034-6861, Retrieved from the Internet <URL:https://arxiv.org/pdf/1604.03304.pdf> DOI: 10.1103/RevModPhys.89.015004;;MIKHAIL BURTSEV ET AL: ""DeepPavlov: Open-Source Library for Dialogue Systems"", PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS-SYSTEM DEMONSTRATIONS, 1 July 2018 (2018-07-01), Melbourne, Australia, pages 122 - 127, XP055597237, DOI: 10.18653/v1/P18-4021;;IULIAN V SERBAN ET AL: ""A Deep Reinforcement Learning Chatbot"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 7 September 2017 (2017-09-07), XP081282935;;M. HERRERO-COLLANTESJ. C. GARCIA-ESCARTIN: ""Quantum Random Number Generators"", REVIEWS OF MODERN PHYSICS, vol. 89, 2017, pages 015004;;JOSEPH WEIZENBAUM: ""ELIZA - A Computer Program for the Study of Natural Language Communication Between Man And Machine"", COMMUNICATIONS OF THE ACM, vol. 9, no. 1, January 1966 (1966-01-01), pages 36 - 45, XP055016958, DOI: 10.1145/365153.365168;;I. SOLAIMAN ET AL.: ""Release Strategies and the Social Impacts of Language Models"", 13 November 2019, CORNELL UNIVERSITY;;Y. ZHANG ET AL.: ""DialoGPT: Large-Scale Generative Pre-training for Conversational Response Generation"", ARXIV: 1911.00536 V3, 2 May 2020 (2020-05-02);;M. HENDERSON ET AL.: ""ConverRT: Efficient and Accurate Conversational Representations from Transformers"", FINDINGS OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, EMNLP, 2020, pages 2161 - 2174;;J.H. FRIEDMAN: ""Greedy function approximation: A gradient boosting machine"", ANNALS OF STATISTICS, vol. 29, no. 5, 2001, pages 1189 - 1232, XP055249500;;T.K. HO: ""Random decision forests"", PROCEEDINGS OF 3RD INTERNATIONAL CONFERENCE ON DOCUMENT ANALYSIS AND RECOGNITION, 1995, pages 278 - 282",PENDING
45,EP,A1,EP 4258219 A1,072-331-225-313-701,2023-10-11,2023,EP 22305479 A,2022-04-07,EP 22305479 A,2022-04-07,RENDERING OF AUGMENTED REALITY (AR) CONTENT AND METHOD FOR ENABLING AR CONTENT RENDERING,"The present application relates to a method implemented by an augmented reality, AR, device (500) for performing AR content rendering, the method comprising: transmitting, to an external processing device (502), encoded source video picture data representative of a video picture (PR1) of a real-world scene (OB1); receiving lighting information from the processing device (502); and generating an AR video picture (PR2) by aggregating the video picture (PR1) and volumetric information representative of a virtual object (OB2) into an aggregated video picture and by incorporating (404), into the aggregated video picture, relighting effects (SH2) associated with the virtual object (OB2) based on the received lighting information. A corresponding method implemented by a processing device (502) for enabling AR content rendering is also provided.",BEIJING XIAOMI MOBILE SOFTWARE CO LTD,ANDRIVON PIERRE;;LE LEANNEC FABRICE;;THOMAS EMMANUEL;;CHAMPEL MARY-LUC,,https://lens.org/072-331-225-313-701,Patent Application,yes,0,0,2,2,0,G06T15/506;;G06T19/006;;G06T19/20;;G06T2219/2012,G06T15/50;;G06T19/00;;G06T19/20,,3,3,039-749-938-706-62X;;040-480-743-712-073;;118-893-146-710-647,10.1109/icit.2017.7915547;;10.1007/s00371-019-01666-x;;10.1145/3130800.3130891,"SCHNEIDER MICHAEL ET AL: ""Augmented reality based on edge computing using the example of remote live support"", 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), IEEE, 22 March 2017 (2017-03-22), pages 1277 - 1282, XP033091243, DOI: 10.1109/ICIT.2017.7915547;;KÁN PETER ET AL: ""DeepLight: light source estimation for augmented reality using deep learning"", VISUAL COMPUTER, vol. 35, no. 6-8, 1 June 2019 (2019-06-01), DE, pages 873 - 883, XP055981143, ISSN: 0178-2789, Retrieved from the Internet <URL:https://link.springer.com/content/pdf/10.1007/s00371-019-01666-x.pdf> DOI: 10.1007/s00371-019-01666-x;;GARDNER MARC-ANDRÉ ET AL: ""Learning to predict indoor illumination from a single image"", ACM TRANSACTIONS ON GRAPHICS, vol. 36, no. 6, 20 November 2017 (2017-11-20), US, pages 1 - 14, XP055981146, ISSN: 0730-0301, Retrieved from the Internet <URL:https://arxiv.org/pdf/1704.00090.pdf> DOI: 10.1145/3130800.3130891",PENDING
46,EP,A1,EP 4258605 A1,128-905-699-906-429,2023-10-11,2023,EP 22166905 A,2022-04-06,EP 22166905 A,2022-04-06,AMBIGUITY RESOLUTION OF MULTIPATH COMPONENT PARAMETERS,"Inter-alia, a method is disclosed comprising: Obtaining a measurement of a first signal on a first radio channel, wherein the first radio channel exhibits multipath propagation represented by a set of multipath components; Identifying at least a part of a first subspace of a plurality of sets of possible multipath components consistent with the first signal as an identified first subspace; Obtaining at least one additional information associated with the identified first subspace; Downselecting the identified first subspace based on the at least one additional information into a downselected subspace; and identifying an estimation of the set of multipath components from the downselected subspace. It is further disclosed an according apparatus, computer program and system.",NOKIA TECHNOLOGIES OY,ZIRWAS WOLFGANG;;VILAS BOAS BRENDA,,https://lens.org/128-905-699-906-429,Patent Application,yes,3,0,1,1,0,H04L25/0204;;H04L25/0212;;H04L25/0254;;H04L25/0256,H04L25/02,,0,0,,,,PENDING
47,EP,A1,EP 4258220 A1,091-708-444-545-875,2023-10-11,2023,EP 22305480 A,2022-04-07,EP 22305480 A,2022-04-07,RENDERING OF AUGMENTED REALITY (AR) CONTENT,"The present application relates to a method (400) for performing AR content rendering, the method comprising: obtaining (410) virtual relighting effects based on virtual lighting information (DT6) representative of at least one virtual light source (SC2); obtaining (412) hybrid relighting effects based on the virtual lighting information (DT6) and based on physical lighting information (DT4) representative of at least one physical light source (SC1); and generating (408) an AR video picture (PR3) by aggregating a real-world scene relighted based on the virtual relighting effects (RL1) and at least one virtual object relighted based on the hybrid relighting effects (RL2). The AR video picture (PR3) may then be rendered.",BEIJING XIAOMI MOBILE SOFTWARE CO LTD,THOMAS EMMANUEL;;ANDRIVON PIERRE;;LE LEANNEC FABRICE;;CHAMPEL MARY-LUC,,https://lens.org/091-708-444-545-875,Patent Application,yes,1,0,2,2,0,G06T19/20;;G06T15/506;;G06T19/006;;G06T2219/2012,G06T15/50;;G06T19/00,,2,2,056-327-603-392-653;;079-338-004-202-799,10.1109/2945.895874;;10.1186/s13640-018-0357-8,"LOSCOS CÉLINE ET AL: ""Interactive Virtual Relighting of Real Scenes Interactive Virtual Relighting of Real Scenes"", IEEE TRANSACTIONS ON VISUALIZATION AND COMPUTER GRAPHICS, 1 January 2000 (2000-01-01), pages 289 - 305, XP055958947, Retrieved from the Internet <URL:https://hal.inria.fr/inria-00527523/document> [retrieved on 20220908];;SEO SANGHYUN ET AL: ""Real-time adaptable and coherent rendering for outdoor augmented reality"", EURASIP JOURNAL ON IMAGE AND VIDEO PROCESSING, vol. 2018, no. 1, 1 December 2018 (2018-12-01), pages 118, XP055959448, Retrieved from the Internet <URL:https://jivp-eurasipjournals.springeropen.com/track/pdf/10.1186/s13640-018-0357-8.pdf> DOI: 10.1186/s13640-018-0357-8",PENDING
48,EP,B1,EP 3783882 B1,146-722-685-233-500,2023-10-04,2023,EP 19875951 A,2019-06-06,CN 201811260175 A;;CN 2019090372 W,2018-10-26,CAMERA APPARATUS ADJUSTMENT METHOD AND RELATED DEVICE,,HUAWEI TECH CO LTD,YANG DONGDONG;;HU WEILONG;;YANG TAO,,https://lens.org/146-722-685-233-500,Granted Patent,yes,11,0,6,6,0,H04N23/73;;G07C5/0866;;G06N3/084;;G06V10/60;;G06V20/56;;H04N23/64;;H04N23/71;;H04N23/73;;H04N23/75;;H04N23/76;;G06N3/084;;G06V10/60;;G06V20/56,H04N23/60;;G06N3/084;;G06V10/60;;G06V20/56;;G07C5/08;;H04N23/71;;H04N23/73;;H04N23/75;;H04N23/76,,0,0,,,,ACTIVE
49,EP,A1,EP 4254332 A1,153-801-202-238-788,2023-10-04,2023,EP 22192805 A,2022-08-30,CN 202210331902 A,2022-03-30,"METHOD AND APPARATUS FOR OPTIMIZING MAP DATA, AND STORAGE MEDIUM","The present disclosure provides a method and apparatus for optimizing map data, a device and a storage medium, relates to the technical field of image processing, and in particular relates to artificial intelligence, intelligent transportation, smart cities and smart cockpits. A specific implementation is: performing a completeness detection of a lane line on received local map data comprising road condition information to obtain a detection result, the detection result comprising the lane line being complete or is the lane line having a missing area; in a case where the detection result is the lane line having the missing area, performing completion processing on the lane line having the missing area to obtain completed local map data; and performing a rationality detection on the completed local map data, and in a case of passing the detection, synthesizing the completed local map data with global map data to obtain an optimization result of map data. The method of the present disclosure may be applicable to map data optimization in different scenarios, thereby improving generalization.",APOLLO INTELLIGENT CONNECTIVITY BEIJING TECHNOLOGY CO LTD,CAI YUZHAN;;YAN QINGYUE;;YAN CHAO,,https://lens.org/153-801-202-238-788,Patent Application,yes,1,0,3,3,0,G06F16/215;;G06F16/29;;G01C21/3841;;G01C21/3819;;G01C21/3889;;G06T2207/20084;;G06T2207/30256;;G06N3/084;;G06N3/045;;G06N3/0475;;G06T5/77;;G06T5/60;;G01C21/3815;;G01C21/3833;;G06T7/0002;;G06T2207/20081;;G06T2207/20084;;G06T2207/30168;;G08G1/0969,G06T7/12;;G01C21/00;;G01C21/32;;G06N3/08,,2,2,016-161-444-832-739;;016-125-667-287-733,10.1109/iaeac47372.2019.8997573;;10.1109/eit.2014.6871806,"JIANG LIBIAO ET AL: ""Lane Line Detection Optimization Algorithm based on Improved Hough Transform and R-least Squares with Dual Removal"", 2019 IEEE 4TH ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC), IEEE, vol. 1, 20 December 2019 (2019-12-20), pages 186 - 190, XP033715113, DOI: 10.1109/IAEAC47372.2019.8997573;;MARTINEZ LEONARDO ET AL: ""Map-based lane identification and prediction for autonomous vehicles"", IEEE INTERNATIONAL CONFERENCE ON ELECTRO/INFORMATION TECHNOLOGY, 1 June 2014 (2014-06-01), pages 448 - 453, XP093047558, ISBN: 978-1-4799-4774-4, Retrieved from the Internet <URL:https://ieeexplore.ieee.org/stampPDF/getPDF.jsp?tp=&arnumber=6871806&ref=aHR0cHM6Ly9pZWVleHBsb3JlLmllZWUub3JnL2Fic3RyYWN0L2RvY3VtZW50LzY4NzE4MDY=> DOI: 10.1109/EIT.2014.6871806",PENDING
50,EP,B1,EP 3853807 B1,113-580-712-319-433,2023-09-20,2023,EP 19801445 A,2019-10-18,US 201862748296 P;;US 201916242873 A;;US 2019/0056883 W,2018-10-19,GENERATION OF SYNTHETIC HIGH-ELEVATION DIGITAL IMAGES FROM TEMPORAL SEQUENCES OF HIGH-ELEVATION DIGITAL IMAGES,,MINERAL EARTH SCIENCES LLC,YANG JIE;;GUO CHENG-EN;;YUAN ZHIQIANG;;GRANT ELLIOTT;;MA HONGXU,MINERAL EARTH SCIENCES LLC (2023-04-19),https://lens.org/113-580-712-319-433,Granted Patent,yes,0,0,25,25,0,G06T3/4007;;G06Q10/04;;G06Q50/02;;A01B79/005;;G06N20/00;;G06N7/023;;G06N3/084;;G06T7/00;;G06T2207/10032;;G06T2207/20084;;G06T2207/20081;;G06T2207/30188;;G06T2207/30192;;G06T2207/10024;;G06T2207/20076;;G06V20/188;;G06V10/82;;G06N3/044;;G06N3/045;;Y02A40/10;;G06T7/0016;;A01D41/127;;G06T2207/10032;;G06T2207/10016;;G06T2207/20081;;G06T2207/20084;;G06T2207/20221;;G06T2207/30188;;G06T5/50;;G06T2207/10048;;G06T2207/30181;;G06T7/143;;G06N3/08;;G06Q10/04;;G06Q50/02;;G06V20/188;;G06V20/194;;G06N3/047;;G06T3/4007;;G06V10/82;;G06V20/13,G06Q10/04;;G06T7/00;;G06Q50/02,,2,0,,,"MALLESWARA RAO J ET AL: ""Spatiotemporal Data Fusion Using Temporal High-Pass Modulation and Edge Primitives"", IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING, IEEE SERVICE CENTER, PISCATAWAY, NJ, US, vol. 53, no. 11, 1 November 2015 (2015-11-01), pages 5853-5860, XP011665817, ISSN: 0196-2892, DOI: 10.1109/TGRS.2015.2422712 [retrieved on 2015-08-11];;ZHANG LEI ET AL: ""An evaluation of monthly impervious surface dynamics by fusing Landsat and MODIS time series in the Pearl River Delta, China, from 2000 to 2015"", REMOTE SENSING OF ENVIRONMENT, vol. 201, 1 November 2017 (2017-11-01), pages 99-114, XP085205162, ISSN: 0034-4257, DOI: 10.1016/J.RSE.2017.08.036",ACTIVE
51,EP,B1,EP 3707572 B1,025-693-346-359-427,2023-08-23,2023,EP 18816312 A,2018-11-09,US 201762584549 P;;US 2018/0060205 W,2017-11-10,SYSTEMS AND METHODS FOR SAFE AND RELIABLE AUTONOMOUS VEHICLES,,NVIDIA CORP,DITTY MICHAEL ALAN;;HICOK GARY;;SWEEDLER JONATHAN;;FARABET CLEMENT;;YOUSUF MOHAMMED ABDULLA;;CHAN T Y;;GANAPATHI RAM;;SRINIVASAN ASHOK;;TRUOG MIKE;;GREB KARL;;MATHIESON JOHN;;NISTER DAVID;;FLORY KEVIN;;PERRIN DANIEL;;HETTENA DAN,,https://lens.org/025-693-346-359-427,Granted Patent,yes,2,0,12,12,0,G05D1/0088;;G05D1/0248;;G06N3/063;;G06F15/7807;;Y02D10/00;;B60W60/0015;;B60W50/023;;B60W2050/0005;;G06N3/045;;G08G1/165;;G08G1/166;;B60W60/0027;;G05D1/0088;;G05D1/0248;;G05D1/0274;;G06F15/7807;;G06N3/063;;G06V20/58;;G06V20/588;;G06N3/045,G05D1/00;;B60W50/00;;B60W50/023;;B60W60/00;;G05D1/02;;G06F15/78;;G06N3/063,,0,0,,,,ACTIVE
52,EP,A1,EP 4227851 A1,089-123-777-390-570,2023-08-16,2023,EP 22155807 A,2022-02-09,EP 22155807 A,2022-02-09,CREATIVE WRITING ASSISTANCE,"A computer-implemented method for providing a creativity enhancing measure to a user to enhance a creativity level of a textual user input created by the user is provided. The method comprises receiving a digitized textual representation representing the textual user input. A creativity level of the textual user input is determined by applying one or more algorithms including semantic analysis to the digitized textual representation. If the creativity level of the textual user input is below a minimum creativity threshold level, a creativity enhancing measure is generated. In aspects, textual user input may encompass one or more letters, one or more words, one or more phrases and/or one or more sentences. Specifically, the textual user input may be created by the user using a writing instrument.",BIC VIOLEX SINGLE MEMBER SA,KOKOZIDIS MICHAIL,,https://lens.org/089-123-777-390-570,Patent Application,yes,3,0,2,2,0,G06F40/30;;G06F3/03545;;G09B5/02;;G09B5/04;;G09B19/00,G06F40/30,,0,0,,,,PENDING
53,EP,A1,EP 4224368 A1,011-374-522-592-88X,2023-08-09,2023,EP 21875083 A,2021-09-03,US 202063084776 P;;JP 2021032556 W,2020-09-29,"INFORMATION PROCESSING SYSTEM, AND INFORMATION PROCESSING METHOD","Functions can be flexibly changed according to various use cases. An information processing system according to an embodiment includes a sensor data acquisition unit that acquires sensing data acquired by a sensor, a processing unit including an inference unit that executes inference using the sensing data as an input, and a switching unit that switches the inference unit according to a use case.",SONY SEMICONDUCTOR SOLUTIONS CORP,SHIMOMURA MUNEHIRO;;MIYOSHI HIRONORI;;OGAWA YOSHIMI;;KUMAGAI YOSHIHIRO;;ANDO HIDEKI;;WATANABE SATOSHI,,https://lens.org/011-374-522-592-88X,Patent Application,yes,0,0,7,7,0,H04L63/0428;;H04L63/0876;;H04W4/38;;H04W4/02;;G06N3/09;;G06N3/0442;;G06N3/0464;;G06N3/045;;G06N3/063;;G06V10/82;;G06V10/44;;H04L67/12;;H04L67/34;;G06N3/096;;G06N3/09;;G06N3/045;;H04N7/18;;G06V10/7715;;G06V10/82;;G06V20/40;;G10L15/063;;G10L25/30;;H04L63/0428;;H04L12/1432;;G06N5/04,G06N3/02,,0,0,,,,PENDING
54,EP,A1,EP 4224434 A1,129-787-821-377-252,2023-08-09,2023,EP 22154886 A,2022-02-03,EP 22154886 A,2022-02-03,APPARATUS AND METHOD FOR EVALUATING A MACHINE LEARNING MODEL USED FOR ASSISTED OR AUTONOMOUS DRIVING OF A VEHICLE,"The present disclosure relates to evaluating a machine learning model (110) used for assisted or autonomous driving of a vehicle (300), the machine learning model (110) predicting one or more objects in proximity of the vehicle based on sensor data capturing the proximity of the vehicle. One or more areas (230) in the proximity of the vehicle (300) are determined which are safety-relevant for a current driving state or driving maneuver (210) of the vehicle. Predicted objects inside the one or more relevant areas (230) are assigned a higher computational weight than predicted objects outside the one or more relevant areas. A performance metric of the machine learning model (110) is calculated based on the weighted predicted objects in the proximity of the vehicle (300).",VOLKSWAGEN AG,VARGHESE SERIN;;SCHNEIDER JAN DAVID;;PHILIPP ROBIN,,https://lens.org/129-787-821-377-252,Patent Application,yes,0,0,1,1,0,G06V10/776;;G06V10/87;;G06V20/58,G06V10/776;;G06V10/70;;G06V20/58,,2,1,086-747-418-560-693,10.1109/iwssip48289.2020.9145130,"PADILLA RAFAEL ET AL: ""A Survey on Performance Metrics for Object-Detection Algorithms"", 2020 INTERNATIONAL CONFERENCE ON SYSTEMS, SIGNALS AND IMAGE PROCESSING (IWSSIP), IEEE, 1 July 2020 (2020-07-01), pages 237 - 242, XP033795995, DOI: 10.1109/IWSSIP48289.2020.9145130;;HOIEM DEREK ET AL: ""Diagnosing Error in Object Detectors"", 21 July 2020, ARXIV.ORG, PAGE(S) 340 - 353, XP047530688",PENDING
55,EP,B1,EP 3537867 B1,002-360-194-731-292,2023-08-02,2023,EP 17817016 A,2017-11-08,GB 201618809 A;;GB 2017053367 W,2016-11-08,A ROBOTIC FRUIT PICKING SYSTEM,,DOGTOOTH TECH LIMITED,ROBERTSON DUNCAN;;COOK MATTHEW;;HERBERT EDWARD;;TULLY FRANK,,https://lens.org/002-360-194-731-292,Granted Patent,yes,6,0,17,17,0,G05D1/0094;;A01G9/143;;A01D46/30;;Y02A40/25;;B25J5/005;;B25J9/0084;;B25J11/00;;B25J9/1697;;G05D1/0219;;A01D46/22;;A01D46/243;;A01D46/253;;A01D46/30;;B25J9/1679;;B25J9/1697;;B25J11/00;;B25J15/0019;;G05B2219/45003;;G06T7/50;;G06T7/11;;G06T7/90;;G06T7/70;;A01D46/28;;B25J9/0084;;B25J9/06;;B25J15/0033;;G06Q30/0283;;G06T7/0004;;G06T7/60;;G06T2207/10048;;G06T2207/20081;;G06T2207/20084;;G06T2207/30128;;A01G9/143;;Y02A40/25;;G06V20/10;;G06V20/68;;G06F18/2148;;G06F18/24323;;G06F18/24765,A01D46/30;;A01G9/14;;B25J5/00;;B25J9/00;;B25J9/16;;B25J11/00;;G05D1/00,,0,0,,,,ACTIVE
56,EP,A1,EP 4216053 A1,129-659-899-422-889,2023-07-26,2023,EP 22208464 A,2022-11-21,US 202117559804 A,2021-12-22,SIGNATURE-BASED AUTOMATIC OFFLOAD TO HARDWARE ACCELERATORS,"Technology to automatically recognize library functions and substitute accelerator calls can include scanning program code to detect one or more of a library signature or an accelerator tag, substituting an accelerator call for a library function tagged with the accelerator tag upon detecting the accelerator tag, and upon detecting the library signature, performing one of substituting the accelerator call for the library function associated with the library signature or applying the accelerator tag to the library function associated with the library signature to indicate the accelerator call is to be substituted for the library function. When the accelerator tag is applied to the library function associated with the library signature, a subsequent scan is to be performed to detect the applied tag and substitute the accelerator call for the library function tagged with the accelerator tag.",INTEL CORP,MILLAR DAMON,,https://lens.org/129-659-899-422-889,Patent Application,yes,1,0,3,3,0,G06F9/45558;;G06F2009/4557;;G06N3/04;;G06N3/063;;G06N3/08;;G06N10/00;;G06F8/4441;;G06F9/3887;;G06F9/3877;;G06F9/4881,G06F8/41,,1,0,,,"SHANE COOK: ""CUDA Programming"", 2013, pages: 37 - 51",PENDING
57,EP,A1,EP 4213062 A1,079-098-677-805-439,2023-07-19,2023,EP 23157096 A,2019-06-28,US 201862692621 P;;US 201816125644 A;;EP 19824678 A;;US 2019/0039909 W,2018-06-29,MANIPULATING ONE OR MORE FORMATION VARIABLES TO FORM THREE-DIMENSIONAL OBJECTS,"The present disclosure relates to generation of forming instructions to form one or more three-dimensional (3D) objects. Generation of the forming instructions may include selection of one or more formation variables to form at least a portion of the one or more 3D objects. Generation of the forming instructions may include selection of a speed, feature, and/or an effect manifested in at least a portion of the formed one or more 3D objects. The forming variable(s) may be associated with a surface patch and/or volume portion of a model of the 3D object.",VELO3D INC,BULLER BENYAMIN;;TSVETANOV TSVETAN;;RUSSEL DANIEL;;SMITH KYLE JOSEPH;;LAPPAS TASSO;;DZAMBAZOVA TATJANA;;COOL THOMAS C;;WOODCOCK GEOFFREY ERIC,,https://lens.org/079-098-677-805-439,Patent Application,yes,24,0,6,6,0,B33Y50/02;;B22F5/04;;B22F10/28;;B22F10/368;;B22F10/385;;B22F12/90;;B29C64/393;;B33Y80/00;;G05B19/4099;;G05B2219/35134;;G05B2219/49007;;G06F30/17;;G06F2113/10;;Y02P10/25;;Y02P90/02;;G05B19/4099;;B33Y30/00;;B33Y50/02;;G05B2219/35134;;G05B2219/49007,G06F30/17;;B22F5/00;;B22F5/04;;B22F10/28;;B22F10/368;;B22F10/38;;B29C64/386;;B29C64/393;;B33Y50/02;;B33Y80/00;;F01D5/14;;F01D9/04;;G05B19/4099;;G06F113/10,,0,0,,,,PENDING
58,EP,B1,EP 3961031 B1,045-235-619-888-744,2023-07-12,2023,EP 20192742 A,2020-08-25,EP 20192742 A,2020-08-25,"MONITORING SYSTEM FOR A WIND TURBINE BLADE, WIND TURBINE ARRANGEMENT AND METHOD FOR MONITORING OF A WIND TURBINE BLADE",,SIEMENS GAMESA RENEWABLE ENERGY AS,PONNADA RAJESH SRI MARKANDEYA,,https://lens.org/045-235-619-888-744,Granted Patent,yes,4,0,7,7,0,F03D17/00;;F03D80/30;;G01R29/08;;F03D17/00;;F03D80/30;;F05B2260/80;;F05B2260/83;;F05B2280/2006;;Y02E10/72;;F03D17/00;;F03D80/30;;F05B2260/80;;F05B2280/2006,F03D17/00;;F03D80/30,,0,0,,,,ACTIVE
59,EP,A1,EP 4210327 A1,016-535-720-957-874,2023-07-12,2023,EP 21871636 A,2021-09-26,CN 202011043931 A;;CN 2021120642 W,2020-09-28,INTRA FRAME PREDICTION METHOD AND DEVICE,"This application provides an intra prediction method and an apparatus. This application relates to the field of artificial intelligence (AI)-based video or picture compression technologies, and in particular, to the field of neural network-based video compression technologies. The method includes: obtaining respective intra prediction modes or texture distributions of P reconstructed picture blocks in a surrounding region of a current block; obtaining, based on the respective intra prediction modes or texture distributions of the P reconstructed picture blocks, Q priori candidate intra prediction modes of the current block and Q probability values; obtaining, based on M probability values corresponding to M priori candidate intra prediction modes, M weighting factors corresponding to the M priori candidate intra prediction modes; separately performing intra prediction based on the M priori candidate intra prediction modes to obtain M predicted values; and obtaining a predicted value of the current block based on a weighted summation of the M predicted values and the corresponding M weighting factors. This application can improve accuracy of intra prediction, reduce an error of intra prediction, and improve RDO efficiency of intra prediction.",HUAWEI TECH CO LTD,YANG HAITAO;;SONG NAN;;CHEN XU;;MA XIANG;;CHEN HUANBANG;;ZHAO YIN,,https://lens.org/016-535-720-957-874,Patent Application,yes,0,0,6,6,0,H04N19/176;;H04N19/11;;H04N19/593;;H04N19/149;;H04N19/11;;H04N19/136;;H04N19/159;;H04N19/172;;H04N19/176;;H04N19/42;;H04N19/593;;G06N3/08,H04N19/11,,0,0,,,,PENDING
60,EP,A1,EP 4207766 A1,019-170-314-650-789,2023-07-05,2023,EP 21874376 A,2021-09-26,CN 202011066451 A;;CN 2021120639 W,2020-09-30,ENTROPY ENCODING/DECODING METHOD AND DEVICE,"This application provides an entropy encoding/decoding method and apparatus; and relates to the field of artificial intelligence (AI)-based video or picture compression technologies, and in particular, to the field of neural network-based video compression technologies. The method includes: obtaining base layer information of a to-be-encoded picture block, where the base layer information corresponds to M samples in the picture block, and M is a positive integer; obtaining K elements corresponding to enhancement layer information of the picture block, where the enhancement layer information corresponds to N samples in the picture block, both K and N are positive integers, and N≥M; inputting the base layer information into a neural network to obtain K groups of probability values, where the K groups of probability values correspond to the K elements, and any group of probability values is for representing probabilities of a plurality of candidate values of a corresponding element; and performing entropy encoding on the K elements based on the K groups of probability values. This application can improve entropy encoding/decoding efficiency.",HUAWEI TECH CO LTD,MAO JUE;;YANG HAITAO;;MA XIANG,,https://lens.org/019-170-314-650-789,Patent Application,yes,0,0,7,7,0,H04N19/91;;G06N3/0464;;G06N3/048;;G06N3/0455;;G06N3/047;;G06N3/088;;G06N3/044;;G06N3/084;;G06N3/0475;;G06N3/094;;H04N19/30;;H04N19/13;;H04N19/132;;H04N19/172;;H04N19/176;;H04N19/42;;H04N19/50;;H04N19/70;;H04N19/91,H04N19/91,,0,0,,,,PENDING
61,EP,A2,EP 4201776 A2,147-500-661-574-709,2023-06-28,2023,EP 22212591 A,2022-12-09,US 202117560405 A,2021-12-23,DRIVER SCORING SYSTEM AND METHOD USING OPTIMUM PATH DEVIATION,"Techniques are disclosed to determine driver scoring that consider deviations in map and sensor data in driver score computations. The deviations can be based on deviations from an optimum driving path (520), and include the determination of vectors between a reference point (530) and one or more landmarks (502, 504, 506, 508.1, 508.2, 510, 512, 514, 516), and one or more reference vectors between the reference point the landmark(s) when traveling on an optimum driving path. A difference between the vectors may then be used determine the deviations from the optimum driving path. In contrast to the conventional approaches, the use of positional deviations (e.g. determined from road markings) in the computation of driver scores allows for improved driver scoring techniques and driver characterizations.",INTEL CORP,LAWRENCE SEAN J W;;BHAT RAGHAVENDRA;;CHANDRAN PRAVIN CHANDER,,https://lens.org/147-500-661-574-709,Patent Application,yes,0,0,4,4,0,G01C21/3415;;G01C21/3461;;G01C21/3476;;G01C21/28;;B60W40/09;;B60W2420/403;;B60W2552/53;;B60W2554/801;;B60W2556/45;;B60W2556/50;;G01C21/3602;;G06V20/56;;B60W60/001;;B60W30/18109;;B60W2420/403;;B60W2554/4041;;G01C21/3476;;G01C21/3896,B60W40/09,,0,0,,,,PENDING
62,EP,A1,EP 4194924 A1,020-566-076-430-663,2023-06-14,2023,EP 21853895 A,2021-07-29,JP 2020131465 A;;JP 2021028178 W,2020-08-03,SLIT-LAMP MICROSCOPE,"An exemplary embodiment of a slit-lamp microscope (1) includes an image acquisition unit (illumination system (2), imaging system (3), and movement mechanism (6)), a storage unit (10), and a misregistration information acquisition unit. The image acquisition unit scans the anterior ocular segment of a subject eye (E) to acquire an image. The storage unit (10) stores a first image of the anterior ocular segment of the subject eye (E), and a second image acquired in follow-up imaging performed by the image acquisition unit with reference to the first image. The misregistration information acquisition unit analyzes the first image and the second image after the follow-up imaging is performed, and acquires information relating to misregistration between the first image and the second image.",TOPCON CORP,TSUKADA HISASHI,,https://lens.org/020-566-076-430-663,Patent Application,yes,0,0,5,5,0,A61B3/135;;A61B3/0025;;G02B21/0012;;G02B21/082;;G02B21/36;;G06T7/0014;;G06T7/30;;G06T2207/20081;;G06T2207/20084;;G06T2207/30041;;A61B3/135;;A61B3/12;;A61B3/145;;G02B21/36,G02B21/06;;A61B3/135;;A61B3/14;;G02B21/36;;G06T7/32,,1,0,,,See references of WO 2022030364A1,PENDING
63,EP,A1,EP 4194985 A1,134-690-308-780-227,2023-06-14,2023,EP 21213524 A,2021-12-09,EP 21213524 A,2021-12-09,"AUTONOMOUS BOT CONTROL FOR PLANT INSPECTION, CONTROL AND REPAIR","The present invention generally relates to a method for controlling an autonomous bot (100) configured for unmanned plant inspection and repair operations or for controlling the unmanned plant (200). The invention further relates to an autonomous bot, to a system comprising a set of autonomous bots, and an unmanned floating production storage and offloading plant operative offshore on which the autonomous bots are deployed, and to a computer program.",ABB SCHWEIZ AG,LINGE SIMON;;SHARMA DIVYASHEEL;;RODRIGUEZ PABLO;;BERNING MATTHIAS;;KLOEPPER BENJAMIN;;BORRISON REUBEN;;DIX MARCEL;;SCHMIDT BENEDIKT;;ABUKWAIK HADIL;;KOTRIWALA ARZAM;;MACZEY SYLVIA;;ZIOBRO DAWID;;GAERTLER MARCO;;DOPPELHAMER JENS;;K R CHANDRIKA;;GOPALAKRISHNAN GAYATHRI,,https://lens.org/134-690-308-780-227,Patent Application,yes,4,0,1,1,0,B63B79/10;;B63B79/15;;G05B23/0283;;G05B2219/39413;;G05B2219/45066;;G05D1/0055;;G05D1/0055,G05D1/00,,0,0,,,,DISCONTINUED
64,EP,A1,EP 4187491 A1,174-058-524-891-839,2023-05-31,2023,EP 22207340 A,2022-11-14,US 202163282814 P;;US 202217951281 A,2021-11-24,SYSTEM AND METHOD FOR VISUALIZING PLACEMENT OF A MEDICAL TUBE OR LINE,"An image processing system is provided. The image processing system includes a display, a processor, and a memory. The memory stores processor-executable code that when executed by the processor causes receiving an image of a region of interest of a patient with an enteric tube or line disposed within the region of interest, detecting the medical tube or line within the image, generating a combined image by superimposing graphical markers on the image that indicate placement or misplacement of the enteric tube or line, and displaying the combined image on a display. In further aspects, a classification of the enteric tube or line (e.g., correctly placed tube present, malpositioned tube present, and so forth) may be determined and communicated to one or more clinicians. Additionally, the outputs of the image processing system may also be provided to facilitate triage of patients, helping prioritize which tube placements require further attention and in what order.",GE PREC HEALTHCARE LLC,TEGZES PAL;;HERCZEG ZITA;;TAN TAO;;CZIRIA BALAZS PETER;;BAENEN ALEC JOSEPH;;RAO GIREESHA CHINTHAMANI;;FERENCZI LEHEL;;AVINASH GOPAL BILIGERI;;KISS ZOLTAN;;YANG HONGXU;;HECKEL BETH ANN,,https://lens.org/174-058-524-891-839,Patent Application,yes,0,0,3,4,0,G16H30/20;;G06N3/08;;G06T11/60;;G06T11/00;;G06T7/0012;;G06T2207/20081;;G16H50/20,G06T11/00,,5,5,001-665-914-497-731;;034-378-224-661-026;;053-762-322-108-860;;083-176-219-034-070;;017-207-066-821-959,10.1007/s10278-021-00495-6;;34322753;;pmc8455789;;10.1109/isbi48211.2021.9434022;;pmc8017400;;10.1148/ryai.2020190082;;33937813;;34027589;;10.1007/s10278-021-00463-0;;pmc8455772;;10.1109/icaicst53116.2021.9497809,"HARRIS ROBERT J ET AL: ""Measurement of Endotracheal Tube Positioning on Chest X-Ray Using Object Detection"", JOURNAL OF DIGITAL IMAGING, SPRINGER INTERNATIONAL PUBLISHING, CHAM, vol. 34, no. 4, 28 July 2021 (2021-07-28), pages 846 - 852, XP037568368, ISSN: 0897-1889, [retrieved on 20210728], DOI: 10.1007/S10278-021-00495-6;;SIRAZITDINOV ILYAS ET AL: ""Landmark Constellation Models For Central Venous Catheter Malposition Detection"", 2021 IEEE 18TH INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), IEEE, 13 April 2021 (2021-04-13), pages 1132 - 1136, XP033917816, DOI: 10.1109/ISBI48211.2021.9434022;;YI XIN ET AL: ""Computer-aided Assessment of Catheters and Tubes on Radiographs: How Good Is Artificial Intelligence for Assessment?"", RADIOLOGY: ARTIFICIAL INTELLIGENCE, vol. 2, no. 1, 29 January 2020 (2020-01-29), pages 1 - 9, XP093038794, Retrieved from the Internet <URL:https://pubs.rsna.org/doi/epdf/10.1148/ryai.2020190082> DOI: 10.1148/ryai.2020190082;;KARA SU ET AL: ""Identification and Localization of Endotracheal Tube on Chest Radiographs Using a Cascaded Convolutional Neural Network Approach"", JOURNAL OF DIGITAL IMAGING, SPRINGER INTERNATIONAL PUBLISHING, CHAM, vol. 34, no. 4, 23 May 2021 (2021-05-23), pages 898 - 904, XP037568390, ISSN: 0897-1889, [retrieved on 20210523], DOI: 10.1007/S10278-021-00463-0;;KHAN ABDUL BASEER MOHAMMED ET AL: ""Early Detection of Malpositioned Catheters and Lines on Chest X-Rays using Deep Learning"", 2021 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTER SCIENCE TECHNOLOGY (ICAICST), IEEE, 29 June 2021 (2021-06-29), pages 51 - 55, XP033950323, DOI: 10.1109/ICAICST53116.2021.9497809",PENDING
65,EP,A1,EP 4183333 A1,183-363-094-586-443,2023-05-24,2023,EP 21842607 A,2021-07-15,JP 2020123208 A;;JP 2021026658 W,2020-07-17,"BRAIN FUNCTIONAL CONNECTIVITY CORRELATION VALUE CLUSTERING DEVICE, BRAIN FUNCTIONAL CONNECTIVITY CORRELATION VALUE CLUSTERING SYSTEM, BRAIN FUNCTIONAL CONNECTIVITY CORRELATION VALUE CLUSTERING METHOD, BRAIN FUNCTIONAL CONNECTIVITY CORRELATION VALUE CLASSIFIER PROGRAM, AND BRAIN ACTIVITY MARKER CLASSIFICATION SYSTEM","There is provided a therapy selection support device that generates a discriminator (identifier) as a diagnostic marker or a classifier as a stratification marker through machine learning on the basis of measurement data on brain activities and that uses the discriminator or the classifier as a biomarker.A therapy selection support system 300a, 300b, 500 includes a clustering device 300b that executes stratification in which the results of measurement of brain functional connectivity correlation values acquired from a plurality of second subjects are divided into a plurality of clusters through a clustering process. The therapy selection support system further includes: a database device 5100 that stores clusters obtained as a result of stratification by a clustering classifier and corresponding predetermined therapy information in association with each other; and a support information providing device 300a that receives an input of the results of measurement of brain activities of a first subject and that outputs corresponding therapy information in accordance with the results of classification by the clustering classifier for the measurement results.",ADVANCED TELECOMMUNICATIONS RES INSTITUTE INTERNATIONAL;;UNIV HIROSHIMA;;SHIONOGI & CO,KASHIWAGI YUTO;;TOKUDA TOMOKI;;TAKAHARA YUJI;;KAWATO MITSUO;;YAMASHITA AYUMU;;YAMASHITA OKITO;;SAKAI YUKI;;YOSHIMOTO JUNICHIRO;;OKADA GO,,https://lens.org/183-363-094-586-443,Patent Application,yes,0,0,6,6,0,G06T7/0012;;A61B5/0042;;A61B5/055;;A61B5/165;;G06T2207/10088;;G06T2207/20081;;G06T2207/30016;;G16H20/00;;G16H20/10;;G16H20/70;;G16H50/20;;G16H50/70;;A61B5/7267;;G06N20/00;;G16H20/10,A61B5/055;;A61B5/05;;A61B5/372;;G06T7/00,,0,0,,,,PENDING
66,EP,B1,EP 3937077 B1,142-824-786-632-22X,2023-05-24,2023,EP 21181451 A,2021-06-24,CN 202011488643 A,2020-12-16,"LANE MARKING DETECTING METHOD, APPARATUS, ELECTRONIC DEVICE, STORAGE MEDIUM, AND VEHICLE",,APOLLO INTELLIGENT CONNECTIVITY BEIJING TECHNOLOGY CO LTD,HE GANG,,https://lens.org/142-824-786-632-22X,Granted Patent,yes,1,0,9,9,0,G06V20/46;;G06V20/41;;G06V20/588;;G06F18/214;;G06V20/46;;G06V20/588;;G06V10/82;;G06V10/764;;G06V10/774;;G06V20/588;;G06T7/73;;G06N3/04;;G06T2207/10016;;G06V20/588;;G06V20/46;;G06F18/214;;G06V10/764;;G06V10/774;;G06V10/82,G06V10/764;;G06V10/774;;G06V10/82;;G06V20/56,,1,1,061-702-102-263-987,10.1109/itsc.2018.8569387,"DAI DENGXIN ET AL: ""Dark Model Adaptation: Semantic Image Segmentation from Daytime to Nighttime"", 2018 21ST INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), IEEE, 4 November 2018 (2018-11-04), pages 3819 - 3824, XP033470035, ISBN: 978-1-7281-0321-1, [retrieved on 20181207], DOI: 10.1109/ITSC.2018.8569387",ACTIVE
67,EP,A1,EP 4177741 A1,034-099-875-435-733,2023-05-10,2023,EP 21876008 A,2021-09-28,KR 20210103061 A;;IN 202041042555 A;;KR 2021013283 W,2020-09-30,ELECTRONIC DEVICE AND CONTROL METHOD THEREOF,"An electronic device is provided. The electronic device includes a memory, a user interface, and at least one processor. The at least one processor is configured to determine an optimal domain from a plurality of domains based on a current context, combine the current context and a historical context of the optimal domain to determine a combined context, determine an optimal feature from a plurality of features based on the combined context and a parameter of the optimal domain, and control the user interface to output a recommendation message for the optimal feature.",SAMSUNG ELECTRONICS CO LTD,MISHRA ABHISHEK;;KASARANENI SAI HEMANTH;;ARORA MANALI;;RANJAN SAHOO MANAS,,https://lens.org/034-099-875-435-733,Patent Application,yes,0,0,3,5,0,G06F16/9035;;G06F9/451;;G06F9/54;;G06F11/34;;G06F16/9038;;G06N3/044;;G06N3/045;;G06N3/08;;G06N7/01;;G06N20/00;;H04M1/6066;;H04M1/72454;;H04M2250/52;;H04N23/60;;G06N7/01;;G06F18/2113;;G06F18/2415;;G06V10/768,G06F9/451;;G06F9/54;;G06F11/34;;G06F16/332;;G06N20/00,,0,0,,,,PENDING
68,EP,A1,EP 4170553 A1,036-138-367-897-538,2023-04-26,2023,EP 22186932 A,2022-07-26,US 202117505568 A,2021-10-19,FRAMEWORK FOR OPTIMIZATION OF MACHINE LEARNING ARCHITECTURES,"The present disclosure is related to framework for automatically and efficiently finding machine learning (ML) architectures that are optimized to one or more specified performance metrics and/or hardware platforms. This framework provides ML architectures that are applicable to specified ML domains and are optimized for specified hardware platforms in significantly less time than could be done manually and in less time than existing ML model searching techniques. Furthermore, a user interface is provided that allows a user to search for different ML architectures based on modified search parameters, such as different hardware platform aspects and/or performance metrics. Other embodiments may be described and/or claimed.",INTEL CORP,SARAH ANTHONY;;CUMMINGS DANIEL;;MUNOZ JUAN PABLO;;WEBB TRISTAN,,https://lens.org/036-138-367-897-538,Patent Application,yes,4,0,3,3,0,G06N3/082;;G06N3/044;;G06N3/045;;G06N3/047;;G06N3/065;;G06N3/084;;G06N3/086;;G06N3/12;;G06N7/01;;G06F16/953;;G06N5/027,G06N3/08;;G06N3/04;;G06N3/063;;G06N3/12;;G06N7/00,,19,5,052-266-529-374-833;;000-541-797-292-217;;010-778-106-333-496;;032-433-467-838-54X;;165-785-715-835-180,17388777;;10.1162/evco.2007.15.1.1;;10.1109/4235.996017;;12180173;;10.1162/106365602320169811;;10.1088/1742-6596/1288/1/012057;;10.1007/978-3-662-44874-8,"ABDELFATTAH ET AL.: ""Zero-Cost Proxies for Lightweight NAS"", ARXIV, 20 January 2021 (2021-01-20);;LIU ET AL.: ""DARTS: Differentiable Architecture Search"", ARXIV:1806.09055V2, 23 April 2019 (2019-04-23);;CAI ET AL.: ""Once-for-All: Train One Network and Sepcialize it for Efficient Deployment"", ARXIV:1908.09791V5, 29 April 2020 (2020-04-29);;CAI ET AL.: ""ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware"", ARXIV:1812.00332V2, 23 February 2019 (2019-02-23);;WANG ET AL.: ""HAT: Hardware-Aware Transformers for Efficient Natural Language Processing"", ARXIV:2005.14187VL, 28 May 2020 (2020-05-28);;MELLOR ET AL.: ""Neural Architecture Search without Training"", INT'L CONFERENCE ON MACHINE LEARNING, 1 July 2021 (2021-07-01), pages 7588 - 7598;;IGEL ET AL.: ""Covariance Matrix Adaptation for Multi-objective Optimization"", EVOLUTIONARY COMPUTATION, vol. 15, no. 1, 1 March 2007 (2007-03-01), pages 1 - 28, XP058148006, DOI: 10.1162/evco.2007.15.1.1;;DEB ET AL.: ""A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II"", IEEE TRANSACTIONS ON EVOLUTIONARY COMPUTATION, vol. 6, no. 2, April 2002 (2002-04-01), XP011072884, DOI: 10.1109/4235.996017;;STANLEY ET AL.: ""Evolving Neural Networks Through Augmented Topologies"", EVOLUTIONARY COMPUTATION, vol. 10, no. 2, 10 June 2002 (2002-06-10), pages 99 - 127;;HUANG ET AL.: ""Survey on Multi-Objective Evolutionary Algorithms"", IOP CONF. SERIES: J. OF PHYSICS: CONF. SERIES, vol. 1288, no. 1, 1 August 2019 (2019-08-01), pages 012057;;TAN ET AL.: ""EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"", ARXIV:1905.11946V5, 11 September 2020 (2020-09-11);;BERGSTRA ET AL.: ""Random Search for Hyper-Parameter Optimization"", J. OF MACHINE LEARNING RESEARCH, vol. 13, 1 February 2012 (2012-02-01), XP055293358;;EIBEN ET AL.: ""Introduction to evolutionary computing"", 2015, SPRINGER;;DEWANCKER ET AL.: ""Bayesian Optimization for Machine Learning: A Practical Guidebook"", ARXIV: 1612.04858, 14 December 2016 (2016-12-14);;SNOEK ET AL.: ""Practical Bayesian Optimization of Machine Learning Algorithms"", ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS, vol. 25, 29 August 2012 (2012-08-29);;BERGSTRA ET AL.: ""Algorithms for Hyper-Parameter Optimization"", ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS, vol. 24, 2011;;ZITZLER ET AL.: ""Technical Report 103"", May 2001, SWISS FEDERAL INSTITUTE OF TECHNOLOGY (ETH) ZURIC, article ""SPEA2: Improving the Performance of the Strength Pareto Evolutionary Algorithm"";;JAVADI ET AL.: ""Combining Manhattan and Crowding distances in Decision Space for Multimodal Multi-objective Optimization Problems"", EUROGEN 2019, 12 September 2019 (2019-09-12);;NASER ET AL.: ""Insights into Performance Fitness and Error Metrics for Machine Learning"", ARXIV:2006.00887VL, 17 May 2020 (2020-05-17)",PENDING
69,EP,A1,EP 4170427 A1,094-344-911-984-311,2023-04-26,2023,EP 21826892 A,2021-05-13,JP 2020104223 A;;JP 2021018134 W,2020-06-17,SLIT LAMP MICROSCOPE,"A slit lamp microscope 1 according to an exemplary embodiment includes a scanning unit (lighting system 2, imaging system 3, and movement mechanism 6), an image group evaluation unit 81 (data processing unit 8), and a control unit 7. The scanning unit scans, with slit light, an anterior eye part of an eye E being inspected, and collects an image group. The image group evaluation unit 81 evaluates the quality of the image group collected by the scanning unit. The control unit 7 selectively executes two or more prescribed controls in accordance with the quality evaluation result acquired by a first evaluation unit. For example, the control unit 7 performs a control for applying a new scan to the anterior eye part when the quality is evaluated to be unsatisfactory, and performs a control for transmitting the image group to an external device when the quality is evaluated to be satisfactory.",TOPCON CORP,SHIMIZU HITOSHI;;OMORI KAZUHIRO;;TSUKADA HISASHI,,https://lens.org/094-344-911-984-311,Patent Application,yes,0,0,5,5,0,A61B3/135;;G02B21/082;;G02B21/367;;A61B3/135;;A61B3/117,G03B35/02;;A61B3/135;;G02B21/06;;G02B21/36;;H04N13/388,,1,0,,,See references of WO 2021256130A1,PENDING
70,EP,A1,EP 4169683 A1,095-946-132-493-913,2023-04-26,2023,EP 22202201 A,2022-10-18,IT 202100027284 A,2021-10-22,TRAINING DATASET GENERATION FOR TRAINING AN ARTIFICIAL NEURAL NETWORK CONFIGURED TO DETECT CHARACTERISTICS OF TIMBER BOARDS,"A computer-implemented method for generating a training dataset for training an artificial neural network configured to use images of lateral faces of a timber board to provide information about structure and/or defects, the method including:a log generation step during which a virtual model of a log is generated;a sawing step of the virtual model to obtain one or more virtual timber boards;a pattern step during which a surface pattern is determined as the intersection between the virtual lateral face and the internal structure and/or defects;a rendering step during which a rendered surface image of the lateral face of the virtual timber board is created; andan input data generation step during which the rendered surface images are used to create one or more item of input data;an output data generation step during which an item of output data is generated; anda population step during which a record is added to the training dataset comprising the item of input data, in combination with the item of output data.",MICROTEC AB,HABITE TADIOS;;ABDELJABER OSAMA;;OLSSON ANDERS,,https://lens.org/095-946-132-493-913,Patent Application,yes,0,0,4,4,0,G06V10/82;;B27B1/007;;G01N21/8986;;G01N2021/8883;;G06V10/774;;G06N3/08,B27B1/00;;G01N21/898;;G06V10/774;;G06V10/82,,25,18,016-442-979-664-39X;;029-724-849-468-697;;060-751-356-436-125;;032-446-828-466-044;;094-118-252-936-272;;094-887-046-021-414;;024-938-395-873-971;;032-393-661-572-884;;067-184-205-951-660;;084-287-840-948-362;;024-018-514-103-856;;012-848-994-668-684;;030-346-147-617-360;;081-823-394-535-177;;058-824-459-053-250;;026-853-808-556-49X;;035-603-945-397-477;;060-751-356-436-125,10.1109/ispa.2009.5297696;;10.1016/j.compag.2020.105795;;10.1007/s00226-021-01266-w;;10.1016/j.conbuildmat.2022.127129;;10.1051/forest:19980306;;10.1007/s002260050126;;10.1016/j.matdes.2019.107617;;10.1007/s00107-016-1102-6;;10.1007/s00107-018-1348-2;;10.1007/s00107-016-1049-7;;10.1016/j.conbuildmat.2016.08.001;;10.1016/j.conbuildmat.2018.03.021;;10.1007/s00107-020-01558-1;;10.22382/wfs-2018-053;;10.1109/tsp.2012.2210890;;10.1137/s1052623496303470;;10.1109/cvpr.2017.632;;10.1007/s00226-021-01266-w,"KRISTIN NORELL: ""Creating synthetic log end face images"", IMAGE AND SIGNAL PROCESSING AND ANALYSIS, 2009. ISPA 2009. PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON, 16 September 2009 (2009-09-16), IEEE, PISCATAWAY, NJ, USA, pages 353 - 358, XP031552041, ISBN: 978-953-184-135-1;;BHANDARKAR S M ET AL: ""A computer vision system for lumber production planning"", APPLICATIONS OF COMPUTER VISION, 19 October 1998 (1998-10-19), IEEE, LOS ALAMITOS, CA, USA, pages 134 - 139, XP010315599, ISBN: 978-0-8186-8606-1, DOI: 10.1109/ACV.1998.732870;;ZOLOTAREV FEDOR ET AL: ""Modelling internal knot distribution using external log features"", COMPUTERS AND ELECTRONICS IN AGRICULTURE, vol. 179, 12 October 2020 (2020-10-12), ELSEVIER, AMSTERDAM, NL, XP086377297, ISSN: 0168-1699, [retrieved on 20201012], DOI: 10.1016/J.COMPAG.2020.105795;;HABITE TADIOS ET AL: ""Automatic detection of annual rings and pith location along Norway spruce timber boards using conditional adversarial networks"", WOOD SCIENCE AND TECHNOLOGY, vol. 55, no. 2, 2 March 2021 (2021-03-02), Springer, Germany, pages 461 - 488, XP037411986, ISSN: 0043-7719, DOI: 10.1007/S00226-021-01266-W;;HABITE TADIOS ET AL: ""Determination of pith location along Norway spruce timber boards using one dimensional convolutional neural networks trained on virtual timber boards"", CONSTRUCTION AND BUILDING MATERIALS, vol. 329, 21 March 2022 (2022-03-21), ELSEVIER, NETHERLANDS, XP087008382, ISSN: 0950-0618, [retrieved on 20220321], DOI: 10.1016/J.CONBUILDMAT.2022.127129;;KLIGER, I. R.PERSTORPER, M.JOHANSSON, G.: ""Bending properties of Norway spruce timber. Comparison between fast-and slow-grown stands and influence of radial position of sawn timber"", ANNALES DES SCIENCES FORESTIERES, vol. 55, no. 3, 1998, pages 349 - 358;;JOHANSSON, C. J., TIMBER ENGINEERING, 1998;;BLOUIN, D.BEAULIEU, J.DAOUST, G.POLIQUIN, J.: ""Wood quality of Norway spruce grown in plantations in Quebec"", WOOD AND FIBER SCIENCE, vol. 26, no. 3, 2007, pages 342 - 353;;ORMARSSON, S.DAHLBLOM, 0.PETERSSON, H.: ""A numerical study of the shape stability of sawn timber subjected to moisture variation: Part 2: Simulation of drying board"", WOOD SCIENCE AND TECHNOLOGY, vol. 33, no. 5, 1999, pages 407 - 423, XP002437383, DOI: 10.1007/s002260050126;;HU, M.OLSSON, A.JOHANSSON, M.OSCARSSON, J.SERRANO, E.: ""Assessment of a three-dimensional fiber orientation model for timber"", WOOD AND FIBER SCIENCE, vol. 48, no. 4, 2016, pages 271 - 290;;LUKACEVIC, M.KANDLER, G.HU, M.OLSSON, A.FÜSSL, J.: ""A 3D model for knots and related fiber deviations in sawn timber for prediction of mechanical properties of boards"", MATERIALS & DESIGN, vol. 166, 2019, pages 107617;;OLSSON, A.OSCARSSON, J.: ""Strength grading on the basis of high resolution laser scanning and dynamic excitation: a full scale investigation of performance"", EUROPEAN JOURNAL OF WOOD AND WOOD PRODUCTS, vol. 75, no. 1, 2017, pages 17 - 31, XP036134004, DOI: 10.1007/s00107-016-1102-6;;M. HUA. OLSSONM. JOHANSSONJ. OSCARSSON: ""Modelling local bending stiffness based on fibre orientation in sawn timber"", EUROPEAN JOURNAL OF WOOD AND WOOD PRODUCTS, vol. 76, no. 6, 2018, pages 1605 - 1621, XP036611766, DOI: 10.1007/s00107-018-1348-2;;BRIGGERT, A.OLSSON, A.OSCARSSON, J.: ""Three-dimensional modelling of knots and pith location in Norway spruce boards using tracheid-effect scanning"", EUROPEAN JOURNAL OF WOOD AND WOOD PRODUCTS, vol. 74, no. 5, 2016, pages 725 - 739, XP036020879, DOI: 10.1007/s00107-016-1049-7;;KANDLER, G.LUKACEVIC, M.FÜSSL, J.: ""An algorithm for the geometric reconstruction of knots within timber boards based on fibre angle measurements"", CONSTRUCTION AND BUILDING MATERIALS, vol. 124, 2016, pages 945 - 960, XP029750939, DOI: 10.1016/j.conbuildmat.2016.08.001;;PERLIN, L. P., DO VALLE, Å., & DE ANDRADE PINTO, R. C.: ""New method to locate the pith position in a wood cross-section based on ultrasonic measurements"", CONSTRUCTION AND BUILDING MATERIALS, vol. 169, 2018, pages 733 - 739;;HABITE, T.OLSSON, A.OSCARSSON, J.: ""Automatic detection of pith location along Norway spruce timber boards on the basis of optical scanning"", EUR. J. WOOD PROD., vol. 78, 2020, pages 1061 - 1074, XP037269187, Retrieved from the Internet <URL:https://doi.org/10.1007/s00107-020-01558-1> DOI: 10.1007/s00107-020-01558-1;;BRIGGERT, A., HU, M., OLSSON, A., & OSCARSSON, J.: ""Tracheid effect scanning and evaluation of in-plane and out-of-plane fibre direction in Norway spruce using"", WOOD AND FIBER SCIENCE, vol. 50, no. 4, 2018, pages 411 - 429;;LILLY, J.M.OLHEDE, S.C.: ""Generalized Morse wavelets as a superfamily of analytic wavelets"", IEEE TRANSACTIONS ON SIGNAL PROCESSING, vol. 60, no. 11, 2012, pages 6036 - 6041, XP011480516, DOI: 10.1109/TSP.2012.2210890;;LAGARIAS, J.C.REEDS, J.A.WRIGHT, M.H.WRIGHT, P.E.: ""Convergence properties of the Nelder-Mead simplex method in low dimensions"", SIAM JOURNAL ON OPTIMIZATION, vol. 9, no. 1, 1998, pages 112 - 147;;SÄLL, H.: ""Doctoral dissertation"", 2002, VAXJO UNIVERSITY PRESS, article ""Spiral grain in Norway spruce"";;ISOLA, P.ZHU, J. Y.ZHOU, T.EFROS, A. A.: ""Image-to-image translation with conditional adversarial networks"", PROCEEDINGS OF THE IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, 2017, pages 1125 - 1134, XP055972425, DOI: 10.1109/CVPR.2017.632;;HABITE, T.ABDELJABER, O.OLSSON, A.: ""Automatic detection of annual rings and pith location along Norway spruce timber boards using conditional adversarial networks"", WOOD SCI TECHNOL, vol. 55, 2021, pages 461 - 488, XP037411986, Retrieved from the Internet <URL:https://doi.org/10.1007/s00226-021-01266-W> DOI: 10.1007/s00226-021-01266-w;;KINGMA, D. P.,BA, J.: ""Adam: A method for stochastic optimization"", ARXIV PREPRINT ARXIV:1412.6980, 2014;;TEAM, P. C.: ""Python: a dynamic, open source programming language"", PYTHON SOFTWARE FOUNDATION, 2019",PENDING
71,EP,A1,EP 4167195 A1,169-692-796-163-509,2023-04-19,2023,EP 21202896 A,2021-10-15,EP 21202896 A,2021-10-15,PERSONAL DATA PROCESSING SYSTEM,"Personal data processing system comprising a first device configured to capture image data including facial image data of a human being; the first device further configured to detect the facial image data of a human being, to determine a descriptor including information describing a characteristic of a mimic expression feature and a characteristic of each identification feature of a selectable subset of the plurality of identification features; the first device further configured to provide an obfuscated image with placeholder data replacing the facial image data; the first device further configured to provide the obfuscated image and the descriptor to a second device; the second device configured to perform a replacement of the placeholder data with artificial facial image data corresponding to the descriptor to produce an anonymized image.",BRIGHTER AI TECH GMBH,STROTTNER THOMAS;;CONEYS SEAN;;SUKMANOVA ELENA;;YOUN SINA;;CHATTERJEE SREENJOY;;GLÄSER MARIAN,,https://lens.org/169-692-796-163-509,Patent Application,yes,0,0,2,2,0,G06V10/95;;G06V40/161;;G06V40/176,G06V10/94;;G06V40/16,,8,5,069-651-659-807-383;;103-150-168-121-737;;093-667-357-958-326;;028-779-103-186-88X;;016-235-063-143-293,10.1109/icdcsw53096.2021.00009;;10.1109/iccv.2019.00728;;10.1109/tpami.2022.3155571;;35471874;;10.1016/j.eswa.2018.01.023;;10.1109/cvpr.2017.145;;10.1109/cvpr.2016.144,"LACHNER CLEMENS ET AL: ""Towards Understanding the Adaptation Space of AI-Assisted Data Protection for Video Analytics at the Edge"", 2021 IEEE 41ST INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS (ICDCSW), IEEE, 7 July 2021 (2021-07-07), pages 7 - 12, XP033978024, DOI: 10.1109/ICDCSW53096.2021.00009;;KAIPENG ZHANG, ZHANPENG ZHANG, ZHIFENG LI, YU QIAO: ""Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks"", ARXIV:1604.02878, 2016;;JIANZHU GUOXIANGYU ZHUYANG YANGFAN YANGZHEN LEISTAN Z. LI: ""Towards Fast, Accurate and Stable 3D Dense Face Alignment"", ARXIV:2009.09960, 2020;;YUVAL NIRKINYOSI KELLERTAL HASSNER: ""FSGAN: Subject Agnostic Face Swapping and Reenactment"", ARXIV:1908.05932V1, 2019;;HAKON HUKKELASRUDOLF MESTERFRANK LINDSETH: ""DeepPrivacy: A Generative Adversarial Network for Face Anonymization"", ARXIV:1909.04538, 2019, Retrieved from the Internet <URL:https://dblp.org/rec/journals/corr/abs-1909-04538.bib>;;SOLEYMANI, ROGHAYEHERIC GRANGERGIORGIO FUMERA: ""Progressive boosting for class imbalance and its application to face re-identification"", EXPERT SYSTEMS WITH APPLICATIONS, vol. 101, 2018, pages 271 - 291;;CHEN, WEIHUA ET AL.: ""Beyond triplet loss: a deep quadruplet network for person re-identification"", PROCEEDINGS OF THE IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, 2017;;WANG, FAQIANG ET AL.: ""Joint learning of single-image and cross-image representations for person re-identification"", PROCEEDINGS OF THE IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, 2016",DISCONTINUED
72,EP,A1,EP 4163833 A1,130-829-161-936-132,2023-04-12,2023,EP 22186944 A,2022-07-26,US 202117497736 A,2021-10-08,DEEP NEURAL NETWORK MODEL DESIGN ENHANCED BY REAL-TIME PROXY EVALUATION FEEDBACK,"The present disclosure is related to artificial intelligence (AI), machine learning (ML), and Neural Architecture Search (NAS) technologies, and in particular, to Deep Neural Network (DNN) model engineering techniques that use proxy evaluation feedback. The DNN model engineering techniques discussed herein provide near real-time feedback on model performance via low-cost proxy scores without requiring continual training and/or validation cycles, iterations, epochs, etc. In conjunction with the proxy-based scoring, semi-supervised learning mechanisms are used to map proxy scores to various model performance metrics. Other embodiments may be described and/or claimed.",INTEL CORP,CUMMINGS DANIEL J;;NITTUR SRIDHAR SHARATH,,https://lens.org/130-829-161-936-132,Patent Application,yes,1,0,3,3,0,G06N20/20;;G06N3/044;;G06N3/045;;G06N3/048;;G06N3/063;;G06N3/08;;G06N20/10;;G06N20/00,G06N3/04;;G06N3/063;;G06N3/08;;G06N20/10;;G06N20/20,,11,2,063-568-145-659-226;;170-460-564-520-119,10.1007/978-3-030-58452-8_3;;10.1007/s10994-019-05855-6,"YEHUI TANG ET AL: ""A Semi-Supervised Assessor of Neural Architectures"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 14 May 2020 (2020-05-14), XP081673610;;EFI KOKIOPOULOU ET AL: ""Fast Task-Aware Architecture Inference"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 15 February 2019 (2019-02-15), XP081029554;;LU ZHICHAO ET AL: ""NSGANetV2: Evolutionary Multi-objective Surrogate-Assisted Neural Architecture Search"", 3 November 2020, 16TH EUROPEAN CONFERENCE - COMPUTER VISION - ECCV 2020, PAGE(S) 35 - 51, XP047569480, DOI: 10.1007/978-3-030-58452-8_3;;ABDELFATTAH ET AL.: ""Zero-Cost Proxies for Lightweight NAS"", ARXIV ABS/2101.08134, 20 January 2021 (2021-01-20);;MELLOR ET AL.: ""Neural Architecture Search without Training"", INT'L CONFERENCE ON MACHINE LEARNING, 1 July 2021 (2021-07-01), pages 7588 - 7598;;LEE ET AL.: ""SNIP: Single-Shot Network Pruning based on Connection Sensitivity"", INT'L CONFERENCE ON LEARNING REPRESENTATIONS (ICLR) 2019, 6 May 2019 (2019-05-06);;TURNER ET AL.: ""BlockSwap: Fisher-guided Block Substitution for Network Compression on a Budget"", ARXIV:1906.04113V2, 23 January 2020 (2020-01-23);;NASER ET AL.: ""Insights into Performance Fitness and Error Metrics for Machine Learning"", ARXIV:2006.00887VL, 17 May 2020 (2020-05-17);;VAN ENGELEN ET AL.: ""A survey on semi-supervised learning"", MACHINE LEARNING, vol. 109, no. 2, February 2020 (2020-02-01), pages 373 - 440, XP037042584, DOI: 10.1007/s10994-019-05855-6;;KIPF ET AL.: ""Semi-Supervised Classification with Graph Convolutional Networks"", ARXIV:1609.02907V4, 22 February 2017 (2017-02-22);;""Semi-Supervised Learning"", 2006, THE MIT PRESS",PENDING
73,EP,A1,EP 4160526 A1,198-225-512-304-904,2023-04-05,2023,EP 21813575 A,2021-05-14,JP 2020091923 A;;JP 2021018331 W,2020-05-27,"INFORMATION PROCESSING DEVICE, INFORMATION PROCESSING METHOD, INFORMATION PROCESSING SYSTEM, AND PROGRAM","The present disclosure relates to an information processing apparatus, an information processing method, an information processing system, and a program capable of appropriately evaluating an object recognition filter by simpler processing.A generation unit that generates teacher data of a preprocessing filter provided in a preceding stage of the object recognition filter is generated by a cyclic generative adversarial network (Cylcic GAN) that is unsupervised learning. The teacher data generated by the generated generation unit is applied to the object recognition filter, an evaluation image is generated from a difference between object recognition result images, and an evaluation filter that generates an evaluation image from the evaluation image and the teacher data is generated. The evaluation filter is applied to an input image to generate an evaluation image, and the object recognition filter is evaluated by the generated evaluation image. The present disclosure can be applied to an object recognition device.",SONY GROUP CORP,YAMAMOTO YUKI;;WRIGHT CHRISTOPHER;;ELLIOTT-BOWMAN BERNADETTE;;WALKER NICHOLAS,,https://lens.org/198-225-512-304-904,Patent Application,yes,0,0,6,6,0,G06V10/26;;G06V10/72;;G06V10/776;;G06V10/87;;G06V20/56;;G06V10/776;;G06V10/24;;G06V10/778;;G06V10/993;;G06V20/58,G06T7/00,,0,0,,,,PENDING
74,EP,A1,EP 4156043 A1,193-037-783-334-769,2023-03-29,2023,EP 22195623 A,2022-09-14,US 202117484178 A,2021-09-24,DRIVER SCORING SYSTEM AND METHOD WITH ACCIDENT PRONENESS FILTERING USING ALERT CLUSTERING AND SAFETY-WARNING BASED ROAD CLASSIFICATION,"Techniques are disclosed to determine driver scoring that consider road accident proneness scores in driver score computations. The road accident proneness scores may be based on one or more alerts. Further, road types of roads may be determined based on alerts. The determination of the road type may use a machine learning model. In contrast to the conventional approaches, the use of road accident proneness scores in the computation of driver scores allows for the consideration of accident proneness of the road to improve upon conventional scoring techniques. Further, map data and generated maps may be improved based on determined road types.",INTEL CORP,SRIVASTAVA MASHRIN;;MANSOOR MUVAZIMA;;LAWRENCE SEAN;;C SUBRAMANIAN;;SANTHANAM BALACHANDAR,,https://lens.org/193-037-783-334-769,Patent Application,yes,1,0,2,2,0,G06Q50/265;;B60W40/09;;G06Q10/00;;G08G1/0141;;G06F16/215;;G06F16/285;;G06F16/29;;G06Q50/265;;G08G1/0112,G06Q10/00,,0,0,,,,PENDING
75,EP,A1,EP 4156698 A1,069-774-680-477-438,2023-03-29,2023,EP 22186793 A,2022-07-25,US 202117449076 A,2021-09-27,METHODS AND SYSTEMS FOR GENERATING AND PROVIDING PROGRAM GUIDES AND CONTENT,"Systems and methods are configured to manage streaming video content. A first time length specification for a content pod is accessed. If a determination is made that a response to a request for ancillary content of a duration corresponding to the first time length of the content pod includes ancillary content of insufficient duration to populate the first time length of the content pod, the content pod time length is reduced. Ancillary content items associated with the response to the request are streamed to a user device as part of a streaming channel comprising primary content having scheduled start times. A primary content item, having a scheduled start time, is streamed to the user device after the items of ancillary content, and earlier than the scheduled start time of the item of primary content.",PLUTO INC,SHANSON SPENCER;;VASILIEVICH PAVLO KALMYKOV;;JESPERSON JONATHAN MICHAEL;;CHIU ADRIAN;;FISH BRYAN RANDALL;;GWIAZDA JONATHAN JOVAN;;HASHIM SONIA PRIYA,,https://lens.org/069-774-680-477-438,Patent Application,yes,4,0,4,20,0,H04N21/2668;;H04N21/23424;;H04N21/2407;;H04N21/26233,H04N21/2668;;H04N21/234;;H04N21/24;;H04N21/262,,0,0,,,,PENDING
76,EP,A1,EP 4155765 A1,070-525-268-569-590,2023-03-29,2023,EP 21746942 A,2021-01-29,KR 20200012053 A;;KR 2021001222 W,2020-01-31,"3D LIDAR-BASED TARGET OBJECT RECOGNITION METHOD, DEVICE, AND MOVING BODY USING SAME","Disclosed are 3D LiDAR based target object recognizing method, apparatus, and a mobile object using the same.A target object recognizing method according to an exemplary embodiment of the present invention includes an irradiating step of irradiating laser light to a reference target object; an acquiring step of acquiring LiDAR data generated based on a reflection signal reflected from the reference target object; a learning step of generating a reference map and virtual LiDAR data based on the LiDAR data and determining a weight for recognizing a target object by performing the deep learning based on the virtual LiDAR data; and recognizing a new target object by applying the weight when new LiDAR data with respect to the new target object is acquired.",YUJIN ROBOT CO LTD;;MIELE & CIE,SHIN KYUNG CHUL;;PARK SEONG JU;;PARK GI YEON;;LEE KYU BEOM,,https://lens.org/070-525-268-569-590,Patent Application,yes,0,0,5,5,0,G01S17/42;;G06N3/045;;G06N3/0475;;G01S7/497;;G01S7/4808;;G06N3/047;;G06N3/094;;G01S7/4861;;G01S7/4913;;G06N3/02;;G01S17/04;;G01S7/4802;;G01S17/06;;G01S17/89,G01S7/4861;;G01S7/4913;;G06N3/02,,0,0,,,,PENDING
77,EP,A1,EP 4154798 A1,026-654-279-405-992,2023-03-29,2023,EP 21198717 A,2021-09-24,EP 21198717 A,2021-09-24,APPARATUS FOR DETERMINING A POSTURE OF A PATIENT FOR AN EXAMINATION TO BE PERFORMED WITH A MEDICAL EXAMINATION APPARATUS AND CORRESPONDING METHOD,"A positioning apparatus for adjusting a posture of a patient for an imaging and/or interventional and/or therapeutic examination of the patient is provided. The apparatus comprises a patient support device, an interface unit, and a computing unit. The patient support device is adjustable such that one or more body segments of the patient may be arranged and/or fixed in a predetermined posture. The interface unit is configured to provide examination information indicative of an examination to be performed at the patient. The computing unit is configured to receive the examination information via the interface unit. The computing unit is further configured to determine, based on the examining information, a posture of one or more body segments of the patient for the examination. The computing unit is configured to generate one or more control signals, the one or more control signals being suited to control the patient support device such that the patient support device is adjusted such that the one or more body segments of the patient are arranged and/or fixed in the determined posture. The computing unit is further configured to provide the control signals to the patient support device, preferably via the interface unit.",SIEMENS HEALTHCARE GMBH,KAPOOR ANKUR;;MAILHE BORIS;;NADAR MARIAPPAN S;;SINGH VIVEK;;TAMERSOY BIRGI,SIEMENS HEALTHINEERS AG (2024-02-14),https://lens.org/026-654-279-405-992,Patent Application,yes,5,0,1,1,0,A61B5/4561;;A61B5/702;;A61B5/6892;;A61B5/0077;;A61B5/7267;;A61B5/055;;A61B5/0073;;A61B6/0407;;A61B6/0478;;A61B6/0487;;A61B6/545;;A61N5/1049,A61B5/00;;A61B5/055,,0,0,,,,PENDING
78,EP,A1,EP 4149109 A1,059-776-689-804-606,2023-03-15,2023,EP 21818681 A,2021-05-29,CN 202010480675 A;;CN 2021097047 W,2020-05-30,VIDEO GENERATION METHOD AND RELATED APPARATUS,"This application provides a video generation method and a related device, and may be applied to the field of image processing and video generation in the field of artificial intelligence. The video generation method includes: receiving a video generation instruction, and obtaining text information and image information in response to the video generation instruction, where the text information includes one or more keywords, and the image information includes N images; obtaining, based on the one or more keywords, an image feature that is in each of the N images and that corresponds to the one or more keywords; and inputting the one or more keywords and image features of the N images into a target generator network to generate a target video, where the target video includes M images, and the M images are images that are generated based on the image features of the N images and that correspond to the one or more keywords. During embodiments of this application, a video is automatically generated on the premise of ensuring richness of video content.",HUAWEI TECH CO LTD,SHAO BIN;;YUE JUN;;QIAN LI;;XU SONGCEN;;HUANG XUEYAN;;LIU YAJIAO,,https://lens.org/059-776-689-804-606,Patent Application,yes,0,0,6,6,0,H04N5/265;;G06F18/214;;H04L51/10;;H04L51/52;;H04L51/56;;G06V10/82;;G06Q10/10;;G06Q50/01;;G06V20/30;;H04L51/10;;H04L51/222;;H04L51/52;;Y02A90/10;;H04N21/80;;G06T7/0002;;G06T2207/30168;;G06T2207/30201;;G06V10/44;;G06V20/70;;G06V40/172,H04N5/265;;G06T5/50,,0,0,,,,PENDING
79,EP,A1,EP 4141813 A1,064-228-195-686-631,2023-03-01,2023,EP 22187911 A,2022-07-29,US 202117462472 A,2021-08-31,DETECTION AND MITIGATION OF INAPPROPRIATE BEHAVIORS OF AUTONOMOUS VEHICLE PASSENGERS,"Disclosed herein are systems and methods for detecting and mitigating inappropriate behavior. The systems and methods may include receiving data. Using the data a harassment score and/or classification for a behavior may be determined. Using the harassment score and/or classification, a determination may be made as to when the harassment score and/or classification for the behavior exceeds a threshold. When the threshold is exceeded, a protection system and/or action engine may be activated to mitigate the inappropriate behavior.",INTEL CORP,BUERKLE CORNELIUS;;OBORIL FABIAN;;PASCH FREDERIK;;LIEW YING WEI;;TAN SAY CHUAN;;YEW CHIEN CHERN;;GRAEFE RALF;;GEISSLER FLORIAN;;ALVAREZ IGNACIO J,,https://lens.org/064-228-195-686-631,Patent Application,yes,4,0,3,3,0,G06Q50/265;;G06F40/30;;G06Q50/01;;G06Q50/40;;G06V20/59;;G06V40/20;;G10L25/48;;G06V20/59;;B60W60/0016;;B60W60/00253;;G06V40/10;;G06V40/20;;G10L15/1815,G06V20/52;;B60W50/00;;G06Q50/00;;G06Q50/26;;G06Q50/30;;G06V20/59;;G06V40/20;;G10L25/48,,0,0,,,,PENDING
80,EP,A1,EP 4134884 A1,180-022-572-920-625,2023-02-15,2023,EP 21785099 A,2021-04-02,JP 2020068669 A;;JP 2021014254 W,2020-04-06,"BRAIN FUNCTIONAL CONNECTIVITY CORRELATION VALUE CLUSTERING DEVICE, BRAIN FUNCTIONAL CONNECTIVITY CORRELATION VALUE CLUSTERING SYSTEM, BRAIN FUNCTIONAL CONNECTIVITY CORRELATION VALUE CLUSTERING METHOD, BRAIN FUNCTIONAL CONNECTIVITY CORRELATION VALUE CLASSIFIER PROGRAM, BRAIN ACTIVITY MARKER CLASSIFICATION SYSTEM AND CLUSTERING CLASSIFIER MODEL FOR BRAIN FUNCTIONAL CONNECTIVITY CORRELATION VALUES","A brain functional connectivity correlation value clustering device for clustering subjects having a prescribed attribute on the basis of brain measurement data obtained from a plurality of facilities, wherein a plurality of MRI devices capture resting state fMRI image data of a healthy cohort and a patient cohort; a computing system 300 performs generation of an identifier as ensemble learning of ""supervised learning"" between harmonized component values of correlation matrixes and disease labels of each of the subjects, selects, during the ensemble learning, features for clustering in accordance with importance from the features specified for generating an identifier for a disease label, and performs multiple co-clustering by ""unsupervised learning.""",ADVANCED TELECOMMUNICATIONS RES INSTITUTE INTERNATIONAL,KASHIWAGI YUUTO;;TOKUDA TOMOKI;;TAKAHARA YUJI;;KAWATO MITSUO;;YAMASHITA AYUMU;;YAMASHITA OKITO;;SAKAI YUKI;;YOSHIMOTO JUNICHIRO,,https://lens.org/180-022-572-920-625,Patent Application,yes,0,0,7,7,0,A61B5/055;;A61B5/0042;;A61B5/7267;;A61B5/165;;G06N20/20;;G06N7/01;;G06F18/211;;G06F18/2415;;G06F2123/02;;A61B5/055;;A61B5/165,G06N20/00;;A61B5/055,,0,0,,,,PENDING
81,EP,A1,EP 4134853 A1,141-651-919-329-787,2023-02-15,2023,EP 21191073 A,2021-08-12,EP 21191073 A,2021-08-12,METHOD AND SYSTEM FOR SELECTIVE IMAGE MODIFICATION FOR PROTECTING IDENTITIES,"This application is directed to a method of selective image modification for protecting identities, comprising capturing (S101) a first image by means of an image-capturing unit (11) of a first device (1); detecting (S102), by the first device (1), an anonymizable object in the first image; determining (S103), by the first device (1), that the anonymizable object is associated with a second device(4); and modifying (S105), by the first device (1), the anonymizable object in the first image by using privacy setting data received from the second device(4). The application is further directed at the first device and at a system for selective image modification.",BRIGHTER AI TECH GMBH,PASPUEL MARCO;;SUCIU TEODORA;;CHATTERJEE SREENJOY;;GLÄSER MARIAN,,https://lens.org/141-651-919-329-787,Patent Application,yes,4,0,2,2,0,G06F21/6254;;G06F21/6245;;H04L9/008;;H04L2209/42;;H04W12/02,G06F21/62;;H04L9/00;;H04W12/02,,4,3,093-667-357-958-326;;028-779-103-186-88X;;016-235-063-143-293,10.1016/j.eswa.2018.01.023;;10.1109/cvpr.2017.145;;10.1109/cvpr.2016.144,"45 BILLION CAMERAS BY 2022 FUEL BUSINESS OPPORTUNITIES - FIVE YEAR VISUAL TECHNOLOGY MARKET ANALYSIS, August 2017 (2017-08-01);;SOLEYMANI, ROGHAYEHERIC GRANGERGIORGIO FUMERA: ""Progressive boosting for class imbalance and its application to face re-identification"", EXPERT SYSTEMS WITH APPLICATIONS, vol. 101, 2018, pages 271 - 291;;CHEN, WEIHUA ET AL.: ""Beyond triplet loss: a deep quadruplet network for person re-identification"", PROCEEDINGS OF THE IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, 2017;;WANG, FAQIANG ET AL.: ""Joint learning of single-image and cross-image representations for person re-identification"", PROCEEDINGS OF THE IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, 2016",PENDING
82,EP,B1,EP 3948794 B1,128-589-591-012-798,2023-01-25,2023,EP 20718113 A,2020-03-23,US 201962822844 P;;US 201962936439 P;;US 201962950279 P;;US 2020/0024169 W,2019-03-23,SYSTEMS AND METHODS FOR GENERATING SYNTHETIC SENSOR DATA VIA MACHINE LEARNING,,UATC LLC,MANIVASAGAM SIVABALAN;;WANG SHENLONG;;MA WEI-CHIU;;WONG KELVIN KA WING;;ZENG WENYUAN;;URTASUN RAQUEL,,https://lens.org/128-589-591-012-798,Granted Patent,yes,0,0,9,9,0,G01S7/497;;G01S13/931;;G01S17/006;;G01S17/89;;G01S17/931;;G06T17/05;;G06T2210/56;;G06N3/08;;G06T17/00;;G06N3/045;;G06F11/263;;G06T17/20;;G06F17/18;;G06N20/00;;G06T15/06;;G06T2207/10028;;G06N3/047,G06T17/05;;G01S17/00,,3,0,,,"JIN FANG ET AL: ""Simulating LIDAR Point Cloud for Autonomous Driving using Real-world Scenes and Traffic Flows"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 17 November 2018 (2018-11-17), XP081051385,;;BICHEN WU ET AL: ""SqueezeSegV2: Improved Model Structure and Unsupervised Domain Adaptation for Road-Object Segmentation from a LiDAR Point Cloud"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 23 September 2018 (2018-09-23), XP080920110,;;XIANGYU YUE ET AL: ""A LiDAR Point Cloud Generator: from a Virtual World to Autonomous Driving"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 31 March 2018 (2018-03-31), XP081225058,",ACTIVE
83,EP,B1,EP 3727134 B1,056-275-939-970-953,2023-01-25,2023,EP 18833243 A,2018-12-21,US 201762610033 P;;EP 2018086762 W,2017-12-22,PROCESSOR READABLE MEDIUM AND CORRESPONDING METHOD FOR HEALTH AND MEDICAL SENSING,,RESMED SENSOR TECH LTD,SHOULDICE REDMOND;;MCMAHON STEPHEN;;WREN MICHAEL,RESMED SENSOR TECHNOLOGIES LIMITED (2023-02-22),https://lens.org/056-275-939-970-953,Granted Patent,yes,2,0,10,10,0,A61B5/4806;;A61B5/0053;;A61B5/024;;A61B5/113;;A61B5/6898;;A61B5/7228;;A61B5/7267;;A61B8/02;;A61B8/0883;;G16H50/70;;A61B5/4806;;A61B5/1113;;A61B5/113;;A61B5/4818;;A61B5/6898;;A61B5/7228;;A61B5/749;;A61B8/02;;A61B8/0883;;A61M16/0003;;A61M16/0057;;A61M16/026;;G16H50/70;;A61B5/4809;;A61B5/02;;A61B5/0205;;A61B5/02405;;A61B5/05;;A61B5/1126;;A61B5/113;;A61B5/4812;;A61B5/4818;;A61B5/4833;;A61B5/681;;A61B5/6887;;A61B5/7225;;A61B5/7228;;A61B5/7257;;A61B5/7405;;A61B8/08;;A61B8/5207;;A61B8/5223;;G06F3/165;;G10K15/04;;G10L25/66;;G16H20/30;;G16H40/40;;G16H40/67;;G16H50/20;;G16H50/30;;G16H50/50;;H04R1/028;;H04R1/08;;H04R3/04;;H04R2499/11,A61B5/00;;A61B5/024,,0,0,,,,ACTIVE
84,EP,A1,EP 4116840 A1,017-469-569-930-399,2023-01-11,2023,EP 20718362 A,2020-03-05,IB 2020051926 W,2020-03-05,SYSTEM AND METHOD OF DETECTION AND IDENTIFICATION OF CROPS AND WEEDS,"A system for detecting and identifying plant species in an agricultural field that allows to act on them, which comprises at least one camera that includes a lens, a bandpass filter and an image sensor; a GPS unit; and at least one data processing unit comprising data storage means and in data communication with the at least one camera and with the GPS unit, wherein each data processing unit comprises a system for calibrating the cameras, where the cameras capture and send images to the data processing unit, where each data processing unit is configured to autonomously detect and identify plant species, discriminating between crops, weeds and soil, based on the images that it receives and make decisions as detected and identified, and where each data processing unit geolocates the detected plant species. A method that uses the plant species detection and identification system of the present invention to detect and identify plant species in an agricultural field.",PLANTIUM S A;;GENTILI JORGE A,CORTI CINTIA;;PELLEJERO NICOLÁS,,https://lens.org/017-469-569-930-399,Patent Application,yes,0,0,5,6,0,G06F16/532;;A01M7/0089;;G01N33/0098;;G06F16/55;;G06F16/583;;G06T7/0012;;A01M7/0089;;G06T2207/10048;;G06T2207/20208;;G06T2207/30188,G06F16/532;;G06F16/55;;G06F16/583,,1,0,,,See references of WO 2021176254A1,PENDING
85,EP,A1,EP 4109385 A1,096-621-648-349-577,2022-12-28,2022,EP 22159086 A,2022-02-28,US 202117356043 A,2021-06-23,TYPED UNORDERED ACCESS VIEW OVERLOADING ON PIXEL PIPELINE,"Methods, systems and apparatuses provide for graphics processor technology that routes untyped unordered access view (UAV) messages to a next level memory cache, routes typed UAV messages and render target messages to a pixel pipeline, and processes, via the pixel pipeline, the typed UAV messages. The technology can also provide for the pixel pipeline to perform a format conversion of one or more pixels associated with a typed UAV message based on a surface format of a UAV resource, calculate a memory address for each pixel associated with the typed UAV message, and collect a plurality of fragments from processed typed UAV messages.",INTEL CORP,JARDOSH JAY;;SURTI PRASOONKUMAR;;APPU ABHISHEK,,https://lens.org/096-621-648-349-577,Patent Application,yes,0,0,3,3,0,G06T1/20;;G06N3/08;;G06T1/60;;G06T1/20;;G06T1/60;;G06T1/20;;G06T1/60,G06T1/20;;G06F9/00;;G06T1/60,,2,0,,,"PAUL INTEL CORPORATION: ""Intel® Open Source HD Graphics and Intel Iris™ Graphics. Programmer's Reference Manual. Vol. 7: 3D-Media-GPGPU"", 1 October 2015 (2015-10-01), IHD-OS-CHV-BSW-Vol 7-10.15, pages 1 - 1055, XP055599412, Retrieved from the Internet <URL:https://01.org/sites/default/files/documentation/intel-gfx-prm-osrc-bdw-vol07-3d_media_gpgpu_1.pdf> [retrieved on 20190625];;SHANE COOK: ""CUDA Programming"", 2013, pages: 37 - 51",PENDING
86,EP,A1,EP 4109391 A1,063-227-896-174-435,2022-12-28,2022,EP 22159055 A,2022-02-28,US 202117355856 A,2021-06-23,OPPORTUNISTIC LATE DEPTH TESTING TO PREVENT STALLING FOR OVERLAPPING CACHE LINES,"Methods, systems and apparatuses provide for graphics processor technology that determines whether a first cache line allocated for early depth testing overlaps a second cache line allocated for late depth testing, and when the first cache line overlaps the second cache line, switches the first cache line to be allocated for late depth testing, and bypasses an early depth test for the first cache line. The technology can also compare coordinates of the first cache line with the coordinates of the second cache line, where an overlap is determined when coordinates for at least one pixel in the first cache line match coordinates for at least one pixel in the second cache line. Additionally, the technology can also perform early depth testing on each pixel in the first cache line when the first cache line does not overlap any existing cache lines allocated for late depth testing.",INTEL CORP,MANDAL SAIKAT;;HOEKSTRA ERIC;;RANGANATHAN VASANTH;;SURTI PRASOONKUMAR,,https://lens.org/063-227-896-174-435,Patent Application,yes,10,0,3,3,0,G06F11/2236;;G06F11/2273;;G06T1/60;;G06F12/0875;;G06F2212/1024;;G06F2212/455;;G06F12/0855;;G06F12/0815;;G06T7/50,G06T1/60;;G06T1/20;;G06T15/00;;G06T15/40,,2,1,046-127-227-423-292,10.1049/cje.2015.01.015,"ZHANG JUN: ""XY -Type GPU Cache: Exploiting Spatial Localities in both X and Y Directions to Avoid Conflict Miss"", CHINESE JOURNAL OF ELECTRONICS, TECHNOLOGY EXCHANGE LTD., HONG KONG, HK, vol. 24, no. 1, 1 January 2015 (2015-01-01), pages 88 - 95, XP006072615, ISSN: 1022-4653, DOI: 10.1049/CJE.2015.01.015;;SHANE COOK, CUDA PROGRAMMING CHAPTER, vol. 3, 2013, pages 37 - 51",PENDING
87,EP,A1,EP 4105878 A1,074-983-481-429-697,2022-12-21,2022,EP 22186911 A,2018-12-26,KR 20170180036 A;;EP 20190447 A;;EP 18894837 A;;KR 2018016678 W,2017-12-26,IMAGE ACQUISITION DEVICE AND METHOD OF CONTROLLING THE SAME,"Provided are an artificial intelligence (Al) system that mimics functions, such as recognition and determination by human brains, by utilizing a machine learning algorithm and applications of the Al system. An image acquisition device is disclosed including a camera configured to acquire a first image, at least one processor configured to: input the first image to a first Al neural network; detect, by the first Al neural network from data corresponding to a plurality of object included the first image, first data corresponding to the main object and second data corresponding to the sub-object, and generate, using a second Al neural network, a second image by restoring third data corresponding to at least a portion of the main object hidden by the sub-object, wherein the third data replaces the second data; and a display configured to display at least one of the first image and the second image.",SAMSUNG ELECTRONICS CO LTD,JUNG JAEHO;;SUNG YEULTAK,,https://lens.org/074-983-481-429-697,Patent Application,yes,0,0,12,17,0,G06T7/0002;;G06N3/04;;G06N3/08;;G06T2207/10004;;G06T2207/20084;;G06T2207/20081;;G06T2207/20104;;G06T2207/30196;;G06T5/50;;G06T2207/10016;;G06T2207/20221;;G06T5/77;;G06T5/60;;G06T1/0007;;G06T7/11;;G06T7/20;;G06T2207/20084;;G06T5/00,G06T5/00;;G06T5/50,,3,1,100-152-608-273-970,10.1016/j.jvcir.2012.01.006,"MIGUEL GRANADOS ET AL: ""Background Inpainting for Videos with Dynamic Objects and a Free-Moving Camera"", 7 October 2012, ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, PAGE(S) 682 - 695, XP047018591;;ZHANG WEI ET AL: ""Reference-guided exposure fusion in dynamic scenes"", JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION, vol. 23, no. 3, 20 January 2012 (2012-01-20), US, pages 467 - 475, XP055977447, ISSN: 1047-3203, Retrieved from the Internet <URL:https://www.sciencedirect.com/science/article/pii/S1047320312000193/pdfft?md5=9c23417b142e08e2ddeef3b3660f4b1f&pid=1-s2.0-S1047320312000193-main.pdf> DOI: 10.1016/j.jvcir.2012.01.006;;ANGELO NODARI ET AL: ""Digital privacy: Replacing pedestrians from Google Street View images"", PATTERN RECOGNITION (ICPR), 2012 21ST INTERNATIONAL CONFERENCE ON, IEEE, 11 November 2012 (2012-11-11), pages 2889 - 2893, XP032329954, ISBN: 978-1-4673-2216-4",PENDING
88,EP,A1,EP 4102247 A1,171-682-282-050-104,2022-12-14,2022,EP 22178761 A,2022-06-13,US 202163209907 P;;US 202117352185 A;;US 202163235103 P;;US 202163253083 P;;US 202163293065 P;;US 202217827902 A;;US 202217838228 A;;US 202217838231 A;;US 202217838244 A,2021-06-11,SYSTEM AND METHOD FOR RADIO-ASSISTED SOUND SENSING,"Methods, apparatus and systems for sound sensing and wireless sensing are described. In one example, a described system comprises: a sensor configured to obtain a baseband mixture signal in a venue; a transmitter configured to transmit a first radio signal through a wireless channel of the venue; a receiver configured to receive a second radio signal through the wireless channel; and a processor. The baseband mixture signal comprises a mixture of a first source signal and an additional signal. The first source signal is generated by a first motion of a first object in the venue. The second radio signal differs from the first radio signal due to the wireless channel and at least the first motion of the first object in the venue. The processor is configured for: obtaining a radio feature of the second radio signal, constructing a first adaptive filter for the baseband mixture signal based on the radio feature, filtering the baseband mixture signal using the first adaptive filter to obtain a first output signal, and generating an estimation of the first source signal based on the first output signal.",WANG BEIBEI;;OZTURK MUHAMMED ZAHID;;WU CHENSHU;;ZENG XIAOLU;;REGANI SAI DEEPIKA;;HU YUQIAN;;LIU K J RAY;;AU OSCAR CHI LIM;;HAN YI;;LAI HUNG QUOC DUC;;CLAFFEY DAVID N;;CHEN CHUN I;;BUGOS DAN;;ZAN PENG;;ZHU GUOZHEN,WANG BEIBEI;;OZTURK MUHAMMED ZAHID;;WU CHENSHU;;ZENG XIAOLU;;REGANI SAI DEEPIKA;;HU YUQIAN;;LIU K J RAY;;AU OSCAR CHI-LIM;;HAN YI;;LAI HUNG-QUOC DUC;;CLAFFEY DAVID N;;CHEN CHUN-I;;BUGOS DAN;;ZAN PENG;;ZHU GUOZHEN,,https://lens.org/171-682-282-050-104,Patent Application,yes,2,2,2,260,0,G01S7/415;;G01S7/006;;G01S7/2883;;G01S7/292;;G01S7/414;;G01S7/417;;G01S13/003;;G01S13/56;;G01S13/66;;G01S13/862,G01S7/00;;G01S7/288;;G01S7/292;;G01S7/41;;G01S13/00;;G01S13/66;;G01S13/86,,2,0,,,"MUHAMMED ZAHID OZTURK ET AL: ""RadioMic: Sound Sensing via mmWave Signals"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 6 August 2021 (2021-08-06), XP091029695;;MUHAMMED ZAHID OZTURK ET AL: ""RadioSES: mmWave-Based Audioradio Speech Enhancement and Separation System"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 14 April 2022 (2022-04-14), XP091204229",PENDING
89,EP,A1,EP 4099226 A1,071-966-131-428-738,2022-12-07,2022,EP 21176983 A,2021-05-31,EP 21176983 A,2021-05-31,"TRAINING METHOD FOR TRAINING A CVAE TO PREDICT FUTURE PROPERTIES OF AGENTS, PREDICTION METHOD, COMPUTER PROGRAM(S), COMPUTER READABLE MEDIUM, FUTURE PROPERTIES PREDICTION SYSTEM","A training method for training a CVAE to calculate a prediction Y relative to future properties of agent(s) Ai, and a prediction method to calculate such predictions using the CVAE.The CVAE comprises a posterior (Po), a prior (Pr) and a decoder (D).Each of the posterior (Po) and the prior (Pr) comprises an encoder (PoE), a sampler (PoS) and an attention mechanism (PoAM,PrAM).The encoders (PoE,PrE) calculate parameters of conditional distributions of intermediate variables (PoW,PrW), based on past trajectories of the agents.The attention mechanisms (PoAM,PrAM) output values of the latent space variable Z based on the drawn value of the intermediate variable (PoW,PrW).The decoder (D) calculates predictions Y based on a value of the latent space variable Z.Both the posterior distribution q<sub>φ</sub>(Z|X,Y) and the prior distribution p<sub>θ</sub>(Z|X) are joint distributions based on the past observations of the agents.Computer program(s), readable medium, prediction system and method.",TOYOTA MOTOR CO LTD;;MAX PLANCK INST FUER INFORMATIK,OLMEDA REINO DANIEL;;BHATTACHARYYA APRATIM;;FRITZ MARIO;;SCHIELE BERNT,,https://lens.org/071-966-131-428-738,Patent Application,yes,0,0,1,1,0,G06N3/08;;B60W60/0027;;G06N3/044;;G06N3/045;;G06N3/047,G06N3/04;;B60W60/00;;G06N3/08,,8,4,095-628-113-018-283;;028-932-101-407-640;;024-276-449-687-198;;056-965-380-133-588,10.1109/iccv48922.2021.00967;;10.1109/cvpr.2016.110;;10.1109/cvpr.2017.233;;10.1109/iccv.2019.00436,"YE YUAN ET AL: ""AgentFormer: Agent-Aware Transformers for Socio-Temporal Multi-Agent Forecasting"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 25 March 2021 (2021-03-25), XP081916860;;A. ALAHIK. GOELV. RAMANATHANA. ROBICQUETL. FEI-FEIS. SAVARESE: ""ocial LSTM: Human trajectory prediction in crowded spaces"", PROCEEDINGS OF THE IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, 2016, pages 961 - 971, XP033021272, DOI: 10.1109/CVPR.2016.110;;IRINA HIGGINSLOIC MATTHEYARKA PALCHRISTOPHER BURGESSXAVIER GLOROTMATTHEW BOTVINICKSHAKIR MOHAMEDALEXANDER LERCHNER: ""Beta-VAE: Learning basic visual concepts with a constrained variational framework"", ICLR, 2017;;DIEDERIK P. KINGMAMAX WELLING: ""Auto-encoding variational Bayes"", ICLR, 2014;;N. LEEW. CHOIP. VERNAZAC. B. CHOYP. H. TORRM. CHANDRAKER: ""Desire: Distant future prediction in dynamic scenes with interacting agents"", CVPR, 2017;;K. SOHNH. LEEX. YAN: ""Learning structured output representation using deep conditional generative models."", ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS, 2015, pages 3483 - 3491, XP055546322;;KAREN SIMONYANANDREW ZISSERMAN: ""Very deep convolutional networks for large-scale image recognition"", ICLR, 2015;;ANEJA, J.AGRAWAL, H.BATRA, D.SCHWING, A: ""Sequential Latent Spaces for Modeling the Intention During Diverse Image Captioning"", IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV, 2019, pages 4260 - 4269, XP033724057, DOI: 10.1109/ICCV.2019.00436",DISCONTINUED
90,EP,A1,EP 4099048 A1,030-635-886-220-384,2022-12-07,2022,EP 22176261 A,2022-05-31,JP 2021094099 A,2021-06-04,POSITION INFORMATION CALCULATION DEVICE AND POSITION INFORMATION CALCULATION METHOD,"A position information calculation device (20) of an embodiment includes a sensor information acquisition module (20A), a landmark detection module (20B), a landmark dictionary section (20D), a landmark search module (20C), and a moving object position calculation module (20F). The sensor information acquisition module (20A) is configured to acquire sensor information obtained by sensing an external environment of a moving object (RV) with a sensor. The landmark detection module (20B) is configured to detect a predetermined landmark set in advance from the sensor information to acquire first sensor landmark information. The landmark dictionary section (20D) is configured to store in advance second sensor landmark information in which the landmark and position information are associated with each other. The landmark search module (20C) is configured to acquire the position information associated with the landmark in the first sensor landmark information by search using the landmark dictionary section. The moving object position calculation module (20F) is configured to calculate a position of the moving object (RV) on the basis of the position information of the landmark.",TOSHIBA KK;;TOSHIBA INFRASTRUCTURE SYSTEMS & SOLUTIONS CORP,MASHIMA YOSHIKI;;KOBAYASHI HIROYUKI;;OODAKE TATSUYA;;TAKAHASHI YUSUKE;;KATO NORIYASU;;HATTORI YOHEI;;ITO HIROAKI,,https://lens.org/030-635-886-220-384,Patent Application,yes,3,1,3,3,0,G06F16/2455;;B61L25/025;;G01C21/20;;G06F16/29;;G06F16/90348;;G06F16/909;;G06N20/00;;G01S5/16;;G01C21/30;;G01C21/3602;;G01S17/88,G01S7/48;;G01C21/36;;G01S5/16;;G01S17/931,,0,0,,,,PENDING
91,EP,A1,EP 4089682 A1,193-512-462-654-964,2022-11-16,2022,EP 21173445 A,2021-05-12,EP 21173445 A,2021-05-12,MEDICAL SUPPORT SYSTEM AND MEDICAL SUPPORT METHOD FOR PATIENT TREATMENT,"The present disclosure provides a medical support system (100) for patient treatment. The medical support system (100) includes an audio reception module (110) configured to receive sounds (S) of a patient (1) and generate sound data (SD) indicative of the received sounds (S); and an artificial intelligence module (120) configured to analyze the sound data (SD), wherein the artificial intelligence module (120) is further configured to provide a medical support function based on the analysis of the sound data (SD).",BIOTRONIK SE & CO KG,DÖRR THOMAS;;MÜLLER JENS;;GRATZ MATTHIAS;;WHITTINGTON R HOLLIS,,https://lens.org/193-512-462-654-964,Patent Application,yes,3,0,1,1,0,G16H40/63;;A61B5/08;;A61B5/16;;A61B5/4803;;A61B5/7264;;A61B7/003;;G10L25/66;;G16H10/20;;G16H20/30;;G16H20/70;;G16H50/20,G16H10/20;;A61B5/00;;A61B7/00;;G10L17/26;;G10L25/27;;G10L25/66;;G16H20/30;;G16H20/70;;G16H40/63;;G16H50/20,,2,1,014-169-515-798-093,10.1159/000515346;;34056518;;pmc8138221,"FAGHERAZZI GUY ET AL: ""Voice for Health: The Use of Vocal Biomarkers from Research to Clinical Practice"", DIGITAL BIOMARKERS, vol. 5, no. 1, 16 April 2021 (2021-04-16), pages 78 - 88, XP055851902, Retrieved from the Internet <URL:https://www.karger.com/Article/Pdf/515346> [retrieved on 20211018], DOI: 10.1159/000515346;;MAOR ELAD ET AL: ""Conclusions"", JOURNAL OF THE AMERICAN HEART ASSOCIATION, vol. 9, no. 7, 9 April 2020 (2020-04-09), pages 13359, XP055841519, Retrieved from the Internet <URL:https://www.ahajournals.org/doi/pdf/10.1161/JAHA.119.013359> [retrieved on 20211018], DOI: 10.1161/JAHA.119.013359",DISCONTINUED
92,EP,A1,EP 4080393 A1,156-488-846-507-964,2022-10-26,2022,EP 22178575 A,2018-07-24,US 201762536042 P;;KR 20170142106 A;;EP 18838530 A;;KR 2018008355 W,2017-07-24,ELECTRONIC DEVICE AND METHOD FOR CONTROLLING THE ELECTRONIC DEVICE,"A method for controlling an electronic device is provided. The method includes receiving a command to upload an image to an external server; acquiring, based on the command, a characteristic value corresponding to the image by inputting the image and a key of the electronic device into an encryption model trained to identify characteristic values based on an input image and an input key; and transmitting the characteristic value to the external server.",SAMSUNG ELECTRONICS CO LTD,KANG SEONG-MIN;;HAN HEUNG-WOO,,https://lens.org/156-488-846-507-964,Patent Application,yes,3,0,11,11,0,H04N1/444;;H04N1/4413;;G06F21/602;;G06F21/46;;G06F21/62;;G06N3/08;;G06T9/002;;G06T2207/20081;;G06T2207/20084;;G06V10/761;;H04N21/2347;;H04N21/4405;;H04N1/444;;H04N1/4413;;H04N19/126,G06F21/60;;G06F21/46;;G06F21/62;;G06N3/08;;G06T7/00;;G06T9/00;;H04N21/2347;;H04N21/4405,,0,0,,,,PENDING
93,EP,A1,EP 4080166 A1,198-899-527-072-334,2022-10-26,2022,EP 22150937 A,2022-01-11,TW 110113894 A,2021-04-19,METHOD FOR GENERATING VIRTUAL NAVIGATION ROUTE,"The present invention generates a virtual navigation route by obtaining multiple navigation points each with a flag data (S11); identifying at least two lanes (31) from a front video data (30) (S13); creating a navigation characteristic image according to the flag data, the navigation points, the front video data (30), and the at least two lanes (31), wherein the navigation characteristic image has multiple dotted grids (33) (S14); calculating a probability of a navigation route (351) passing through each dotted grid, and setting the dotted grid with the highest probability calculated in each row of the navigation characteristic image as a first default value (S16); and fitting curves for the grids with the first default value as the navigation route (351) (S17); the navigation route (351) is projected over the front video data (30) for navigating with better traffic representation.",UNIV FENG CHIA,LIN YU-CHEN;;CHAN YU-CHING;;LIN MING-CHIH,,https://lens.org/198-899-527-072-334,Patent Application,yes,1,0,5,5,0,G01C21/365;;G06V20/58;;G06V20/49;;G01C21/367;;G01C21/3676;;G06T19/006,G01C21/36,,0,0,,,,PENDING
94,EP,A1,EP 4072128 A1,038-831-454-562-128,2022-10-12,2022,EP 21167468 A,2021-04-08,EP 21167468 A,2021-04-08,COMMUNICATION ASSEMBLY,"A communication method and a communication assembly, comprising a first capturing unit configured to capture video data of a first peer in real-time, wherein the video data of the first peer comprises an identification feature a mimic expression feature; a second capturing unit configured to capture video data of a second peer in real-time; a first anonymization unit configured to modify the video data captured by the first capturing unit in real-time by replacing a characteristic of the identification feature in the video data of the first peer while substantially maintaining a characteristic of the mimic expression feature in the video data of the first peer; a first display unit of the first peer; a second display unit of the second peer; a data transfer unit configured to perform a transfer of the video data.",BRIGHTER AI TECH GMBH,CHATTERJEE SCREENJOY;;GLÄSER MARIAN,,https://lens.org/038-831-454-562-128,Patent Application,yes,4,0,2,2,0,H04N7/157,H04N7/15,,8,3,093-667-357-958-326;;028-779-103-186-88X;;016-235-063-143-293,10.1016/j.eswa.2018.01.023;;10.1109/cvpr.2017.145;;10.1109/cvpr.2016.144,"HUKKELÅS HÅKON ET AL: ""DeepPrivacy: A Generative Adversarial Network for Face Anonymization"", 10 September 2019 (2019-09-10), pages 1 - 14, XP055835138, Retrieved from the Internet <URL:https://arxiv.org/pdf/1909.04538.pdf> [retrieved on 20210826];;JIANKANG DENGJIA GUOYUXIANG ZHOUJINKE YUIRENE KOTSIASTEFANOS ZAFEIRIOU: ""RetinaFace: Single-stage Dense Face Localisation in the Wild"", ARXIV:1905.00641, CS.CV, Retrieved from the Internet <URL:https://dblp.org/rec/journals/corr/abs-1905-00641.bib>;;JIANZHU GUOXIANGYU ZHUYANG YANGFAN YANGZHEN LEISTAN Z. LI: ""Towards Fast, Accurate and Stable 3D Dense Face Alignment"", ARXIV:2009.09960, CS.CV, 2020;;YAO FENGHAIWEN FENGMICHAEL J. BLACKTIMO BOLKART: ""Learning an Animatable Detailed 3D Face Model from In-The-Wild Images"", ARXIV:2012.04012, CS.CV, 2020;;HAKON HUKKELASRUDOLF MESTERFRANK LINDSETH: ""DeepPrivacy: A Generative Adversarial Network for Face Anonymization"", ARXIV:1909.04538, CS.CV, 2019, Retrieved from the Internet <URL:https://dblp.org/rec/journals/corr/abs-1909-04538.bib>;;SOLEYMANIROGHAYEHERIC GRANGERGIORGIO FUMERA: ""Progressive boosting for class imbalance and its application to face re-identification"", EXPERT SYSTEMS WITH APPLICATIONS, vol. 101, 2018, pages 271 - 291;;CHEN, WEIHUA ET AL.: ""Beyond triplet loss: a deep quadruplet network for person re-identification"", PROCEEDINGS OF THE IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, 2017;;WANG, FAQIANG ET AL.: ""Joint learning of single-image and cross-image representations for person re-identification"", PROCEEDINGS OF THE IEEE CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, 2016",DISCONTINUED
95,EP,A2,EP 4068273 A2,158-633-126-403-201,2022-10-05,2022,EP 22165702 A,2022-03-30,GB 202104696 A;;US 202117219610 A;;US 202217707923 A,2021-03-31,SYSTEM AND METHODS FOR AUTOMATICALLY GENERATING A MUSICAL COMPOSITION HAVING AUDIBLY CORRECT FORM,"A generative composition system reduces existing musical artefacts to constituent elements termed ""Form Atoms"". These Form Atoms may each be of varying length and have musical properties and associations that link together through Markov chains. To provide myriad new composition, a set of heuristics ensures that musical textures between concatenated musical sections follow a supplied and defined briefing narrative for the new composition whilst contiguous concatenated Form Atoms are also automatically selected to see that similarities in respective and identified attributes of musical textures for those musical sections are maintained to support maintenance of musical form. Independent aspects of the disclosure further ensure that, within the composition work, such as a media product or a real-time audio stream, chord spacing determination and control are practiced to maintain musical sense in the new composition. Further, a structuring of primitive heuristics operates to maintain pitch and permit key transformation. The system and its functionality provides signal analysis and music generation through allowing emotional connotations to be specified and reproduced from cross-referenced Form-Atoms.",DAACI LTD,LYSKE DR JOSEPH MICHAEL WILLIAM,,https://lens.org/158-633-126-403-201,Patent Application,yes,1,0,11,31,0,G10H1/0025;;G10H2210/125;;G10H2240/085;;G10H2210/061;;G10H1/0025;;G10H2210/061;;G10H2210/125;;G10H2240/085,G10H1/00,,0,0,,,,PENDING
96,EP,A1,EP 4057226 A1,041-917-335-881-762,2022-09-14,2022,EP 22159874 A,2022-03-03,CN 202110257474 A;;KR 20210162793 A,2021-03-09,METHOD AND APPARATUS FOR ESTIMATING POSE OF DEVICE,"The present disclosure relates to the field of artificial intelligence technology, and to a method of estimating a pose of a device and a related device. The method of estimating a pose of a device includes identifying a similar key frame that is similar to a current frame collected by the device from a key frame set, based on a vector distance between the similar key frame and the current frame; obtaining data-related information between image frames based on a feature matching relationship between the current frame and the similar key frame; and obtaining the pose of the device based on the data-related information",SAMSUNG ELECTRONICS CO LTD,LIU ZHIHUA;;LEE HONGSEOK;;WANG QIANG;;KIM YUNTAE;;MA KUAN,,https://lens.org/041-917-335-881-762,Patent Application,yes,1,1,2,4,0,G06T7/73;;G06T2207/10016;;G06T2207/20084;;G06T2207/30244;;G06T7/74;;G06V10/42;;G06V10/44;;G06V10/761,G06T7/73,,4,3,048-510-019-754-753;;192-751-999-674-131;;047-055-268-960-699,10.1109/tro.2015.2463671;;10.1109/iccv.2011.6126544;;10.1007/978-3-030-58565-5_43,"MUR-ARTAL RAUL ET AL: ""ORB-SLAM: A Versatile and Accurate Monocular SLAM System"", IEEE TRANSACTIONS ON ROBOTICS, IEEE SERVICE CENTER, PISCATAWAY, NJ, US, vol. 31, no. 5, 1 October 2015 (2015-10-01), pages 1147 - 1163, XP011670910, ISSN: 1552-3098, [retrieved on 20151001], DOI: 10.1109/TRO.2015.2463671;;ETHAN RUBLEE ET AL: ""ORB: An efficient alternative to SIFT or SURF"", COMPUTER VISION (ICCV), 2011 IEEE INTERNATIONAL CONFERENCE ON, IEEE, 6 November 2011 (2011-11-06), pages 2564 - 2571, XP032101497, ISBN: 978-1-4577-1101-5, DOI: 10.1109/ICCV.2011.6126544;;CAO BINGYI ET AL: ""Unifying Deep Local and Global Features for Image Search"", 23 August 2020, COMPUTER VISION - ECCV 2020 : 16TH EUROPEAN CONFERENCE, GLASGOW, UK, AUGUST 23-28, 2020 : PROCEEDINGS; [LECTURE NOTES IN COMPUTER SCIENCE ; ISSN 0302-9743], PAGE(S) 726 - 743, ISBN: 978-3-030-58594-5, XP047588754;;SHORTEN CONNOR ET AL: ""A survey on Image Data Augmentation for Deep Learning"", JOURNAL OF BIG DATA, vol. 6, no. 1, 6 July 2019 (2019-07-06), pages 1 - 48, XP055850083, Retrieved from the Internet <URL:https://link.springer.com/content/pdf/10.1186/s40537-019-0197-0.pdf> [retrieved on 20200101], DOI: 10.1186/s40537-019-0197-0",PENDING
97,EP,A1,EP 4043645 A1,093-627-716-052-408,2022-08-17,2022,EP 20890154 A,2020-11-05,JP 2019210857 A;;JP 2020041308 W,2019-11-21,"ROAD SURFACE CONDITION MONITORING SYSTEM, WORK VEHICLE, ROAD SURFACE CONDITION MONITORING METHOD, AND PROGRAM","A road surface condition monitoring system according to the present invention includes: a road surface condition acquisition unit configured to acquire monitoring object information on at least a shape or size of a monitoring object existing in an area including a road surface in a direction in which a work vehicle travels by driving of a traveling mechanism, which mounts a tire, of the work vehicle; a storage unit configured to store reference information for determining whether the tire is to be damaged; a damage determination unit configured to determine, based on the monitoring object information and the reference information, whether the tire is to be damaged when the tire comes into contact with the monitoring object by the driving of the traveling mechanism; and an output unit configured to output a result determined by the damage determination unit.",KOMATSU MFG CO LTD,MURAKAMI YUYA;;ONO MASANORI,,https://lens.org/093-627-716-052-408,Patent Application,yes,0,0,7,7,0,E02F9/261;;H04N7/183;;E02F9/261,E02F9/24;;E02F9/26;;H04N7/18,,0,0,,,,PENDING
98,EP,A1,EP 4044107 A1,128-344-597-598-712,2022-08-17,2022,EP 22154346 A,2022-01-31,US 202217583607 A;;US 202163146268 P,2021-02-05,UPSCALING TRIANGULATION SCANNER IMAGES TO REDUCE NOISE,"Examples described herein provide a method that includes performing, by a processing device, using a neural network, pattern recognition on an image to recognize a feature in the image. The method further includes performing, by the processing device, upscaling of the image to increase a resolution of the image while maintaining the feature to generate an upscaled image.",FARO TECH INC,MÜLLER MICHAEL;;BALATZIS GEORGIOS,,https://lens.org/128-344-597-598-712,Patent Application,yes,2,0,2,2,0,G06T3/4046;;G06V10/82;;G06N3/08;;G06T3/4046;;G06V10/751,G06T3/40,,4,2,049-061-362-267-501;;014-937-440-189-267,10.1109/cvpr.2019.00990;;10.1016/j.petrol.2019.106261,"LI YAWEI ET AL: ""3D Appearance Super-Resolution With Deep Learning"", 2019 IEEE/CVF CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR), IEEE, 15 June 2019 (2019-06-15), pages 9663 - 9672, XP033686876, DOI: 10.1109/CVPR.2019.00990;;CHRISTIAN LEDIG ET AL: ""Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network"", 15 September 2016 (2016-09-15), XP055383327, Retrieved from the Internet <URL:https://arxiv.org/pdf/1609.04802v1.pdf> DOI: 10.1109/CVPR.2017.19;;""Advances in Databases and Information Systems"", vol. 8692, 1 January 2014, SPRINGER INTERNATIONAL PUBLISHING, Cham, ISBN: 978-3-319-10403-4, article CHAO DONG ET AL: ""Learning a Deep Convolutional Network for Image Super-Resolution"", pages: 184 - 199, XP055545078, 032682, DOI: 10.1007/978-3-319-10593-2_13;;WANG YING DA ET AL: ""Enhancing Resolution of Digital Rock Images with Super Resolution Convolutional Neural Networks"", JOURNAL OF PETROLEUM SCIENCE AND ENGINEERING, ELSEVIER, AMSTERDAM, NL, vol. 182, 12 July 2019 (2019-07-12), XP085772381, ISSN: 0920-4105, [retrieved on 20190712], DOI: 10.1016/J.PETROL.2019.106261",PENDING
99,EP,A1,EP 4036783 A1,166-052-297-581-971,2022-08-03,2022,EP 21305132 A,2021-01-29,EP 21305132 A,2021-01-29,ADVERSARIAL 3D DEFORMATIONS LEARNING,"The invention notably relates to a computer-implemented method of machine-learning. The method comprises providing a dataset of 3D modeled objects representing real-world objects. The method further comprises learning, based on the dataset, a generative neural network. The generative neural network is configured for generating a deformation basis of an input 3D modeled object. The learning comprising an adversarial training.",DASSAULT SYSTEMES,MEHR ELOI;;JOURDAN ARIANE;;JACOB PAUL,,https://lens.org/166-052-297-581-971,Patent Application,yes,0,0,4,4,0,G06F30/27;;G06N3/08;;G06T17/00;;G06F18/214;;G06F30/27;;G06N3/088;;G06T19/20;;G06T2219/2021;;G06N3/047;;G06N3/045;;G06N3/08;;G06N3/047;;G06N3/045,G06F30/27;;G06N3/04;;G06N3/08;;G06T19/20,,7,5,045-308-850-512-234;;062-955-401-586-024;;153-991-808-092-066;;000-356-373-101-611;;033-421-314-782-061,10.2514/6.2021-1690;;10.1109/iccv.2019.00827;;10.24963/ijcai.2018/688;;10.1109/cvpr.2019.00113;;10.1109/cvpr.2017.16,"WEI CHEN ET AL: ""Deep Generative Model for Efficient 3D Airfoil Parameterization and Generation"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 7 January 2021 (2021-01-07), XP081854888, DOI: 10.2514/6.2021-1690;;JERRY LIU ET AL: ""Interactive 3D Modeling with a Generative Adversarial Network"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 16 June 2017 (2017-06-16), XP080770297, DOI: 10.1109/3DV.2017.00024;;AUMENTADO-ARMSTRONG TRISTAN ET AL: ""Geometric Disentanglement for Generative Latent Shape Models"", 2019 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), IEEE, 27 October 2019 (2019-10-27), pages 8180 - 8189, XP033723956, DOI: 10.1109/ICCV.2019.00827;;WANG ZHIHUA ET AL: ""3D-PhysNet: Learning the Intuitive Physics of Non-Rigid Object Deformations"", PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, 13 July 2018 (2018-07-13), pages 4958 - 4964, XP055823996, ISBN: 978-0-9992411-2-7, DOI: 10.24963/ijcai.2018/688;;J. MAIRALF. BACHJ. PONCE: ""Sparse Modeling for Image and Vision Processing"", NEW FOUNDATIONS AND TRENDS, 2014;;W. WANGD. CEYLANR. MECHU. NEUMANN: ""3dn: 3d deformation network"", CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR, 2019;;C. QIH. SUK. MOL. GUIBAS: ""Pointnet: Deep learning on point sets for 3d classification and segmentation"", CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION (CVPR, 2017",PENDING
100,EP,B1,EP 3754592 B1,073-833-469-594-825,2022-07-27,2022,EP 20190447 A,2018-12-26,KR 20170180036 A;;EP 18894837 A;;KR 2018016678 W,2017-12-26,IMAGE ACQUISITION DEVICE AND METHOD OF CONTROLLING THE SAME,,SAMSUNG ELECTRONICS CO LTD,JUNG JAEHO;;SUNG YEULTAK,,https://lens.org/073-833-469-594-825,Granted Patent,yes,0,0,12,17,0,G06T7/0002;;G06N3/04;;G06N3/08;;G06T2207/10004;;G06T2207/20084;;G06T2207/20081;;G06T2207/20104;;G06T2207/30196;;G06T5/50;;G06T2207/10016;;G06T2207/20221;;G06T5/77;;G06T5/60;;G06T1/0007;;G06T7/11;;G06T7/20;;G06T2207/20084;;G06T5/00,G06T5/00,,2,2,187-691-405-441-697;;154-698-951-744-278,10.1016/j.patcog.2017.09.040;;10.1109/avss.2017.8078547,"BABAEE MOHAMMADREZA ET AL: ""A deep convolutional neural network for video sequence background subtraction"", PATTERN RECOGNITION, ELSEVIER, GB, vol. 76, 29 September 2017 (2017-09-29), pages 635 - 649, XP085329740, ISSN: 0031-3203, DOI: 10.1016/J.PATCOG.2017.09.040;;LIM KYUNGSUN ET AL: ""Background subtraction using encoder-decoder structured convolutional neural network"", 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), IEEE, 29 August 2017 (2017-08-29), pages 1 - 6, XP033233444, DOI: 10.1109/AVSS.2017.8078547",ACTIVE
101,EP,B1,EP 3705367 B1,129-541-191-328-877,2022-07-27,2022,EP 19160830 A,2019-03-05,EP 19160830 A,2019-03-05,TRAINING A GENERATOR UNIT AND A DISCRIMINATOR UNIT FOR COLLISION-AWARE TRAJECTORY PREDICTION,,BAYERISCHE MOTOREN WERKE AG,VAN DER HEIDEN TESSA;;COCCIA GIUSEPPE,,https://lens.org/129-541-191-328-877,Granted Patent,yes,4,0,5,5,0,B60W30/095;;B60W40/00;;B60W40/02;;G06N3/04;;G08G1/166;;B60W30/0956;;G06N3/006;;G06N3/08;;G06N3/044;;G06N3/045;;G05D1/0289;;B60W60/0025;;B60W60/00272;;B60W60/0011;;B60W60/00274,B60W30/095;;G06N3/04;;G06N3/08;;G08G1/16,,0,0,,,,ACTIVE
102,EP,A1,EP 4033411 A1,050-878-539-359-439,2022-07-27,2022,EP 21153512 A,2021-01-26,EP 21153512 A,2021-01-26,SYNTHESIZING MOBILITY TRACES,"Methods for training a first machine learning model (18), which is a sequential generative model, and a second machine learning model (24), which is a sequence-to-sequence model, with a training data set (1) comprising a plurality (16) of specific routes (3) and with a plurality (17) of generic routes (8) mapped from the specific routes (3). And a method for synthesizing mobility traces comprising: generating a plurality (29) of synthetic generic routes (22), each synthetic generic route (22) comprising an ordered sequence of synthetic generic positions (23), and generating a plurality (30) of synthetic specific routes (27) using the plurality (29) of synthetic generic routes (22), wherein each synthetic specific route (27) corresponds to a synthetic generic route (22) and comprises a corresponding ordered sequence of synthetic specific positions (28), wherein the synthetic specific positions (28) have a finer granularity than the synthetic generic positions (23).",MOSTLY AI SOLUTIONS MP GMBH,KALCHER KLAUDIUS;;PLATZER MICHAEL;;SOUKUP DANIEL,,https://lens.org/050-878-539-359-439,Patent Application,yes,2,0,2,2,0,G06N20/00;;H04W4/025;;H04W4/029;;G06N3/08;;G06N3/047;;G06N7/01;;G06N3/045;;G06N20/20;;G06F18/23,G06N3/04;;G06N3/08;;G06N20/00,,6,3,036-682-009-390-031;;065-110-918-832-958;;069-179-048-530-139,10.1109/mipr.2019.00086;;10.15439/2019f320;;10.1109/icde48307.2020.00087,"HUANG DOU ET AL: ""A Variational Autoencoder Based Generative Model of Urban Human Mobility"", 2019 IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR), IEEE, 28 March 2019 (2019-03-28), pages 425 - 430, XP033541067, DOI: 10.1109/MIPR.2019.00086;;VINCENT BINDSCHAEDLER ET AL: ""Privacy through Fake yet Semantically Real Traces"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 27 May 2015 (2015-05-27), XP080803257;;SONG HA YOON ET AL: ""Generating Human Mobility Route Based on Generative Adversarial Network"", 2019 FEDERATED CONFERENCE ON COMPUTER SCIENCE AND INFORMATION SYSTEMS (FEDCSIS), POLISH INFORMATION PROCESSING SOCIETY -- AS SINCE 2011, 1 September 2019 (2019-09-01), pages 91 - 99, XP033626353, DOI: 10.15439/2019F320;;LIU YIDING ET AL: ""Online Anomalous Trajectory Detection with Deep Generative Sequence Modeling"", 2020 IEEE 36TH INTERNATIONAL CONFERENCE ON DATA ENGINEERING (ICDE), IEEE, 20 April 2020 (2020-04-20), pages 949 - 960, XP033774238, DOI: 10.1109/ICDE48307.2020.00087;;KUMAR, A.BISWAS, A.SANYAL, S. ET AL.: ""eCommerceGAN: A Generative Adversarial Network for E-commerce"", ARXIV:1801.03244, 2018;;VASWANI ET AL.: ""Attention Is All You Need"", ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS, 2017, pages 5998 - 6008",DISCONTINUED
103,EP,A1,EP 4029449 A1,061-612-756-420-196,2022-07-20,2022,EP 22150732 A,2022-01-10,US 202163135398 P,2021-01-08,"SYSTEMS, DEVICES, COMPONENTS AND METHODS FOR DETECTING THE LOCATIONS OF SOURCES OF CARDIAC RHYTHM DISORDERS IN A PATIENT'S HEART USING IMPROVED ELECTROGRAPHIC FLOW (EGF) METHODS","Disclosed are various examples and embodiments of systems, devices, components and methods configured to estimate the action potential wave propagation in a patient's heart, and subsequently to detect at least one location or type of at least one source of, or rotational phenomenon associated with, at least one cardiac rhythm disorder using intracardiac electrodes and a modified multiframe Horn-Schunck algorithm to generate a map corresponding to a spatial map, the map being configured to reveal on a monitor or display to a user the at least one location of the at least one source of the at least one cardiac rhythm disorder.",ABLACON INC,RUPPERSBERG PETER,,https://lens.org/061-612-756-420-196,Patent Application,yes,7,0,1,55,0,A61B5/287;;A61B5/361;;A61B5/367;;A61B5/6852,A61B5/287;;A61B5/00;;A61B5/367,,35,27,031-064-185-006-887;;095-222-233-809-186;;048-826-202-539-34X;;071-230-472-487-320;;039-707-281-293-449;;028-260-992-581-773;;149-761-705-121-233;;021-268-460-970-243;;147-006-097-597-470;;039-707-281-293-449;;196-241-402-408-136;;017-438-154-343-684;;033-928-519-356-675;;150-661-098-718-27X;;015-468-435-995-982;;048-356-837-959-002;;031-064-185-006-887;;000-525-871-634-677;;012-309-556-586-176;;007-651-830-094-805;;010-928-630-248-934;;007-692-789-290-847;;000-704-821-265-854;;018-550-414-509-756;;016-938-750-502-99X;;023-350-337-170-107;;144-944-103-738-244,30773268;;10.1016/j.ijcard.2019.02.006;;10.3389/fphys.2018.00208;;pmc5859379;;29593566;;20937979;;10.1161/circulationaha.109.910901;;10.1016/0002-9149(82)90003-0;;7090993;;10.1007/s11004-011-9346-5;;10.1023/a:1021713421882;;10.1007/bf00893171;;10.1029/gl014i002p00139;;10.1016/j.cageo.2008.08.012;;10.1007/s11004-011-9346-5;;10.2307/2007507;;10.5201/ipol.2013.20;;10.1016/0004-3702(81)90024-2;;10.1023/b:visi.0000045324.43199.43;;23516352;;pmc3597547;;10.1371/journal.pcbi.1002970;;25768978;;10.1371/journal.pone.0118746;;pmc4358999;;30773268;;10.1016/j.ijcard.2019.02.006;;10.1007/s00392-018-1274-7;;29744616;;pmc7733961;;33330650;;10.3389/fcvm.2020.587945;;10.1371/journal.pone.0141573;;pmc4629897;;26523732;;10.1016/j.hrthm.2014.05.013;;pmc4292884;;24846374;;pmc5833527;;10.1001/jamacardio.2017.4665;;29128866;;10.1161/01.cir.95.5.1231;;9054854;;10.1161/circulationaha.105.575340;;16461834;;26835111;;pmc4711559;;10.15420/aer.2015.04.02.109;;pmc3124959;;21349400;;10.1016/j.jacc.2010.09.066;;10.1161/circep.111.965145;;21984446,"BELLMANN BARBARA ET AL: ""Velocity characteristics of atrial fibrillation sources determined by electrographic flow mapping before and after catheter ablation"", INTERNATIONAL JOURNAL OF CARDIOLOGY, vol. 286, 11 February 2019 (2019-02-11), pages 56 - 60, XP085665774, ISSN: 0167-5273, DOI: 10.1016/J.IJCARD.2019.02.006;;GONZALO R. RÍOS-MUÑOZ ET AL: ""Real-Time Rotational Activity Detection in Atrial Fibrillation"", FRONTIERS IN PHYSIOLOGY, vol. 9, 13 March 2018 (2018-03-13), CH, XP055613759, ISSN: 1664-042X, DOI: 10.3389/fphys.2018.00208;;DE GROOT MS ET AL.: ""Electropathological Substrate of Longstanding Persistent Atrial Fibrillation in Patients with Structural Heart Disease Epicardial Breakthrough"", CIRCULATION, vol. 3, 2010, pages 1674 - 1682;;SANGHAMITRA MOHANTYANDREA NATALE ET AL., J AM COLL CARDIOL, 2016;;D. CURTIS DENOKUMARASWAMY NANTHAKUMAR ET AL.: ""Novel Strategy for Improved Substrate Mapping of the Atria: Omnipolar Catheter and Signal Processing Technology Assesses Electrogram Signals Along Physiologic and Anatomic Directions"", CIRCULATION, vol. 132, 2015, pages A19778;;M. E. JOSEPHSON ET AL.: ""VENTRICULAR ENDOCARDIAL PACING II, The Role of Pace Mapping to Localize Origin of Ventricular Tachycardia"", THE AMERICAN JOURNAL OF CARDIOLOGY, vol. 50, November 1982 (1982-11-01);;XINGSHENG DENGZHONG-AN TANG: ""Moving Surface Spline Interpolation Based on Green's Function"", MATH. GEOSCI, vol. 43, 2011, pages 663 - 680, XP019933892, DOI: 10.1007/s11004-011-9346-5;;PAUL WESSELDAVID BERCOVICI: ""Interpolation with Splines in Tension: A Green's Function Approach"", MATHEMATICAL GEOLOGY, vol. 30, no. 1, 1998, pages 77 - 93;;MITASOVA, H.L. MITAS: ""Interpolation by regularized spline with tension: I. Theory and implementation"", MATH. GEOL., vol. 25, 1993, pages 641 - 655;;PARKER, R. L.: ""Geophysical Inverse Theory"", 1994, PRINCETON UNIV. PRESS, pages: 386;;SANDWELL, D. T.: ""Biharmonic spline interpolation of Geos-3 and Seasat altimeter data"", GEOPHYS. RES. LETT., vol. 14, 1987, pages 139 - 142;;WESSEL, P.J. M. BECKER: ""Interpolation using a generalized Green's function for a spherical surface spline in tension"", GEOPHYS. J. INT, vol. 174, 2008, pages 21 - 28;;WESSEL, P.: ""A general-purpose Green's function interpolator"", COMPUTERS & GEOSCIENCES, vol. 35, 2009, pages 1247 - 1254, XP026023518, DOI: 10.1016/j.cageo.2008.08.012;;XINGSHENG DENGZHONG-AN TANG: ""Moving Surface Spline Interpolation Based on Green's Function"", MATHEMATICAL GEOSCIENCES, vol. 43, August 2011 (2011-08-01), pages 663 - 680, XP019933892, DOI: 10.1007/s11004-011-9346-5;;V. BARNETT: ""Interpreting Multivariate Data"", JOHN WILEY, article ""A brief description of natural neighbor interpolation (Chapter 2"", pages: 21 - 36;;P. LANCASTER ET AL.: ""Surfaces generated by Moving Least Squares Methods"", MATHEMATICS OF COMPUTATION, vol. 37, no. 155, July 1981 (1981-07-01), pages 141 - 158;;MICHAEL TAO ET AL.: ""SimpleFlow: A Non-Iterative, Sublinear Optical Flow Algorithm"", EUROGRAPHICS, vol. 31, no. 2, 2012;;ENRIC MEINHARDT-LLOPIS ET AL.: ""Horn-Schunck Optical Flow with a Multi-Scale Strategy"", IMAGE PROCESSING ON LINE, vol. 3, 2013, pages 151 - 172;;B. K. P. HORNB. G. SCHUNCK: ""Determining Optical Flow"", ARTIFICIAL INTELLIGENCE, vol. 17, 1981, pages 185 - 204;;BRUCE D. LUCASETAKEO KANADE: ""An Iterative Image Registration Technique with an Application to Stereo Vision"", PROCEEDINGS OF IMAGING UNDERSTANDING WORKSHOP, 1981, pages 121 - 130;;ANDRES BRUHNJOACHIM WEICKERTCHRISTOPH SCHNORR: ""International Journal of Computer Vision"", vol. 61, February 2005, article ""Lucas/Kanade Meets Horn/Schunck: Combining Local and Global Optic Flow Methods"", pages: 211 - 231;;GARY R. MIRAMS ET AL.: ""Chaste: An Open Source C++ Library for Computational Physiology and Biology"", PLOS COMPUTATIONAL BIOLOGY, vol. 9, 14 March 2013 (2013-03-14), pages e1002970;;CARRICKR. T. CARRICKP. S. SPECTOR ET AL.: ""Prospectively Quantifying the Propensity for Atrial Fibrillation: A Mechanistic Formulation"", PLOS ONE, 13 March 2015 (2015-03-13);;BELLMANN ET AL.: ""Velocity characteristics of atrial fibrillation sources determined by electrographic flow mapping before and after catheter ablation"", INTERNATIONAL JOURNAL OF CARDIOLOGY, vol. 286, 1 July 2019 (2019-07-01), pages 56 - 60, XP085665774, Retrieved from the Internet <URL:https://doi.Org/10.1016/j.ijcard.2019.02.006> DOI: 10.1016/j.ijcard.2019.02.006;;""Identification of active atrial fibrillation sources and their discrimination from passive rotors using electrographical flow mapping"", CLINICAL RESEARCH IN CARDIOLOGY, May 2018 (2018-05-01);;BELLMANN ET AL.: ""Electrographic Flow Mapping - A Novel Technology for Endocardial Driver Identification in Patients with Persistent Atrial Fibrillation"", POSTER SESSION IV, C-P004-76, S356 HEART RHYTHM, vol. 14, no. 5, May 2017 (2017-05-01);;MURALI ET AL.: ""Cardiac Ambulatory Monitoring: New Wireless Device Validated Against Conventional Holter Monitoring in a Case Series"", FRONT. CARDIOVASC. MED., 30 November 2020 (2020-11-30), Retrieved from the Internet <URL:https://doi.org/10.3389/fcvm.2020.587945>;;FERRER ET AL.: ""Detailed Anatomical and Electrophysiological Models of Human Atria and Torso for the Simulation of Atrial Activation"", PLOS ONE, 2 November 2015 (2015-11-02);;RODRIGO ET AL.: ""Body surface localization of left and right atrial high-frequency rotors in atrial fibrillation patients: A clinical-computational study"", HEART RHYTHM, vol. 11, no. 9, September 2014 (2014-09-01), pages 1584 - 1591;;TAKU INOHARA ET AL.: ""Association of Atrial Fibrillation Clinical Phenotypes With Treatment Patterns and Outcomes: A Multicenter Registry Study"", JAMA CARDIOL, vol. 3, no. 1, 2018, pages 54 - 63;;KONINGS ET AL.: ""Configuration of unipolar atrial electrograms during electrically induced atrial fibrillation in humans"", CIRCULATION, vol. 95, 1997, pages 1231 - 41;;KALIFA ET AL.: ""Mechanisms of wave fractionation at boundaries of high frequency excitation in the posterior left atrium of the isolated sheep heart during atrial fibrillation"", CIRCULATION, vol. 113, 2006, pages 626 - 33, XP008162689, DOI: 10.1161/​CIRCULATIONAHA.105.575340;;SOHAL ET AL.: ""Is Mapping of Complex Fractionated Electrograms Obsolete"", ARRHYTHM. ELECTROPHYSIOL. REV., vol. 4, no. 2, August 2015 (2015-08-01), pages 109 - 115;;ATIENZA ET AL.: ""Mechanisms of Fractionated Electrograms Formation in the Posterior Left Atrium During Paroxysmal Atrial Fibrillation in Humans"", J AM COLL CARDIOL., vol. 57, no. 9, 1 March 2011 (2011-03-01), pages 1081 - 1092, XP028149072, DOI: 10.1016/j.jacc.2010.09.066;;CORREA DE SA ET AL.: ""Electrogram Fractionation - The Relationship between Spatiotemporal Variation of Tissue Excitation and Electrode Spatial Resolution"", CIRC. ARRHYTHM. ELECTROPHYSIOL., vol. 4, no. 6, December 2011 (2011-12-01), pages 909 - 16, XP055268279, DOI: 10.1161/CIRCEP.111.965145",PENDING
104,EP,A1,EP 4024369 A1,048-851-631-018-942,2022-07-06,2022,EP 21208636 A,2021-11-16,US 202117140275 A,2021-01-04,FLIGHT LEG TERMINATION VISUALIZATION SYSTEMS AND METHODS FOR FLIGHT LEG TERMINATION VISUALIZATION,"Various flight leg visualization techniques are enabled. For instance, a method comprises retrieving, by a flight management system from a navigation database, a route of an aircraft associated with the flight management system, determining, by the flight management system, leg terminations on the route, determining, by the flight management system, a leg termination of the leg terminations to display, and displaying, by the flight management system, the leg termination.",GE AVIATION SYSTEMS LLC,EDWARDS SCOTT,,https://lens.org/048-851-631-018-942,Patent Application,yes,2,0,3,3,0,G08G5/003;;G06F16/248;;G06F16/29;;G06N20/00;;G08G5/0034;;G08G5/0034;;G08G5/0021;;G08G5/0047;;G08G5/003;;G06F16/26;;G06F16/29,G08G5/00,,0,0,,,,PENDING
105,EP,A1,EP 4021027 A1,106-679-992-016-504,2022-06-29,2022,EP 21209135 A,2021-11-18,US 202017133125 A,2020-12-23,DISTRIBUTED LEARNING TO LEARN CONTEXT-SPECIFIC DRIVING PATTERNS,"A method of implementing distributed AI or ML learning for autonomous vehicles is disclosed. An AI or ML model specific to a location or a type of the location is generated at a vehicle. In response to a detection that the vehicle is within a proximity to a road side unit (RSU) associated with the location or the type of the location or the vehicle is within a proximity to an additional vehicle that is present or anticipated to be present at the location or the type of the location, causing an AI or ML model transmission to the additional vehicle or the RSU. Based on the causing the AI or ML model reception, causing deployment of an additional AI or ML model in the vehicle to optimize the vehicle for the location or the type of the location.",INTEL CORP,HIMAYAT NAGEEN;;GUPTA HYDE MARUTI;;BALAKRISHNAN RAVIKUMAR;;AKDENIZ MUSTAFA;;SPOCZYNSKI MARCIN,,https://lens.org/106-679-992-016-504,Patent Application,yes,3,0,3,3,0,G06F30/27;;G06N3/04;;G06N3/08;;G06N20/00;;B60W50/06;;B60W60/00;;B60W2420/403;;B60W2420/54;;B60W2556/65;;G06N20/00;;G06V10/764;;G06V20/56;;H04W4/21;;H04W4/40;;H04W4/44;;H04W4/46;;B60W50/06;;B60W60/00;;B60W2420/403;;B60W2420/408;;B60W2420/54;;B60W2556/65;;G06F18/214;;G06N5/04;;G06N20/00;;G06V10/764;;G06V20/56,H04W4/40;;B60W50/06;;B60W60/00;;G06V10/764;;H04W4/21;;H04W4/44;;H04W4/46,,1,1,089-941-801-607-915,10.1109/tits.2020.3017474,"YU ZHENGXIN ET AL: ""Mobility-Aware Proactive Edge Caching for Connected Vehicles Using Federated Learning"", IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, IEEE, PISCATAWAY, NJ, USA, vol. 22, no. 8, 31 August 2020 (2020-08-31), pages 5341 - 5351, XP011871215, ISSN: 1524-9050, [retrieved on 20210806], DOI: 10.1109/TITS.2020.3017474",PENDING
106,EP,A1,EP 4020108 A1,027-843-944-380-940,2022-06-29,2022,EP 21195750 A,2021-09-09,US 202017130030 A,2020-12-22,AUTOMATED MACHINE COLLABORATION,"According to various aspects, controller for an automated machine may include: a processor configured to: compare information about a function of the automated machine with information of a set of tasks available to a plurality of automated machines; negotiate, with the other automated machines of the plurality of automated machines and based on a result of the comparison, which task of the set of tasks is allocated to the automated machine.",INTEL CORP,POORNACHANDRAN RAJESH;;TICKOO OMESH;;TARKHANYAN ANAHIT;;HONKOTE VINAYAK;;MO STANLEY,,https://lens.org/027-843-944-380-940,Patent Application,yes,3,0,2,2,0,B25J9/1682;;B25J9/0084;;B25J9/1661;;G05B19/042;;G05B19/41865;;G05B2219/32328;;B25J13/006;;G05B2219/32328,G05B19/418;;B25J9/16,,0,0,,,,PENDING
107,EP,B1,EP 3635605 B1,007-545-981-260-330,2022-06-15,2022,EP 18838530 A,2018-07-24,US 201762536042 P;;KR 20170142106 A;;KR 2018008355 W,2017-07-24,ELECTRONIC DEVICE AND METHOD FOR CONTROLLING THE ELECTRONIC DEVICE,,SAMSUNG ELECTRONICS CO LTD,KANG SEONG-MIN;;HAN HEUNG-WOO,,https://lens.org/007-545-981-260-330,Granted Patent,yes,8,0,11,11,0,H04N1/444;;H04N1/4413;;G06F21/602;;G06F21/46;;G06F21/62;;G06N3/08;;G06T9/002;;G06T2207/20081;;G06T2207/20084;;G06V10/761;;H04N21/2347;;H04N21/4405;;H04N1/444;;H04N1/4413;;H04N19/126,G06F21/60;;G06F21/46;;G06F21/62;;G06N3/08;;G06T7/00;;G06T9/00;;H04N21/2347;;H04N21/4405,,0,0,,,,ACTIVE
108,EP,A1,EP 4009287 A1,142-317-678-618-598,2022-06-08,2022,EP 21195098 A,2021-09-06,US 202017112967 A,2020-12-04,DEVICES AND METHODS FOR MONITORING DRIVERS OF VEHICLES,An apparatus includes: a camera configured to view a driver of a vehicle; and a processing unit configured to receive an image of the driver from the camera; wherein the processing unit is configured to process the image of the driver to determine whether the driver is engaged with a driving task or not; and wherein the processing unit is configured to determine whether the driver is engaged with the driving task or not based on a pose of the driver as it appears in the image without a need to determine a gaze direction of an eye of the driver.,NAUTO INC,ALPERT BENJAMIN OREN;;KONIECZNY JACEK JAKUB;;ZHANG SHUKUI,,https://lens.org/142-317-678-618-598,Patent Application,yes,1,0,3,3,0,G06V20/597;;G06V10/82;;G06V20/56;;G06V40/161;;G06V40/172;;G06V40/197;;G06V20/597;;G06F18/2413;;G06F18/2431;;G06T7/70;;G06T2207/20081;;G06T2207/20084;;G06T2207/30201,G06V10/82;;G06V20/56;;G06V20/59;;G06V40/16;;G06V40/18,,1,1,085-433-213-997-578,10.1109/tits.2015.2396031,"FRANCISCO VICENTE ET AL: ""Driver Gaze Tracking and Eyes Off the Road Detection System"", IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS, vol. 16, no. 4, 1 August 2015 (2015-08-01), Piscataway, NJ, USA, pages 2014 - 2027, XP055360541, ISSN: 1524-9050, DOI: 10.1109/TITS.2015.2396031",PENDING
109,EP,A1,EP 4002275 A1,000-546-594-186-310,2022-05-25,2022,EP 21207544 A,2021-11-10,US 202016953517 A,2020-11-20,SYSTEM AND METHOD FOR VISUALIZING PLACEMENT OF A MEDICAL TUBE OR LINE,"An image processing system is provided. The image processing system includes a display, a processor, and a memory. The memory stores processor-executable code that when executed by the processor causes receiving an image of a region of interest of a patient with a medical tube or line disposed within the region of interest, detecting the medical tube or line within the image, generating a combined image by superimposing a first graphical marker on the image that indicates an end of the medical tube or line, and displaying the combined image on the display.",GE PREC HEALTHCARE LLC,BAENEN ALEC JOSEPH;;TEGZES PAL;;TOROK LEVENTE;;FISCHER TERI LYNN;;NYE KATELYN ROSE;;RAO GIREESHA CHINTHAMANI,,https://lens.org/000-546-594-186-310,Patent Application,yes,1,0,4,5,0,G16H30/20;;G06T11/60;;G06N3/08;;G06N3/045;;G06T7/73;;G06T11/60;;G06T2207/10116;;G06T2207/20084;;G06T2207/30021;;G06T2207/30061;;G06T2207/30092;;G06T7/74;;G16H20/40;;G16H30/40;;G06T7/0014;;G06T11/00;;G06T2207/20081;;G06T2207/20084;;G06T2207/30021,G06T7/73;;G06T11/60,,4,4,124-979-936-210-115;;053-762-322-108-860;;020-264-074-202-508;;120-749-306-914-901,10.1117/12.2043826;;pmc8017400;;10.1148/ryai.2020190082;;33937813;;pmc5537094;;28600640;;10.1007/s10278-017-9980-7;;10.1007/978-3-030-32226-7_87,"HUO ZHIMIN ET AL: ""Computer-aided detection of malpositioned endotracheal tubes in portable chest radiographs"", PROGRESS IN BIOMEDICAL OPTICS AND IMAGING, SPIE - INTERNATIONAL SOCIETY FOR OPTICAL ENGINEERING, BELLINGHAM, WA, US, vol. 9035, 24 March 2014 (2014-03-24), pages 90350K - 90350K, XP060030535, ISSN: 1605-7422, ISBN: 978-1-5106-0027-0, DOI: 10.1117/12.2043826;;XIN YI ET AL: ""Computer-Aided Assessment of Catheters and Tubes on Radiographs: How Good is Artificial Intelligence for Assessment?"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 9 February 2020 (2020-02-09), XP081596695, DOI: 10.1148/RYAI.2020190082;;LAKHANI PARAS: ""Deep Convolutional Neural Networks for Endotracheal Tube Position and X-ray Image Classification: Challenges and Opportunities"", JOURNAL OF DIGITAL IMAGING, SPRINGER INTERNATIONAL PUBLISHING, CHAM, vol. 30, no. 4, 9 June 2017 (2017-06-09), pages 460 - 468, XP036288395, ISSN: 0897-1889, [retrieved on 20170609], DOI: 10.1007/S10278-017-9980-7;;FRID-ADAR MAAYAN ET AL: ""Endotracheal Tube Detection and Segmentation in Chest Radiographs Using Synthetic Data"", 10 October 2019, COMPUTER VISION - ECCV 2020 : 16TH EUROPEAN CONFERENCE, GLASGOW, UK, AUGUST 23-28, 2020 : PROCEEDINGS; [LECTURE NOTES IN COMPUTER SCIENCE ; ISSN 0302-9743], SPRINGER INTERNATIONAL PUBLISHING, CHAM, PAGE(S) 784 - 792, ISBN: 978-3-030-58594-5, XP047522409",PENDING
110,EP,A1,EP 4001196 A1,192-363-363-917-703,2022-05-25,2022,EP 20207456 A,2020-11-13,EP 20207456 A,2020-11-13,SUSTAINABLE PNEUMATIC ELEVATOR SYSTEM AND METHODS,"The present disclosure relates to elevator technology. In particular, the present disclosure relates to an elevator system using a novel powering scheme. Further in particular, the present disclosure relates to an elevator system using a pressurised gas to power at least a part of the elevator system.Accordingly, there is provided an elevator system (200), comprising an elevator car (112) and an elevator drive (224) adapted to move the elevator car in an elevator shaft (302), wherein the elevator system further comprises a gas reservoir (204,a,b), wherein the gas reservoir is adapted for storing of a pressurized gas, wherein the gas reservoir is connected to an element of the elevator system for powering at least a part of the elevator system, and wherein the element is at least one element of a pneumatic elevator drive (224) and a generator (238). Further, there is provided a method of operating the elevator system and for modernizing an elevator system.",HENNEAU PHILIPPE,HENNEAU PHILIPPE,,https://lens.org/192-363-363-917-703,Patent Application,yes,8,0,5,5,0,B66B9/04;;B66B1/302;;B66B5/027;;Y02B50/00;;B66B9/04;;B66B1/2433;;B66B1/302;;B66B5/027,B66B9/04;;B66B1/30;;B66B5/02,,0,0,,,,DISCONTINUED
111,EP,A1,EP 3988009 A1,129-676-022-800-980,2022-04-27,2022,EP 20202901 A,2020-10-20,EP 20202901 A,2020-10-20,METHOD AND SYSTEM FOR AUTOMATICALLY MONITORING AND DETERMINING THE QUALITY OF LIFE OF A PATIENT,"A computer-implemented method for automatically monitoring and determining the quality of life of a patient, comprises the steps of a) acquiring therapy data concerning a medical therapy that is performed by a medical device on the patient, and b) determining at least one quantifiable score which can be associated with the quality of life of the patient based on the therapy data.",FRESENIUS MEDICAL CARE DEUTSCHLAND GMBH,SCHERER LENA;;BOTLER MAX,,https://lens.org/129-676-022-800-980,Patent Application,yes,15,0,5,5,0,A61B5/4848;;A61B5/1112;;A61B5/1123;;A61B5/16;;A61B5/486;;A61B5/6803;;A61B5/743;;G06N3/044;;G06N3/045;;G06N3/08;;G06N20/00;;G16H40/67;;G16H50/20;;G16H50/30;;G16H50/30;;A61B5/4848;;G16H10/60;;G16H20/40;;G16H40/20;;G16H50/20,A61B5/00;;A61B5/11;;A61B5/16;;G06N3/08;;G16H40/67,,0,0,,,,DISCONTINUED
112,EP,B1,EP 3682415 B1,143-195-622-089-141,2022-04-27,2022,EP 18894837 A,2018-12-26,KR 20170180036 A;;KR 2018016678 W,2017-12-26,IMAGE ACQUISITION DEVICE AND METHOD OF CONTROLLING THE SAME,,SAMSUNG ELECTRONICS CO LTD,JUNG JAEHO;;SUNG YEULTAK,,https://lens.org/143-195-622-089-141,Granted Patent,yes,5,0,12,17,0,G06T7/0002;;G06N3/04;;G06N3/08;;G06T2207/10004;;G06T2207/20084;;G06T2207/20081;;G06T2207/20104;;G06T2207/30196;;G06T5/50;;G06T2207/10016;;G06T2207/20221;;G06T5/77;;G06T5/60;;G06T1/0007;;G06T7/11;;G06T7/20;;G06T2207/20084;;G06T5/00,G06T5/00,,2,0,,,"CHAO YANG ET AL: ""High-Resolution Image Inpainting using Multi-Scale Neural Patch Synthesis"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 30 November 2016 (2016-11-30), XP080735402, DOI: 10.1109/CVPR.2017.434;;CHAO YANG et al.: ""High-Resolution Image Inpainting Using Multi-scale Neural Patch Synthesis"", 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR, 21 July 2017 (2017-07-21), pages 4076-4084, XP033249760, DOI: doi:10.1109/CVPR.2017.434",ACTIVE
113,EP,A1,EP 3984457 A1,191-926-046-625-344,2022-04-20,2022,EP 21202891 A,2021-10-15,US 202063092485 P,2020-10-15,"SYSTEMS, DEVICES, COMPONENTS AND METHODS FOR DETECTING THE LOCATIONS OF SOURCES OF CARDIAC RHYTHM DISORDERS IN A PATIENT S HEART USING BODY SURFACE ELECTRODES AND/OR CARDIAC MONITORING PATCHES","Disclosed are various examples and embodiments of systems, devices, components and methods configured to classify, and to detect at least one location or type of at least one source of, at least one cardiac rhythm disorder in a patient's heart using one or more body surface electrodes, and/or intracardiac electrodes. Body surface electrogram data, and optionally intracardiac electrode data, representative of cardiac signals acquired from the patient are provided to a computing device, which in turn determines the location and type of the at least one source of the at least one cardiac rhythm disorder in the patient's heart using electrographic flow (EGF) methods, and then classifies same using electrographic volatility index (EVI) methods.",ABLACON INC,RUPPERSBERG PETER;;HAEUSSER PHILIP;;KONG MELISSA HUANG SZU-MIN;;KOBLISH JOSEF VINCENT,,https://lens.org/191-926-046-625-344,Patent Application,yes,34,0,1,55,0,A61B5/361;;A61B5/7264,A61B5/361;;A61B5/00,,47,36,048-826-202-539-34X;;001-582-601-347-122;;071-230-472-487-320;;039-707-281-293-449;;028-260-992-581-773;;149-761-705-121-233;;021-268-460-970-243;;147-006-097-597-470;;039-707-281-293-449;;196-241-402-408-136;;017-438-154-343-684;;033-928-519-356-675;;150-661-098-718-27X;;015-468-435-995-982;;048-356-837-959-002;;031-064-185-006-887;;000-525-871-634-677;;012-309-556-586-176;;007-651-830-094-805;;010-928-630-248-934;;007-692-789-290-847;;000-704-821-265-854;;018-550-414-509-756;;016-938-750-502-99X;;023-350-337-170-107;;144-944-103-738-244;;016-214-585-496-499;;031-784-299-941-49X;;027-378-065-907-645;;011-395-729-801-485;;019-969-334-739-112;;113-051-890-031-359;;035-803-421-731-08X;;019-725-764-145-567;;002-452-625-703-911;;120-467-893-225-178,20937979;;10.1161/circulationaha.109.910901;;30144981;;10.1016/j.ahj.2018.05.021;;10.1016/0002-9149(82)90003-0;;7090993;;10.1007/s11004-011-9346-5;;10.1023/a:1021713421882;;10.1007/bf00893171;;10.1029/gl014i002p00139;;10.1016/j.cageo.2008.08.012;;10.1007/s11004-011-9346-5;;10.2307/2007507;;10.5201/ipol.2013.20;;10.1016/0004-3702(81)90024-2;;10.1023/b:visi.0000045324.43199.43;;23516352;;pmc3597547;;10.1371/journal.pcbi.1002970;;25768978;;10.1371/journal.pone.0118746;;pmc4358999;;30773268;;10.1016/j.ijcard.2019.02.006;;10.1007/s00392-018-1274-7;;29744616;;pmc7733961;;33330650;;10.3389/fcvm.2020.587945;;10.1371/journal.pone.0141573;;pmc4629897;;26523732;;10.1016/j.hrthm.2014.05.013;;pmc4292884;;24846374;;pmc5833527;;10.1001/jamacardio.2017.4665;;29128866;;10.1161/01.cir.95.5.1231;;9054854;;10.1161/circulationaha.105.575340;;16461834;;26835111;;pmc4711559;;10.15420/aer.2015.04.02.109;;pmc3124959;;21349400;;10.1016/j.jacc.2010.09.066;;10.1161/circep.111.965145;;21984446;;10.1093/europace/eus027;;22389422;;26498718;;10.1093/europace/euv323;;pmc4676081;;24682347;;10.1161/cir.0000000000000041;;10.1161/cir.0000000000000040;;24682348;;10.1016/j.jacc.2014.04.019;;24814497;;10.1111/j.1540-8159.2011.03284.x;;22150125;;pmc6680367;;31071213;;10.1093/europace/euz108;;23483336;;10.1007/s10840-013-9782-x;;pmc3606509;;31744331;;10.1161/circulationaha.119.042706;;pmc7043236;;10.1161/circep.114.001672;;25744570;;32078374;;10.1161/circep.119.007700;;pmc7508259,"DE GROOT MS ET AL.: ""Electropathological Substrate of Longstanding Persistent Atrial Fibrillation in Patients with Structural Heart Disease Epicardial Breakthrough"", CIRCULATION, vol. 3, 2010, pages 1674 - 1682;;SANGHAMITRA MOHANTY, OASIS, IMPACT OF ROTOR ABLATION IN NON-PAROXYSMAL AF PATIENTS: RESULTS FROM A RANDOMIZED TRIAL;;ANDREA NATALE, J AM COLL CARDIOL., 2016;;D. CURTIS DENO, NOVEL STRATEGY FOR IMPROVED SUBSTRATE MAPPING OF THE ATRIA: OMNIPOLAR CATHETER AND SIGNAL PROCESSING TECHNOLOGY ASSESSES ELECTROGRAM SIGNALS ALONG PHYSIOLOGIC AND ANATOMIC DIRECTIONS;;KUMARASWAMY NANTHAKUMAR, CIRCULATION, vol. 132, 2015, pages A19778;;M. E. JOSEPHSON ET AL.: ""VENTRICULAR ENDOCARDIAL PACING II, The Role of Pace Mapping to Localize Origin of Ventricular Tachycardia"", THE AMERICAN JOURNAL OF CARDIOLOGY, vol. 50, November 1982 (1982-11-01);;XINGSHENG DENGZHONG-AN TANG: ""Moving Surface Spline Interpolation Based on Green's Function"", MATH. GEOSCI, vol. 43, 2011, pages 663 - 680, XP019933892, DOI: 10.1007/s11004-011-9346-5;;PAUL WESSELDAVID BERCOVICI: ""Interpolation with Splines in Tension: A Green's Function Approach"", MATHEMATICAL GEOLOGY, vol. 30, no. 1, 1998, pages 77 - 93;;MITASOVA, H.L. MITAS: ""Interpolation by regularized spline with tension: I. Theory and implementation"", MATH. GEOL., vol. 25, 1993, pages 641 - 655;;PARKER, R. L.: ""Geophysical Inverse Theory"", 1994, PRINCETON UNIV. PRESS, pages: 386;;SANDWELL, D. T.: ""Biharmonic spline interpolation of Geos-3 and Seasat altimeter data"", GEOPHYS. RES. LETT., vol. 14, 1987, pages 139 - 142;;WESSEL, P.J. M. BECKER: ""Interpolation using a generalized Green's function for a spherical surface spline in tension"", GEOPHYS. J. INT, vol. 174, 2008, pages 21 - 28;;WESSEL, P.: ""A general-purpose Green's function interpolator"", COMPUTERS & GEOSCIENCES, vol. 35, 2009, pages 1247 - 1254, XP026023518, DOI: 10.1016/j.cageo.2008.08.012;;XINGSHENG DENGZHONG-AN TANGAUGUST 2011: ""Moving Surface Spline Interpolation Based on Green's Function"", MATHEMATICAL GEOSCIENCES, vol. 43, pages 663 - 680, XP019933892, DOI: 10.1007/s11004-011-9346-5;;V. BARNETT: ""Interpreting Multivariate Data"", JOHN WILEY, article ""A brief description of natural neighbor interpolation"", pages: 21 - 36;;P. LANCASTER ET AL.: ""Surfaces generated by Moving Least Squares Methods"", MATHEMATICS OF COMPUTATION, vol. 37, no. 155, July 1981 (1981-07-01), pages 141 - 158;;MICHAEL TAO ET AL.: ""SimpleFlow: A Non-Iterative, Sublinear Optical Flow Algorithm"", EUROGRAPHICS, vol. 31, no. 2, 2012;;ENRIC MEINHARDT-LLOPIS ET AL.: ""Horn-Schunck Optical Flow with a Multi-Scale Strategy"", IMAGE PROCESSING ON LINE, vol. 3, 2013, pages 151 - 172;;B. K. P. HORNB. G. SCHUNCK: ""Determining Optical Flow"", ARTIFICIAL INTELLIGENCE, vol. 17, 1981, pages 185 - 204;;BRUCE D. LUCASETAKEO KANADE: ""An Iterative Image Registration Technique with an Application to Stereo Vision"", PROCEEDINGS OF IMAGING UNDERSTANDING WORKSHOP, 1981, pages 121 - 130;;ANDRES BRUHNJOACHIM WEICKERTCHRISTOPH SCHNORR: ""Lucas/Kanade Meets Horn/Schunck: Combining Local and Global Optic Flow Methods"", INTERNATIONAL JOURNAL OF COMPUTER VISION, vol. 61, February 2005 (2005-02-01), pages 211 - 231;;GARY R. MIRAMS ET AL.: ""Chaste: An Open Source C++ Library for Computational Physiology and Biology"", PLOS COMPUTATIONAL BIOLOGY, vol. 9, 14 March 2013 (2013-03-14), pages e1002970;;R. T. CARRICKP. S. SPECTOR ET AL.: ""Prospectively Quantifying the Propensity for Atrial Fibrillation: A Mechanistic Formulation"", PLOS ONE, 13 March 2015 (2015-03-13);;BELLMANN ET AL.: ""Velocity characteristics of atrial fibrillation sources determined by electrographic flow mapping before and after catheter ablation"", INTERNATIONAL JOURNAL OF CARDIOLOGY, vol. 286, 1 July 2019 (2019-07-01), pages 56 - 60, XP085665774, Retrieved from the Internet <URL:https://doi.Org/10.1016/j.ijcard.2019.02.006> DOI: 10.1016/j.ijcard.2019.02.006;;""Identification of active atrial fibrillation sources and their discrimination from passive rotors using electrographical flow mapping"", CLINICAL RESEARCH IN CARDIOLOGY, May 2018 (2018-05-01);;BELLMANN ET AL.: ""Electrographic Flow Mapping - A Novel Technology for Endocardial Driver Identification in Patients with Persistent Atrial Fibrillation"", POSTER SESSION IV, C-P004-76, S356 HEART RHYTHM, vol. 14, no. 5, May 2017 (2017-05-01);;MURALI ET AL.: ""Cardiac Ambulatory Monitoring: New Wireless Device Validated Against Conventional Holter Monitoring in a Case Series"", FRONT. CARDIOVASC. MED., 30 November 2020 (2020-11-30), Retrieved from the Internet <URL:https://doi.org/10.3389/fcvm.2020.587945>;;FERRER ET AL.: ""Detailed Anatomical and Electrophysiological Models of Human Atria and Torso for the Simulation of Atrial Activation"", PLOS ONE, 2 November 2015 (2015-11-02);;RODRIGO ET AL., HEART RHYTHM, vol. 11, no. 9, September 2014 (2014-09-01), pages 1584 - 1591;;TAKU INOHARA ET AL.: ""Association of Atrial Fibrillation Clinical Phenotypes With Treatment Patterns and Outcomes: A Multicenter Registry Study"", JAMA CARDIOL, vol. 3, no. 1, 2018, pages 54 - 63;;KONINGS ET AL.: ""Configuration of unipolar atrial electrograms during electrically induced atrial fibrillation in humans"", CIRCULATION, vol. 95, 1997, pages 1231 - 41;;KALIFA ET AL.: ""Mechanisms of wave fractionation at boundaries of high frequency excitation in the posterior left atrium of the isolated sheep heart during atrial fibrillation"", CIRCULATION, vol. 113, 2006, pages 626 - 33, XP008162689, DOI: 10.1161/​CIRCULATIONAHA.105.575340;;SOHAL ET AL.: ""Is Mapping of Complex Fractionated Electrograms Obsolete"", ARRHYTHM. ELECTROPHYSIOL. REV., vol. 4, no. 2, August 2015 (2015-08-01), pages 109 - 115;;ATIENZA ET AL.: ""Mechanisms of Fractionated Electrograms Formation in the Posterior Left Atrium During Paroxysmal Atrial Fibrillation in Humans"", J AM COLL CARDIOL, vol. 57, no. 9, 1 March 2011 (2011-03-01), pages 1081 - 1092, XP028149072, DOI: 10.1016/j.jacc.2010.09.066;;CORREA DE SA ET AL.: ""Electrogram Fractionation - The Relationship between Spatiotemporal Variation of Tissue Excitation and Electrode Spatial Resolution"", CIRC. ARRHYTHM. ELECTROPHYSIOL., vol. 4, no. 6, December 2011 (2011-12-01), pages 909 - 16, XP055268279, DOI: 10.1161/CIRCEP.111.965145;;CALKINS H ET AL., HEART RHYTHM, vol. 14, no. 10, 2017, pages 275 - 444;;VERMA A ET AL., N ENGL J MED, vol. 372, 2015, pages 1812 - 22;;CALKINS H ET AL., EUROPACE, vol. 14, 2012, pages 528 - 606;;DAGRES N ET AL., EUROPACE, vol. 17, 2015, pages 1596 - 1600;;JANUARY CT ET AL., CIRCULATION, vol. 130, 2014, pages 2071 - 2104;;CHARITOS E ET AL., J AM COLL CARDIOL., vol. 63, 2014, pages 2840 - 8;;MASUDA M ET AL., PACE, vol. 35, 2012, pages 327 - 34;;SAU A ET AL., EUROPACE, vol. 21, 2019, pages 1176 - 84;;WINKLE ET AL., J INTERV CARD ELETROPHYSIOL, vol. 36, 2013, pages 157 - 65;;AL-KHATIB SM ET AL., CIRCULATION, vol. 141, 2020, pages 482 - 92;;SCHREIBER D ET AL., CIRC ARRYTHM ELECTROPHYSIOL, vol. 8, no. 2, 2015, pages 308 - 17;;RODRIGO M ET AL., CIRC ARRYTHM ELECTROPHYSIOL, vol. 13, no. 3, 2020, pages e007700",PENDING
114,EP,A1,EP 3964998 A1,024-287-169-219-406,2022-03-09,2022,EP 20804954 A,2020-01-17,CN 201910410679 A;;CN 2020072588 W,2019-05-16,TEXT PROCESSING METHOD AND MODEL TRAINING METHOD AND APPARATUS,"This application relates to the field of artificial intelligence, and provides a text processing method, a model training method, and an apparatus. The method includes: obtaining target knowledge data, where the target knowledge data includes a first named entity, a second named entity, and an association between the first named entity and the second named entity; processing the target knowledge data to obtain a target knowledge vector; processing to-be-processed text to obtain a target text vector, where the to-be-processed text includes the first named entity; fusing the target text vector and the target knowledge vector based on a target fusion model, to obtain a fused target text vector and a fused target knowledge vector; and processing the fused target text vector and/or the fused target knowledge vector based on a target processing model, to obtain a processing result corresponding to a target task. The foregoing technical solution can improve accuracy of a result of processing a target task by the target processing model.",HUAWEI TECH CO LTD;;UNIV TSINGHUA,WANG YASHENG;;JIANG XIN;;CHEN XIAO;;LIU QUN;;ZHANG ZHENGYAN;;QI FANCHAO;;LIU ZHIYUAN,,https://lens.org/024-287-169-219-406,Patent Application,yes,0,1,6,6,0,G06F18/214;;G06F40/205;;G06F40/295;;G06F40/30;;G06N3/045;;G06N3/084;;G06F40/216;;G06F40/284;;G06F40/30;;G06N3/042;;G06N3/045;;G06N3/063;;G06F40/295,G06F40/00,,0,0,,,,PENDING
115,EP,A1,EP 3961031 A1,039-913-117-462-324,2022-03-02,2022,EP 20192742 A,2020-08-25,EP 20192742 A,2020-08-25,"MONITORING SYSTEM FOR A WIND TURBINE BLADE, WIND TURBINE ARRANGEMENT AND METHOD FOR MONITORING OF A WIND TURBINE BLADE","Monitoring system (14) for at least one wind turbine blade (6) of a wind turbine (2), wherein the wind turbine blade (6) comprises at least one electrically conducting or semiconducting structural component (7) and a lightning protection system (8) having a down conductor (31) electrically connected to at least one lightning receptor (32), wherein the down conductor (31) is electrically connected to the at least one structural component (7) by at least one equipotential connector (37, 37a, 37b), such that, in the wind turbine blade (6), a network (19) of electrical impedances comprising the at least one structural component (7), the at least one equipotential connector (37, 37a, 37b) and the down conductor (31) is formed, whereby the hybrid monitoring system (14) comprises, for remotely monitoring both the lightning protection system (8) and the structural health of the at least one structural component (7),- a sensing device (9) for the network (19), comprising at least one transmitter (17) for emitting an electrical pulse (18) into the network (19) via at least one first terminal (15) and at least one receiver (21) for receiving at least one reception pattern (20) of the electrical pulse (18) from the network (19) via at least one second terminal (16), and- an evaluation device (10) for evaluating the at least one reception pattern (20) to determine a first health information regarding the lightning protection system (8), in particular at least one equipotential connector (37, 37a, 37b), and a second health information regarding the at least one structural component (7).",SIEMENS GAMESA RENEWABLE ENERGY AS,PONNADA RAJESH SRI MARKANDEYA,,https://lens.org/039-913-117-462-324,Patent Application,yes,7,1,7,7,0,F03D17/00;;F03D80/30;;G01R29/08;;F03D17/00;;F03D80/30;;F05B2260/80;;F05B2260/83;;F05B2280/2006;;Y02E10/72;;F03D17/00;;F03D80/30;;F05B2260/80;;F05B2280/2006,F03D17/00;;F03D80/30,,2,0,,,"""Structural Health Monitoring"", 2006, ISTE LTD.;;""Structural Health Monitoring (SHM) in Aerospace Structures"", 2016, WOODHEAD PUBLISHING LTD.",ACTIVE
116,EP,A1,EP 3958181 A1,044-370-584-690-29X,2022-02-23,2022,EP 20192250 A,2020-08-21,EP 20192250 A,2020-08-21,PERFORMANCE TESTING FOR ROBOTIC SYSTEMS,"A computer-implemented method of modelling a perception system, the perception system configured to receive sensor data and interpret the sensor data to generate actual perception outputs, comprises: receiving a plurality of input samples, wherein each input sample comprises sensor data and is associated with one or more training perception ground truths pertaining to one or more ground truth objects; providing the sensor data of each input sample to the perception system to be modelled, wherein the perception system interprets the sensor data, in order to generate one or more actual perception outputs for the input sample; and training a function approximator to model the perception system by: for each input sample, inputting the training perception ground truths to the function approximator, wherein the function approximator computes one or more predicted perception values by processing the training perception ground truths but not the sensor data from which the actual perception outputs are generated, and adapting parameters of the function approximator, so as to match the corresponding predicted perception values to the actual perception outputs for each of the input samples; wherein the training perception ground truths associated with at least one of the input samples comprise first and second training perception ground truths pertaining to first and second ground truth objects respectively, wherein at least one of the corresponding predicted perception values is computed from both the first and second training perception ground truths for modelling correlations between the first and second ground truth objects.",FIVE AI LTD,REDFORD JOHN;;SAMANGOOEI SINA;;SADEGHI JONATHAN,,https://lens.org/044-370-584-690-29X,Patent Application,yes,2,2,3,3,0,G06N3/08;;G06N3/008;;G06N3/044;;G06N3/045;;G06N3/048;;G06N7/01;;G06N20/00;;G06N3/08;;G06N3/0464,G06N3/04;;G06N3/00;;G06N3/08;;G06N7/00;;G06N20/00,,1,1,028-219-821-925-688,10.1016/j.jbi.2018.07.015;;30030120;;pmc6299838,"RYAN J. URBANOWICZRANDAL S. OLSONPETER SCHMITTMELISSA MEEKERJASON H. MOORE: ""Benchmarking relief-based feature selection methods for bioinformatics data mining"", JOURNAL OF BIOMEDICAL INFORMATICS, vol. 85, no. 168, 2018, pages 188",DISCONTINUED
117,EP,B1,EP 3583380 B1,087-626-085-928-888,2022-02-23,2022,EP 18709087 A,2018-01-25,JP 2017029248 A;;JP 2018003499 W,2017-02-20,SHAPE ESTIMATING APPARATUS,,OMRON TATEISI ELECTRONICS CO,ANDO TANICHI,,https://lens.org/087-626-085-928-888,Granted Patent,yes,4,0,9,9,0,G01B11/24;;G06T7/50;;G06T2207/10004;;G06T2207/20081;;G06T2207/20084;;G06V20/647;;G06V20/647;;G01B11/24;;G06T17/00,G06T7/50;;G01B11/24;;G06K9/00,,2,0,,,"SHUIWANG JI ET AL: ""3D Convolutional Neural Networks for Human Action Recognition"", IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE, IEEE COMPUTER SOCIETY, USA, vol. 35, no. 1, 1 January 2013 (2013-01-01), pages 221-231, XP011490774, ISSN: 0162-8828, DOI: 10.1109/TPAMI.2012.59;;ELAD RICHARDSON ET AL: ""3D Face Reconstruction by Learning from Synthetic Data"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 14 September 2016 (2016-09-14), XP080726710, DOI: 10.1109/3DV.2016.56",ACTIVE
118,EP,A1,EP 3955151 A1,111-856-146-496-268,2022-02-16,2022,EP 21191141 A,2021-08-12,US 202063064686 P,2020-08-12,RE-IDENTIFICATION RISK ASSESSMENT USING A SYNTHETIC ESTIMATOR,A risk of re-identifying a particular individual associated with a record in a dataset can be assessed by synthesizing a dataset from a dataset to be shared and then sampling a synthetic microdata dataset from the synthetic dataset. The synthetic dataset and the synthetic microdata dataset can then be used to estimate the risk of re-identifying an individual from the dataset to be shared.,REPLICA ANALYTICS,JIANG YANGDI;;JIANG BEI;;KONG LINGLONG;;EL EMAM KHALED,,https://lens.org/111-856-146-496-268,Patent Application,yes,0,0,2,2,0,G06F21/6254;;H04W12/02;;G06N5/01;;G06N7/01;;G06F21/577;;G06F21/6245;;G06F2221/034,G06F21/62;;G06N20/00;;H04W12/02,,6,3,001-414-738-968-859;;079-509-090-064-188;;075-465-154-008-939,pmc6650473;;31337762;;10.1038/s41467-019-10933-3;;24805122;;pmc4151119;;10.1038/nrg3723;;pmc2528029;;18579830;;10.1197/jamia.m2716,"ANCO HUNDEPOOL ET AL: ""Handbook on Statistical Disclosure Control Version 1.01"", 1 March 2007 (2007-03-01), XP055268917, Retrieved from the Internet <URL:http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.135.3606&rep=rep1&type=pdf> [retrieved on 20160427];;FIDA KAMAL DANKAR ET AL: ""A method for evaluating marketer re-identification risk"", 20100322; 1077952576 - 1077952576, 22 March 2010 (2010-03-22), pages 1 - 10, XP058313319, ISBN: 978-1-60558-990-9, DOI: 10.1145/1754239.1754271;;ROCHER LUC ET AL: ""Estimating the success of re-identifications in incomplete datasets using generative models"", NATURE COMMUNICATIONS, vol. 10, no. 1, 23 July 2019 (2019-07-23), XP055785023, Retrieved from the Internet <URL:http://www.nature.com/articles/s41467-019-10933-3> DOI: 10.1038/s41467-019-10933-3;;ERLICH ET AL.: ""Routes for Breaching and Protecting Genetic Privacy"", NAT REV GENET, vol. 15, no. 6, XP055671956, DOI: 10.1038/nrg3723;;EL EMAM ET AL., JOURNAL OF THE AMERICAN MEDICAL INFORMATICS ASSOCIATION, vol. 15;;""Statistical Disclosure Control for Microdata - Methods and Applications in R"", TEMPI, 24 August 2018 (2018-08-24)",PENDING
119,EP,A1,EP 3951646 A1,170-258-519-365-720,2022-02-09,2022,EP 20784955 A,2020-03-18,CN 201910262855 A;;CN 2020080002 W,2019-04-02,"IMAGE RECOGNITION NETWORK MODEL TRAINING METHOD, IMAGE RECOGNITION METHOD AND DEVICE","The present application discloses an image recognition network model training method, comprising: obtaining first image features corresponding to a training image set; using an identity classifier to be trained for obtaining a first identity prediction result, and using an attitude classifier to be trained for obtaining a first attitude prediction result; using the first identity prediction result and an identity tag for obtaining an identity classifier, and using the first attitude prediction result and an attitude tag for obtaining an attitude classifier; using a generator to be trained for converting the attitude of the first image features, obtaining second image features corresponding to the training image set; using the identity classifier for obtaining a second identity prediction result, and using the attitude classifier for obtaining a second attitude prediction result; training the generator to be trained, obtaining a generator. The present application additionally discloses an image recognition method and a device. The present application performs training on the basis of image features which have undergone organization, and has relatively smaller spatial dimensions compared to original images, thus decreasing training difficulty.",TENCENT TECH SHENZHEN CO LTD,GE ZHENG;;JIE ZEQUN;;WANG HAO;;LI ZHIFENG;;GONG DIHONG;;LIU WEI,TENCENT TECHNOLOGY (SHENZHEN) COMPANY LIMITED (2022-07-20),https://lens.org/170-258-519-365-720,Patent Application,yes,0,0,7,7,0,G06V40/172;;G06F18/2415;;G06F18/214;;G06V40/172;;G06V10/82;;G06N3/084;;G06N3/088;;G06V10/774;;G06N3/047;;G06N3/045;;G06N3/088;;G06V40/172;;G06F18/214;;G06F18/2415;;G06N3/045;;G06V10/774;;G06V10/82,G06V10/774,,0,0,,,,ACTIVE
120,EP,A1,EP 3940591 A1,003-111-180-183-255,2022-01-19,2022,EP 20783785 A,2020-03-31,CN 201910254752 A;;CN 2020082599 W,2019-03-31,"IMAGE GENERATING METHOD, NEURAL NETWORK COMPRESSION METHOD, AND RELATED APPARATUS AND DEVICE","The present invention discloses an image generation method, a neural network compression method, and a related apparatus and device in the field of artificial intelligence. The image generation method includes: inputting a first matrix into an initial image generator to obtain a generated image; inputting the generated image into a preset discriminator to obtain a determining result, where the preset discriminator is obtained through training based on a real image and a category corresponding to the real image; updating the initial image generator based on the determining result to obtain a target image generator; and further inputting a second matrix into the target image generator to obtain a sample image. Further, a neural network compression method is disclosed, to compress the preset discriminator based on the sample image obtained by using the foregoing image generation method.",HUAWEI TECH CO LTD,CHEN HANTING;;WANG YUNHE;;LIU CHUANJIAN;;HAN KAI;;XU CHUNJING,,https://lens.org/003-111-180-183-255,Patent Application,yes,0,0,7,7,0,G06V10/774;;G06V10/776;;G06V10/778;;G06V10/82;;G06V10/764;;G06V30/19;;G06V40/16;;G06N3/0495;;G06N3/044;;G06N3/045;;G06N3/047;;G06N3/048;;G06N3/0475;;G06N3/084;;G06N3/088;;G06V30/19;;G06V40/174;;G06V40/178;;G06V10/82;;G06V10/774;;G06V10/776;;G06V10/778;;G06N3/088;;G06N3/084;;G06N3/047;;G06N3/048;;G06N3/044;;G06N3/045;;G06F18/2148;;G06F18/243;;G06N3/047,G06K9/62;;G06F16/35;;G06N3/08,,0,0,,,,PENDING
121,EP,A1,EP 3937077 A1,135-632-401-912-184,2022-01-12,2022,EP 21181451 A,2021-06-24,CN 202011488643 A,2020-12-16,"LANE MARKING DETECTING METHOD, APPARATUS, ELECTRONIC DEVICE, STORAGE MEDIUM, AND VEHICLE","This application discloses a lane marking detecting method, an apparatus, an electronic device, a storage medium, a program product, and a vehicle, which can be applied to artificial intelligence, autonomous driving, intelligent traffic, and deep learning. A specific implementation includes: obtaining a video stream including a lane marking; extracting a key image frame from the video stream at a predetermined interval of frames, with an image frame between adjacent key image frames being a non-key image frame; detecting, for the key image frame, a lane marking according to a feature map of the key image frame; detecting, for the non-key image frame, a lane marking according to the non-key image frame and a feature map of a previous key image frame of the non-key image frame. In this embodiment, the feature map of the non-key image frame is determined and the lane marking is detected by combining the feature map of the previous key image frame, thus enabling flexibility and diversity in lane marking detection. Efficiency in lane marking detection is also improved.",APOLLO INTELLIGENT CONNECTIVITY BEIJING TECHNOLOGY CO LTD,HE GANG,,https://lens.org/135-632-401-912-184,Patent Application,yes,0,0,9,9,0,G06V20/46;;G06V20/41;;G06V20/588;;G06F18/214;;G06V20/46;;G06V20/588;;G06V10/82;;G06V10/764;;G06V10/774;;G06V20/588;;G06T7/73;;G06N3/04;;G06T2207/10016;;G06V20/588;;G06V20/46;;G06F18/214;;G06V10/764;;G06V10/774;;G06V10/82,G06V10/764;;G06V10/774,,4,3,090-598-194-848-230;;047-949-913-222-705;;120-756-749-086-362,10.1109/iccv.2015.316;;33430036;;10.3390/s21020400;;pmc7827336;;10.1016/j.patcog.2020.107623,"DOSOVITSKIY ALEXEY ET AL: ""FlowNet: Learning Optical Flow with Convolutional Networks"", 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV), IEEE, 7 December 2015 (2015-12-07), pages 2758 - 2766, XP032866621, DOI: 10.1109/ICCV.2015.316;;LU SHENG ET AL: ""A Fast and Robust Lane Detection Method Based on Semantic Segmentation and Optical Flow Estimation"", SENSORS, vol. 21, no. 2, 8 January 2021 (2021-01-08), pages 400, XP055869828, DOI: 10.3390/s21020400;;TANG JIGANG ET AL: ""A review of lane detection methods based on deep learning"", PATTERN RECOGNITION, ELSEVIER, GB, vol. 111, 15 September 2020 (2020-09-15), XP086395682, ISSN: 0031-3203, [retrieved on 20200915], DOI: 10.1016/J.PATCOG.2020.107623;;JIANPING GOU ET AL: ""Knowledge Distillation: A Survey"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 23 October 2020 (2020-10-23), XP081795698",ACTIVE
122,EP,A1,EP 3933551 A1,019-537-953-010-110,2022-01-05,2022,EP 20860375 A,2020-09-01,CN 201910843985 A;;CN 2020112766 W,2019-09-06,"MOTOR IMAGERY ELECTROENCEPHALOGRAM SIGNAL PROCESSING METHOD, DEVICE, AND STORAGE MEDIUM","A motor imagery electroencephalogram signal processing method, a device, and a storage medium. The method comprises: inputting a source MI electroencephalogram signal of a source domain and a target MI electroencephalogram signal of a target domain into an initial feature extraction model separately, and obtaining a first source MI feature used to represent the source MI electroencephalogram signal and a first target MI feature used to represent the target MI electroencephalogram signal (S202); inputting the first source MI feature into an initial classification model, and obtaining a first classification result output by the initial classification model, wherein the first classification result is used to represent a desired execution action of the source MI electroencephalogram signal (S204); and if a first known action corresponding to the source MI electroencephalogram signal is inconsistent with the desired execution action of the source MI electroencephalogram signal as represented by the first classification result, or if a similarity level between a feature distribution of the first source MI feature and a feature distribution of the first target MI feature is less than a first pre-determined threshold, adjusting a model parameter of the initial feature extraction model and/or a model parameter of the initial classification model, and obtaining a target feature extraction model and a target classification model (S206).",TENCENT TECH SHENZHEN CO LTD,LEI MENGYING;;DENG ZIJUN;;ZHAO HE;;ZHENG QINGQING;;MA KAI;;ZHENG YEFENG,TENCENT TECHNOLOGY (SHENZHEN) COMPANY LIMITED (2022-07-20),https://lens.org/019-537-953-010-110,Patent Application,yes,0,0,6,6,0,A61B5/369;;A61B5/72;;A61B5/7267;;G06F3/015;;G06F2218/08;;G06F2218/12;;G06N3/045;;G06F3/015;;A61B5/369;;A61B5/7267;;G06F18/24143;;G06N3/044;;G06N3/045;;G06N3/088;;G06V10/454;;G06V40/15;;A61B5/375;;A61B5/372;;A61B2505/09;;G06F3/015;;G06F18/22;;G06N3/045;;G06V10/40;;G16H40/63;;G16H50/20,G06F3/01;;G06K9/00;;G06N3/04,,0,0,,,,PENDING
123,EP,A1,EP 3929189 A1,172-926-823-668-789,2021-12-29,2021,EP 20182386 A,2020-06-25,EP 20182386 A,2020-06-25,NOVEL HETEROARYL-SUBSTITUTED PYRAZINE DERIVATIVES AS PESTICIDES,"The present invention relates to novel heteroaryl-substituted pyrazine derivatives of the general formula (I), in which the structural elements R<sup>1</sup>, R<sup>2</sup>, R<sup>3</sup>, R<sup>4</sup>, R<sup>5</sup> and R<sup>6</sup> have the meaning given in the description, to formulations and compositions comprising such compounds and for their use in the control of animal pests including arthropods and insects in plant protection and to their use for control of ectoparasites on animals.",BAYER ANIMAL HEALTH GMBH,The designation of the inventor has not yet been filed,,https://lens.org/172-926-823-668-789,Patent Application,yes,204,1,4,4,0,C07D403/04;;A61P33/14;;C07D403/14;;C07D403/04;;A01N43/647;;A01N43/653;;A01N43/84;;A01N47/02;;A01P7/04;;A61K31/497;;A61K31/5377;;A61P33/14;;C07D403/14;;C07D413/14,C07D403/04;;A01N43/653;;A61P33/14;;C07D403/14,,9,5,056-357-183-925-763;;090-891-292-313-558;;128-914-612-719-714;;043-173-973-877-294;;070-286-387-669-812,10.1016/s0261-2194(97)00118-x;;8643585;;pmc39256;;10.1073/pnas.93.11.5389;;10.1021/jo0478196;;15787551;;24697240;;10.1021/jo500297r;;pmc2645945;;18620434;;10.1021/ar800036s,"""Technical Monograph No. 2"", May 2008, CROPLIFE INTERNATIONAL, article ""Catalogue of pesticide formulation types and international coding system"";;""The Pesticide Manual"", 2012, BRITISH CROP PROTECTION COUNCIL;;CHEMICAL ABSTRACTS, Columbus, Ohio, US; abstract no. 1207977-87-4;;ESTRUCH ET AL., PROC NATL ACAD SCI US A, vol. 93, no. 11, 1996, pages 5389 - 94;;R. WEGLER: ""Chemie der Pflanzenschutz- and Schadlingsbekampfungsmitte"", vol. 2, 1970, SPRINGER VERLAG, pages: 401 - 412;;F. BURONN. PIEA TURCKG, QUEGUIGNER, J. ORG. CHEM., vol. 70, 2005, pages 2616 - 2621;;T. KLATTJ.T. MARKIEWICZC. SAMANNP. KNOCHEL, J. ORG. CHEM., vol. 79, 2014, pages 4253 - 4269;;T.W. GREENEP.G.M. WUTS: ""Protective Groups in Organic Chemistra"", 1999, WILEY INTERSCIENCE;;R. MARTINS.L. BUCHWALD, ACC. CHEM. RES., vol. 61, 2008, pages 1461 - 1473",DISCONTINUED
124,EP,A1,EP 3922849 A1,112-979-883-590-71X,2021-12-15,2021,EP 20179807 A,2020-06-12,EP 20179807 A,2020-06-12,REPAIR SYSTEM AND METHOD FOR PERFORMING AT LEAST ONE REPAIR TASK IN A WIND TURBINE,"Repair system (1) for performing at least one repair task in at least one wind turbine (2), in particular the nacelle (5), the repair system (1) comprising:- a controllable robotic repair device (15) installed in the wind turbine (2), in particular the nacelle (5),- an operating device for remotely operating the robotic repair device (15), which comprises a control device (23) and virtual reality equipment (3) providing a virtual reality environment of the interior of the wind turbine, in particular the nacelle (5), for at least one human service user provided remote to the wind turbine (2),- wherein the control device (23) of the operating device is adapted to remotely control the robotic repair device (15) according to user input commands provided via the virtual reality equipment (3).",SIEMENS GAMESA RENEWABLE ENERGY GMBH & CO KG,GOLLNICK BERT,,https://lens.org/112-979-883-590-71X,Patent Application,yes,3,0,7,7,0,F03D80/50;;F05B2230/80;;Y02E10/72;;Y02P70/50;;F03D80/50;;F05B2230/80,F03D80/50,,1,1,096-021-973-070-976,pmc6639318;;31320674;;10.1038/s41598-019-45422-6,"K. SONG ET AL.: ""Pneumatic actuator and flexible piezoelectric sensor for soft virtual reality glove system"", SCIENTIFIC REPORTS, vol. 9, 2019, pages 8988",DISCONTINUED
125,EP,B1,EP 3697216 B1,018-429-954-595-195,2021-11-03,2021,EP 18782772 A,2018-10-12,EP 17197094 A;;EP 2018077873 W,2017-10-18,ACTIVE COMPOUND COMBINATIONS HAVING INSECTICIDAL/ACARICIDAL PROPERTIES,,BAYER AG,CEREZO-GALVEZ SILVIA;;MARIENHAGEN CHRISTIAN;;WECKWERT HOLGER;;THIELERT WOLFGANG;;JOHN MARITA,,https://lens.org/018-429-954-595-195,Granted Patent,yes,4,0,25,25,0,A01N43/78;;A01N43/78;;A01N43/78;;A01N43/90,A01N43/78;;A01N37/42;;A01N43/12;;A01N43/22;;A01N43/28;;A01N43/40;;A01N43/54;;A01N43/56;;A01N43/707;;A01N43/90;;A01N47/34;;A01P1/00;;A01P5/00;;A01P7/02;;A01P7/04,,0,0,,,,ACTIVE
126,EP,B1,EP 3670109 B1,152-497-966-320-730,2021-11-03,2021,EP 19211831 A,2019-11-27,KR 20180164091 A,2018-12-18,METHOD AND APPARATUS FOR CONTROLLING BEHAVIOR OF SERVICE ROBOT,,SAMSUNG ELECTRONICS CO LTD,HA TAE SIN;;KIM KYUNG-ROCK;;JANG JUN-WON;;CHO JOON-KEE,,https://lens.org/152-497-966-320-730,Granted Patent,yes,2,0,7,7,0,B25J9/16;;B25J9/1602;;B25J9/1679;;B25J9/1679;;B25J9/1602;;B25J9/163;;B25J11/008;;G05B2219/39254;;G05B2219/45084;;B25J9/1664;;B25J9/1602;;B25J9/163;;B25J19/02;;B25J11/001;;B25J9/1669,B25J9/16;;B25J11/00,,0,0,,,,ACTIVE
127,EP,B1,EP 3380949 B1,025-611-352-124-470,2021-10-20,2021,EP 16869158 A,2016-11-22,US 201562259849 P;;US 2016/0063263 W,2015-11-25,AUTOMATIC SPOKEN DIALOGUE SCRIPT DISCOVERY,,MICROSOFT TECHNOLOGY LICENSING LLC,CHEN PENGYU;;COHEN JORDAN R;;GILLICK LAURENCE S;;HALL DAVID LEO WRIGHT;;KLEIN DANIEL;;PAULS ADAM D;;ROTH DANIEL L;;RUSAK JESSE DANIEL ESKES,"MICROSOFT TECHNOLOGY LICENSING, LLC (2021-11-10)",https://lens.org/025-611-352-124-470,Granted Patent,yes,3,0,10,10,0,G06F3/167;;G06F40/143;;G06F40/186;;G06F40/35;;G10L15/22;;H04L67/02;;G06F3/167;;G06F3/0482;;G06F40/143;;G06F40/186;;G06F40/35;;G10L15/22;;H04L67/02,G06F3/16;;G06F40/143;;G06F40/186;;G06F40/35,,0,0,,,,ACTIVE
128,EP,A1,EP 3876112 A1,157-794-978-643-96X,2021-09-08,2021,EP 21158256 A,2021-02-19,US 202062983450 P;;US 202117171949 A,2020-02-28,SYSTEM AND METHOD FOR CONTENT CREATION VIA INTERACTIVE LAYERS,"A system and method for content creation via interactive layers is provided. Parameters for an artifact are received. A mutable general object on which to build the artifact is maintained and includes a plurality of n-dimensional data units. Layers of data for the artifact are generated via different generators. Each layer of the artifact represents a set of characteristics based on arrangements of the data units. Each layer is generated by obtaining data about an arrangement of the data units for that layer, from one or more layers of the artifact prior to that data layer, and creating the layer to mutate the data units based on the data from one or more prior data layers and the received parameters. The artifact is formed by stacking the layers via the mutable general object. Each data layer is stored with the generator for that layer as a string of characters.",PALO ALTO RES CT INC,LE JACOB;;YOUNGBLOOD GREGORY MICHAEL;;KRIVACIC ROBERT THOMAS;;ZHU JICHEN,,https://lens.org/157-794-978-643-96X,Patent Application,yes,1,0,5,5,0,G06F16/29;;A63F13/63;;A63F13/65;;G06F16/904;;G06T17/00;;G06T15/08;;G06T15/005;;G06T17/05;;G06T17/10;;G06T2215/12,G06F16/904;;A63F13/60;;G06F16/29;;G06T19/00,,1,1,158-143-093-232-896,10.1007/s00371-013-0909-y,"SANTAMARÍA-IBIRIKA AITOR ET AL: ""Procedural approach to volumetric terrain generation"", VISUAL COMPUTER, SPRINGER, BERLIN, DE, vol. 30, no. 9, 28 December 2013 (2013-12-28), pages 997 - 1007, XP035380021, ISSN: 0178-2789, [retrieved on 20131228], DOI: 10.1007/S00371-013-0909-Y",PENDING
129,EP,B1,EP 3552949 B1,011-486-940-437-002,2021-08-25,2021,EP 18783355 A,2018-02-19,BR 2018050036 W,2018-02-19,AEROSTAT REINFORCEMENT SYSTEM AND METHOD,,CEBALLOS MELO ANDRE AUGUSTO,CEBALLOS MELO ANDRÉ AUGUSTO,,https://lens.org/011-486-940-437-002,Granted Patent,yes,17,0,16,16,0,B64B1/58;;Y02E60/36;;B64B1/58;;B64B1/00;;B64B1/60;;B64B1/58;;C01B3/08;;C25B1/04;;Y02E60/36;;B64B1/60,B64B1/58;;B64B1/00;;B64B1/60,,0,0,,,,ACTIVE
130,EP,B1,EP 3697215 B1,002-654-010-817-889,2021-08-11,2021,EP 18782768 A,2018-10-12,EP 17197106 A;;EP 2018077867 W,2017-10-18,ACTIVE COMPOUND COMBINATIONS HAVING INSECTICIDAL/ACARICIDAL PROPERTIES,,BAYER AG,CEREZO-GALVEZ SILVIA;;MARIENHAGEN CHRISTIAN;;WECKWERT HOLGER;;THIELERT WOLFGANG;;JOHN MARITA,,https://lens.org/002-654-010-817-889,Granted Patent,yes,3,0,23,23,0,A01N43/78;;A01N43/78;;Y02A40/146;;A01N43/78;;A01N43/80,A01N43/78;;A01N43/12;;A01N43/40;;A01N47/40;;A01N51/00;;A01P1/00;;A01P5/00;;A01P7/02;;A01P7/04,,0,0,,,,ACTIVE
131,EP,B1,EP 3697217 B1,139-743-895-260-346,2021-08-11,2021,EP 18782773 A,2018-10-12,EP 17197098 A;;EP 2018077882 W,2017-10-18,ACTIVE COMPOUND COMBINATIONS HAVING INSECTICIDAL/ACARICIDAL PROPERTIES,,BAYER AG,CEREZO-GALVEZ SILVIA;;MARIENHAGEN CHRISTIAN;;WECKWERT HOLGER;;THIELERT WOLFGANG;;JOHN MARITA,,https://lens.org/139-743-895-260-346,Granted Patent,yes,3,0,27,27,0,A01N43/78;;A01N63/30;;A01N43/78;;A01N63/30;;A01N43/56;;A01N43/78;;A01N63/30,A01N43/78;;A01N37/02;;A01N43/40;;A01N43/54;;A01N43/56;;A01N43/90;;A01N47/22;;A01N47/24;;A01N63/22;;A01N63/30;;A01N65/00;;A01P1/00;;A01P5/00;;A01P7/02;;A01P7/04,,0,0,,,,ACTIVE
132,EP,A1,EP 3862902 A1,134-633-542-235-39X,2021-08-11,2021,EP 21155627 A,2021-02-05,US 202062970482 P;;US 202063085515 P,2020-02-05,SYSTEM AND METHOD FOR PRIVACY-AWARE ANALYSIS OF VIDEO STREAMS,"A method and system for privacy-aware movement tracking includes receiving a series of images of a field of view, such as captured by a camera. The images containing movement of an unidentified person within the field of view. A body region corresponding to the person is detected within the images. A movement dataset for the unidentified person is generated based on tracking movement of the body region over the fired of view within the images is generated. A characterizing feature set is determined for the unidentified person. The set is associated within the movement dataset to form a first track entry. Anonymizing of the body region can be applied to remove identifying features while or prior to determining the characterizing feature set. A second track entry can be generated from a second series of images and match between the track entries can be determined. A method and system for privacy-aware operation and learning of a computer-implemented classification module is also contemplated.",C2RO CLOUD ROBOTICS INC,BADALONE RICCARDO;;FAROKHI SOODEH;;HAJI ABOLHASSANI AMIR ABBAS;;DUGUAY FELIX-OLIVIER;;BARRET NEIL;;ERFANI MOSTAFA;;VARGAS MORENO ALDO ENRIQUE,,https://lens.org/134-633-542-235-39X,Patent Application,yes,3,1,11,13,0,G06F21/60;;H04W12/02;;H04W4/029;;G06V20/52;;G06V10/22;;H04N7/181;;G06Q30/0201;;G06F16/784;;G06F16/73;;G06F21/6254;;G06V20/48;;G06V40/167;;G06F21/60;;G06V10/22;;G06V20/52,G06F21/60;;G06V10/22;;H04W12/02,,0,0,,,,ACTIVE
133,EP,A1,EP 3848859 A1,194-164-131-774-10X,2021-07-14,2021,EP 21150465 A,2021-01-07,FI 20205013 A,2020-01-08,"APPARATUS, METHOD, AND SYSTEM FOR PROVIDING A SAMPLE REPRESENTATION FOR EVENT PREDICTION","An approach is provided for sample representation for event prediction (e.g., a device failure event). The approach, for example, involves determining a random set of sliding time window lengths for processing a sensor data stream (e.g., device health measurements) to detect an event (e.g., device failure). The approach also involves generating sensor data samples based on the random set of the sliding time window lengths. The approach further involves evaluating the data samples based on a quality metric indicating a level of sample cohesion relative to the event. The approach further involves selecting a combination of the sliding time window lengths of the one or more window lengths based on the evaluation. The selected combination of the sliding time window lengths is used to process the sensor data to detect the event (e.g., via machine learning).",NOKIA TECHNOLOGIES OY,AKYAMAC AHMET;;LEHMANN GERALD;;GARG YASH,,https://lens.org/194-164-131-774-10X,Patent Application,yes,1,2,1,1,0,G06F11/3072;;G06N20/00;;G06F2201/835;;G06F11/3006;;G06F11/3089;;G06F11/004;;G06N7/01,G06N20/00,,1,1,104-987-986-735-969,10.1109/access.2018.2874440,"NAVARRO GONZALEZ JOSE MANUEL ET AL: ""Optimizing Failure Prediction Time Windows Through Genetic Algorithms and Random Forests"", IEEE ACCESS, vol. 6, 31 October 2018 (2018-10-31), pages 58307 - 58323, XP011694012, DOI: 10.1109/ACCESS.2018.2874440",PENDING
134,EP,A1,EP 3841967 A1,056-861-692-675-275,2021-06-30,2021,EP 21155403 A,2016-01-06,AU 2015/900015 A;;EP 16701198 A;;IB 2016050042 W,2015-01-06,MOBILE WEARABLE MONITORING SYSTEMS,"This document describes a number of inventions comprising of one or more wearable devices (i.e. attached or applied to limbs, body, head or other body extremities but also applicable to implanted or physiologically attachable systems). These systems have a means of enabling diagnostic or prognostic monitoring applicable to monitoring relevant parameters and corresponding analysis determination and characterisation applicable to the onset or detection of events or health conditions of interest. One application relates to sleep monitoring and associate EEG sensors.",BURTON DAVID,BURTON DAVID,,https://lens.org/056-861-692-675-275,Patent Application,yes,4,10,29,29,0,A61B5/14551;;A61B5/4806;;A61B5/4809;;A61B5/4818;;A61B5/6802;;A61B5/6803;;A61B5/681;;A61B5/16;;A61B5/72;;A61B5/112;;A61B3/16;;A61B8/06;;A61B8/02;;A61B8/4427;;A61B8/488;;A61B2560/0242;;A61B5/0002;;A61B5/0205;;A61B5/024;;A61B5/11;;A61B5/1123;;A61B5/14551;;A61B5/4806;;A61B5/6814;;A61B5/6824;;G16H40/63;;G16H40/67;;A61B5/4815;;Y02A90/10;;A61B5/291;;A61B5/398;;A61B5/389;;A61B5/369;;A61B5/4082;;G16H50/20;;A61N2/00;;A61N2005/0626;;A61N5/06;;A61B5/4806;;A61B5/4836;;A61B5/4815;;A61B5/0205;;A61B5/14551;;A61B5/4812;;A61B5/369;;A61B5/389;;A61B5/398;;A61B5/681;;A61B5/6824;;G16H50/20;;G16H40/63;;G16H40/67,A61B5/00;;A61B5/0205;;A61B5/024;;A61B5/11;;A61B5/1455;;A61B5/291;;A61B5/369;;A61B5/389;;A61B5/398,,3,3,144-227-092-918-896;;006-747-379-698-419;;048-971-320-421-183,17235428;;10.1007/s10072-007-0734-z;;10.1002/mds.23121;;20629146;;10.1212/01.wnl.0000203648.80727.5b;;16567700,"FANTINI M L ET AL: ""Idiopathic rapid eye movement sleep behaviour disorder"", NEUROLOGICAL SCIENCES ; OFFICIAL JOURNAL OF THE ITALIAN NEUROLOGICAL SOCIETY, SPRINGER-VERLAG, MI, vol. 28, no. 1, 1 January 2007 (2007-01-01), pages S15 - S20, XP019462608, ISSN: 1590-3478, DOI: 10.1007/S10072-007-0734-Z;;BENNINGER DAVID H ET AL: ""REM sleep behavior disorder is not linked to postural instability and gait dysfunction in Parkinson."", MOVEMENT DISORDERS : OFFICIAL JOURNAL OF THE MOVEMENT DISORDER SOCIETY 15 AUG 2010, vol. 25, no. 11, 15 August 2010 (2010-08-15), pages 1597 - 1604, XP000952691, ISSN: 1531-8257;;POSTUMA ET AL: ""Potential early markers of Parkinson disease in idiopathic REM sleep behavior disorder"", vol. 66, no. 6, 28 March 2006 (2006-03-28), pages 845 - 851, XP009526919, ISSN: 0028-3878, Retrieved from the Internet <URL:https://n.neurology.org/content/66/6/845> DOI: 10.1212/01.WNL.0000203648.80727.5B",ACTIVE
135,EP,B1,EP 3602999 B1,130-351-538-178-459,2021-05-19,2021,EP 18713237 A,2018-03-26,EP 17163365 A;;EP 2018057676 W,2017-03-28,INITIALISATION VECTOR IDENTIFICATION FOR ENCRYPTED MALWARE TRAFFIC DETECTION,,BRITISH TELECOMM,EL-MOUSSA FADI;;KALLOS GEORGE,BRITISH TELECOMMUNICATIONS PUBLIC LIMITED COMPANY (2022-02-16),https://lens.org/130-351-538-178-459,Granted Patent,yes,1,0,5,5,0,H04L63/1408;;H04L63/1416;;G06N3/04;;G06N3/084,H04L29/06,,2,0,,,"Jean Goubault-Larrecq and Julien Olivain: ""Detecting Subverted Cryptographic Protocols by Entropy Checking"", research report LSV-06-13, Laboratoire Spécification et Vérification, June 2006 (2006-06), pages 1-19, XP055216893, FR Retrieved from the Internet: URL:http://www.lsv.ens-cachan.fr/Publis/RA PPORTS_LSV/PDF/rr-lsv-2006-13.pdf [retrieved on 2015-09-29] cited in the application;;HAN ZHANG ET AL: ""Detecting encrypted botnet traffic"", COMPUTER COMMUNICATIONS WORKSHOPS (INFOCOM WKSHPS), 2013 IEEE CONFERENCE ON, IEEE, 14 April 2013 (2013-04-14), pages 163-168, XP032436466, DOI: 10.1109/INFCOMW.2013.6562912 ISBN: 978-1-4799-0055-8 cited in the application",ACTIVE
136,EP,B1,EP 3596656 B1,129-767-745-663-637,2021-05-05,2021,EP 19743015 A,2019-05-24,NL 2020989 A;;NL 2020996 A;;NL 2019050301 W,2018-05-25,"MONITORING AND ANALYZING BODY LANGUAGE WITH MACHINE LEARNING, USING ARTIFICIAL INTELLIGENCE SYSTEMS FOR IMPROVING INTERACTION BETWEEN HUMANS, AND HUMANS AND ROBOTS",,KEPLER VISION TECH B V,STOKMAN HENRICUS MEINARDUS GERARDUS;;VAN OLDENBORGH MARC JEAN BAPTIST;;ALNAJAR FARES,,https://lens.org/129-767-745-663-637,Granted Patent,yes,5,0,7,8,0,G06V40/20;;G06T7/70;;G06N20/00;;G06T2207/10016;;G06T2207/20076;;G06T2207/30196;;G06V40/28;;G06V2201/07,G06K9/00,,5,0,,,"REHRL T ET AL: ""Multiple Parallel Vision-Based Recognition in a Real-Time Framework for Human-Robot-Interaction Scenarios"", ADVANCES IN COMPUTER-HUMAN INTERACTIONS, 2010. ACHI '10. THIRD INTERNATIONAL CONFERENCE ON, IEEE, PISCATAWAY, NJ, USA, 10 February 2010 (2010-02-10), pages 50-55, XP031648116, ISBN: 978-1-4244-5693-2;;Alejandro Jaimes ET AL: ""Multimodal Human Computer Interaction: A Survey : ICCV 2005 Workshop on HCI, Beijing, China, October 21, 2005. Proceedings"" In: ""Serious Games"", 1 January 2005 (2005-01-01), Springer International Publishing, Cham 032682, XP055623017, ISSN: 0302-9743 ISBN: 978-3-319-10403-4 vol. 3766, pages 1-15, DOI: 10.1007/11573425_1, section 3.2;;CASTELLANO GINEVRA ET AL: ""Detecting perceived quality of interaction with a robot using contextual features"", AUTONOMOUS ROBOTS, KLUWER ACADEMIC PUBLISHERS, DORDRECHT, NL, vol. 41, no. 5, 8 July 2016 (2016-07-08), pages 1245-1261, XP036203827, ISSN: 0929-5593, DOI: 10.1007/S10514-016-9592-Y [retrieved on 2016-07-08];;MARISKA ESTHER KRET ET AL: ""Social context influences recognition of bodily expressions"", EXPERIMENTAL BRAIN RESEARCH, SPRINGER, BERLIN, DE, vol. 203, no. 1, 17 April 2010 (2010-04-17), pages 169-180, XP019839888, ISSN: 1432-1106;;MORENCY ET AL: ""Head gestures for perceptual interfaces: The role of context in improving recognition"", ARTIFICIAL INTELLIGENCE, ELSEVIER SCIENCE PUBLISHER B.V., AMSTERDAM, NL, vol. 171, no. 8-9, 31 May 2007 (2007-05-31), pages 568-585, XP022099990, ISSN: 0004-3702, DOI: 10.1016/J.ARTINT.2007.04.003",ACTIVE
137,EP,A1,EP 3798659 A1,043-671-275-291-044,2021-03-31,2021,EP 20206710 A,2018-11-13,EP 17201373 A;;EP 17210164 A;;EP 18796987 A;;EP 2018081030 W,2017-11-13,AUTOMATED NONINVASIVE DETERMINING THE FERTILITY OF A BIRD'S EGG,"Shown herein is a method of automated noninvasive determining the fertility of a bird's egg (14), comprising the following steps:conveying a plurality of bird eggs (14) sequentially or in parallel into an NMR apparatus (18),subjecting the bird eggs (14) to an NMR measurement, such as to generate a 3-D NMR image of at least a part of each of said eggs (14), said 3-D NMR image having a spatial resolution in at least one dimension of 1.0 mm or less, preferably of 0.50 mm or less, wherein said part of the egg (14) includes the germinal disc of the respective egg (14), determining a prediction of the fertility according to at least one of the following two procedures:(i) deriving at least one feature from each of said 3-D NMR images, and employing said at least one feature in a feature-based classifier for determining a prediction of the fertility, and(ii) using a deep learning algorithm, and in particular a deep learning algorithm based on convolutional neural networks, generative adversarial networks, recurrent neural networks or long short-term memory networks.",UNIV MUENCHEN TECH,GÓMEZ PEDRO A;;MOLINA-ROMERO MIGUEL;;HAASE AXEL;;SCHUSSER BENJAMIN;;AIGNER MAXIMILIAN;;LAPARIDOU MARIA,,https://lens.org/043-671-275-291-044,Patent Application,yes,10,0,38,38,0,G01N24/085;;G01R33/3415;;G01R33/4835;;G01R33/5611;;G01N33/08;;G01N33/08;;G01R33/483;;G01N24/085;;G01R33/4835;;A01K43/04;;B07C5/344;;G01N24/085;;G01N33/08;;G01R33/3415;;G01R33/5608;;G01R33/561;;G01R33/307;;G01R33/5611,G01R33/483;;G01N33/08;;G01N33/483,,31,21,015-150-806-920-227;;168-081-247-605-520;;137-716-640-041-022;;082-209-393-192-885;;033-728-135-090-728;;071-666-521-667-895;;034-377-320-403-84X;;045-779-156-795-693;;007-729-398-347-160;;035-748-607-984-916;;186-498-104-767-924;;039-341-740-425-356;;129-244-763-388-47X;;014-004-043-247-975;;006-033-973-063-884;;026-755-922-345-486;;000-344-890-213-242;;013-662-727-978-128;;013-110-619-366-76X;;039-324-478-997-10X;;062-273-537-239-533,10.1093/ps/81.4.529;;11989753;;10.1017/cbo9780511801389;;10.1137/060666998;;10.1002/(sici)1522-2594(199911)42:5<952::aid-mrm16>3.3.co;2-j;;10.1002/(sici)1522-2594(199911)42:5<952::aid-mrm16>3.0.co;2-s;;10542355;;10.1002/mrm.10666;;14705048;;10.1007/0-387-25465-x_9;;10.1006/jcss.1997.1504;;10.1109/iccv.2005.194;;10.1002/mrm.1910150305;;2233218;;10.1016/j.jmr.2006.06.027;;16860581;;2663289;;1925560;;10.1126/science.1925560;;10.1088/0022-3719/9/15/004;;22152368;;10.1016/j.jmr.2011.09.021;;pmc4142121;;10.1002/mrm.24751;;23649942;;10.1109/tsp.2002.807005;;12111967;;10.1002/mrm.10171;;10.1371/journal.pone.0015710;;21187930;;pmc3004955;;17969013;;10.1002/mrm.21391;;10.1103/physrev.112.1693;;10.1016/j.neuroimage.2017.02.089;;28263925,"S. KLEIN ET AL: ""Localization of the fertilized germinal disc in the chicken egg before incubation"", POULTRY SCIENCE, vol. 81, no. 4, 1 April 2002 (2002-04-01), Oxford, pages 529 - 536, XP055461661, ISSN: 0032-5791, DOI: 10.1093/ps/81.4.529;;A. DAVENEL ET AL: ""Attempts for early gender determination of chick embryos in ovo using Magnetic Resonance Imaging"", 1 June 2015 (2015-06-01), XP055462402, Retrieved from the Internet <URL:http://www.wpsa.com/index.php/publications/wpsa-proceedings/2015/xxii-european-symposium-on-the-quality-of-poultry-meat-and-the-xvi-european-symposium-on-the-quality-of-eggs-and-egg-products/2196-attempts-for-early-gender-determination-of-chick-embryos-in-ovo-using-magnetic-resonance-imaging/file> [retrieved on 20180323];;CRISTIANINI, N.SHAWE-TAYLOR, J.: ""An Introduction to Support Vector Machines and other kernel based learning methods"", AI MAGAZINE, vol. 22, 2000, pages 190;;TIPPING, M. E.: ""Sparse Bayesian Learning and the Relevance Vector Machine"", J. MACH. LEARN. RES., vol. 1, 2001, pages 211 - 244, XP008099985, DOI: 10.1162/15324430152748236;;DEKEL, O.SHALEV-SHWARTZ, S.SINGER, Y.: ""The forgetron: a kernel-based perceptron on a budget"", SIAM J. COMPUT., vol. 37, no. 5, 2008, pages 1342 - 1372, XP055218413, DOI: 10.1137/060666998;;PRUESSMANN, K. P.WEIGER, M.SCHEIDEGGER, M. B.BOESIGER, P.: ""SENSE: sensitivity encoding for fast MRI"", MAGN. RESON. MED., vol. 42, 1999, pages 952 - 962, XP000866655, DOI: 10.1002/(SICI)1522-2594(199911)42:5<952::AID-MRM16>3.0.CO;2-S;;HARGREAVES, B. A.NISHIMURA, D. G.CONOLLY, S. M.: ""Time-optimal multidimensional gradient waveform design for rapid imaging"", MAGN. RESON. MED., vol. 51, 2004, pages 81 - 92, XP007914338, DOI: 10.1002/mrm.10666;;ROKACH, L.MAIMON, O.: ""Data mining with decision trees: Theory and applications"", 2008, WORLD SCIENTIFIC PUB CO INC;;BREIMAN, L., RANDOM FORESTS. MACH. LEARN., vol. 45, 2001, pages 5 - 32;;RISH, I.: ""An empirical study of the naive Bayes classifier"", EMPIR. METHODS ARTIF. INTELL. WORK. IJCAI, vol. 22230, 2001, pages 41 - 46;;FREUND, Y.SCHAPIRE, R. E.: ""A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting"", J. COMPUT. SYST. SCI., vol. 55, 1997, pages 119 - 139;;JEROME FRIEDMANTREVOR HASTIEROBERT TIBSHIRANI: ""Additive logistic regression: a statistical view of boosting"", ANNALS OF STATISTICS, vol. 28, no. 2, 2000, pages 337 - 407, XP008149847, DOI: 10.1214/aos/1016218223;;TU, Z.: ""Probabilistic boosting-tree: Learning discriminative models for classification, recognition, and clustering"", PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, vol. II, 2005, pages 1589 - 1596, XP010857003, DOI: 10.1109/ICCV.2005.194;;STEPISNIK, J.ERZEN, V.KOS, M.: ""NMR imaging in the earth's magnetic field"", MAGN. RESON. MED., vol. 15, 1990, pages 386 - 391, XP000170518;;ROBINSON, J. N. ET AL.: ""Two-dimensional NMR spectroscopy in Earth's magnetic field"", J. MAGN. RESON., vol. 182, 2006, pages 343 - 347, XP024919449, DOI: 10.1016/j.jmr.2006.06.027;;LAUTERBUR, P. C.: ""Image formation by induced local interactions. Examples employing nuclear magnetic resonance"", NATURE, vol. 242, 1973, pages 190 - 191, XP036980656, DOI: 10.1038/242190a0;;STEHLING, M.TURNER, R.MANSFIELD, P.: ""Echo-planar imaging: magnetic resonance imaging in a fraction of a second"", SCIENCE, vol. 254, 1991, pages 43 - 50;;MANSFIELD, P.MAUDSLEY, A. A.: ""Planar spin imaging by NMR"", J. PHYS. C SOLID STATE PHYS., vol. 9, 1976, pages L409 - L412;;HAASE, A.FRAHM, J.MATTHAEI, D.HANICKE, W.MERBOLDT, K. D.: ""FLASH imaging. Rapid NMR imaging using low flip-angle pulses"", J. MAGN. RESON., vol. 6, 1986, pages 8 - 266;;GÓMEZ, P. A. ET AL.: ""Accelerated parameter mapping with compressed sensing: an alternative to MR Fingerprinting"", PROC INTL SOC MAG RESON MED, 2017;;PRUESSMANNETGRISWOLD, M. A.UECKER, M. ET AL.: ""ESPIRiT - An eigenvalue approach to autocalibrating parallel MRI: Where SENSE meets GRAPPA"", MAGN. RESON. MED., vol. 71, 2014, pages 990 - 1001, XP055357609, DOI: 10.1002/mrm.24751;;FESSLER, J. A.SUTTON, B.: ""Nonuniform Fast Fourier Transforms Using Min-Max Interpolation"", IEEE TRANS. SIGNAL PROCESS., vol. 51, 2003, pages 560 - 574, XP055089679, DOI: 10.1109/TSP.2002.807005;;GRISWOLD, M. A. ET AL.: ""Generalized auto calibrating partially parallel acquisitions (GRAPPA)"", MAGN. RES. MED, vol. 47, 2002, pages 1202 - 1210;;FEINBERG, D. A. ET AL.: ""Multiplexed echo planar imaging for sub-second whole brain fmri and fast diffusion imaging"", PLOS ONE, vol. 5, 2010;;LUSTIG, M.DONOHO, D.PAULY, J. M. SPARSE: ""MRI: The application of compressed sensing for rapid MR imaging"", MAGN. RESON. MED., vol. 58, 2007, pages 82 - 1195;;MA, D. ET AL.: ""Magnetic resonance fingerprinting"", NATURE, vol. 49, 2013, pages 187 - 192;;CARR, H. Y.: ""Steady-state free precession in nuclear magnetic resonance"", PHYS. REV., vol. 112, 1958, pages 1693 - 1701;;ALEXANDER, D. C. ET AL.: ""Image quality transfer and applications in diffusion MRI"", NEUROIMAGE, vol. 152, 2017, pages 283 - 298, XP085020677, DOI: 10.1016/j.neuroimage.2017.02.089;;TANNO, R. ET AL., BAYESIAN IMAGE QUALITY TRANSFER WITH CNNS: EXPLORING UNCERTAINTY IN DMRI SUPER-RESOLUTION, 2017, Retrieved from the Internet <URL:<http.Ilarxiv.orglabslo.oo66>>;;GOODFELLOW, I. J. ET AL., GENERATIVE ADVERSARIAL NETWORKS, 2014, Retrieved from the Internet <URL:<httZ2:ZZarxiv.orglabsllo6.2661>>;;A. EINSTEIN, ANN PHYSIK, vol. 17, 1905, pages 549",PENDING
138,EP,B1,EP 3272095 B1,046-019-978-462-729,2021-03-31,2021,EP 16712757 A,2016-03-15,EP 15275067 A;;EP 2016055507 W,2015-03-17,MALICIOUS ENCRYPTED NETWORK TRAFFIC IDENTIFICATION USING FOURIER TRANSFORM,,BRITISH TELECOMM,AZVINE BEN;;EL-MOUSSA FADI;;KALLOS GEORGE,BRITISH TELECOMMUNICATIONS PUBLIC LIMITED COMPANY (2022-02-16),https://lens.org/046-019-978-462-729,Granted Patent,yes,5,14,7,7,0,H04L63/1416;;H04L63/0428;;H04L63/1416;;G06F17/141;;H04L63/0428;;H04L63/1425;;H04L63/1441,H04L29/06,,0,0,,,,ACTIVE
139,EP,A1,EP 3785581 A1,083-079-693-321-97X,2021-03-03,2021,EP 19870066 A,2019-07-15,KR 2019008726 W,2019-07-15,ARTIFICIAL INTELLIGENCE COOKING APPARATUS,"Disclosed is an artificial intelligence cooking device. The artificial intelligence cooking device includes a heating portion for heating ingredients in a cooking vessel, a vibration sensor for detecting a vibration signal of the ingredients in the cooking vessel, and a processor configured to provide data corresponding to the vibration signal to an artificial intelligence model to obtain information about whether the ingredients in the cooking vessel are boiling, and perform control based on the obtained information.",LG ELECTRONICS INC,CHOI HEUNGSIK;;AN HYOJIN;;KIM SANGOH,,https://lens.org/083-079-693-321-97X,Patent Application,yes,0,1,7,7,0,A47J36/321;;H05B6/062;;B25J11/0045;;B25J9/161;;B25J9/1679;;F24C15/10;;G01H1/00;;G06N3/08;;H05B6/062;;H05B6/12;;A47J36/321;;G05B19/042;;G05B2219/2643;;G06N3/08;;H05B6/1209;;H05B2213/05,A47J36/32;;A47J27/21;;F24C15/20,,0,0,,,,PENDING
140,EP,A1,EP 3782771 A1,082-878-920-815-684,2021-02-24,2021,EP 19853500 A,2019-08-30,KR 20180102689 A;;KR 2019011133 W,2018-08-30,ROBOT AND CONTROL METHOD THEREFOR,"The present invention relates to a robot and a control method therefor and, more particularly, to a robot and a control method therefor, the robot detecting peripheral obstacles and structures by using an image in front of same, thereby providing an efficient and safe moving path. A robot control method according to one embodiment of the present invention comprises the steps of: capturing an image; acquiring a first image of which the bottom surface is separated in the image; recognizing obstacles included in the image by using a learned first artificial intelligence model; allowing a robot to acquire and store a second image in order to perform a task on the basis of the information about the first image and the region including the recognized obstacles; and allowing the robot to move on the basis of the second image.",SAMSUNG ELECTRONICS CO LTD,HONG SOONHYUK,,https://lens.org/082-878-920-815-684,Patent Application,yes,0,0,7,7,0,G05D1/0246;;A47L11/4011;;A47L9/2857;;A47L9/2805;;A47L9/2852;;A47L11/4061;;A47L9/2894;;A47L2201/04;;B25J9/1666;;B25J9/1676;;B25J19/023;;B25J11/0085;;A47L2201/04;;B25J9/1697;;B25J13/08;;G05D1/243;;G05D1/246;;G05D1/622;;G05D1/6484;;G06V10/70;;G05D1/0246;;A47L9/2852;;A47L2201/04;;B25J9/1666;;B25J11/0085;;B25J19/023,B25J9/16;;A47L9/28;;B25J11/00;;B25J19/02,,0,0,,,,PENDING
141,EP,A1,EP 3783882 A1,181-658-140-591-24X,2021-02-24,2021,EP 19875951 A,2019-06-06,CN 201811260175 A;;CN 2019090372 W,2018-10-26,CAMERA APPARATUS ADJUSTMENT METHOD AND RELATED DEVICE,"Embodiments of the present invention disclose a method for adjusting a camera apparatus. The method includes: A computing device obtains tunnel environment data, determines an exposure parameter of a camera apparatus in a vehicle based on the tunnel environment data, and adjusts the camera apparatus based on the exposure parameter when the vehicle enters or exits a tunnel. The tunnel environment data is tunnel-related environment data that is collected before the vehicle enters or exits the tunnel. By implementing the embodiments of the present invention, the exposure parameter of the camera apparatus can be adjusted timely and accurately, thereby effectively ensuring safety of vehicle driving.",HUAWEI TECH CO LTD,YANG DONGDONG;;HU WEILONG;;YANG TAO,,https://lens.org/181-658-140-591-24X,Patent Application,yes,0,2,6,6,0,H04N23/73;;G07C5/0866;;G06N3/084;;G06V10/60;;G06V20/56;;H04N23/64;;H04N23/71;;H04N23/73;;H04N23/75;;H04N23/76;;G06N3/084;;G06V10/60;;G06V20/56,H04N5/235;;G06V10/60;;G07C5/08,,0,0,,,,ACTIVE
142,EP,A1,EP 3772710 A1,039-425-973-300-069,2021-02-10,2021,EP 20171744 A,2020-04-28,KR 2019010013 W,2019-08-08,ARTIFICIAL INTELLIGENCE SERVER,"An artificial intelligence server is disclosed. The artificial intelligence server includes an input unit to which input data is inputted, and a processor, when a first output value outputted by an artificial intelligence model with respect to first input data is correct and a second output value outputted by the artificial intelligence model with respect to second input data is incorrect, configured to use the first input data and the second input data to obtain a first domain causing an incorrect answer, and train the artificial intelligence model to be domain-adapted for the first domain.",LG ELECTRONICS INC,HAN JONGWOO;;KIM JAEHONG;;KIM HYOEUN;;LEE TAEHO;;JEON HYEJEONG;;JEONG HANGIL;;CHOI HEEYEON,,https://lens.org/039-425-973-300-069,Patent Application,yes,0,0,5,5,0,G06F30/27;;G06F16/29;;G06F18/214;;G06F18/24323;;G06N3/045;;G06N3/08;;G06V20/10;;G10L15/26;;G06N20/00;;G06N3/08;;G06N20/20;;G06N3/045;;G06N3/08;;G06N20/00;;G06F18/2431;;G06N3/04;;G06N5/01,G06N20/00,,1,0,,,"MEHRAN KHODABANDEH ET AL: ""A Robust Learning Approach to Domain Adaptive Object Detection"", 4 April 2019 (2019-04-04), XP055737962, Retrieved from the Internet <URL:https://arxiv.org/pdf/1904.02361v1.pdf> [retrieved on 20201008]",PENDING
143,EP,A1,EP 3757789 A1,127-232-454-298-461,2020-12-30,2020,EP 20181598 A,2020-06-23,US 201916453204 A,2019-06-26,MANAGED EDGE LEARNING IN HETEROGENEOUS ENVIRONMENTS,"Systems and methods are provided for managing machine learning processes within distributed and heterogeneous environments. The distributed and heterogeneous environments may include different types of devices that include different specifications, security, and privacy concerns. The devices participate in complex machine learning tasks while maintaining both privacy and autonomy. The systems and methods manage the lifecycle of how machine learning workloads are distributed.",HERE GLOBAL BV,CAPOTA CATALIN;;SPRAGUE MICHAEL;;SCAVUZZO MARCO;;JALALIRAD AMIR;;DO LYMAN;;DIVAKARUNI BALA,,https://lens.org/127-232-454-298-461,Patent Application,yes,0,2,2,2,0,G06F9/5072;;G06N3/045;;G06N3/047;;G06N3/048;;G06N5/01;;G06N7/01;;G06N20/00;;G06F9/5072;;G06F18/214;;G06F21/6245;;G06N20/00,G06F9/50;;G06N20/00,,2,1,068-037-300-460-460,10.1109/iotdi.2018.00024,"KEITH BONAWITZ ET AL: ""Towards Federated Learning at Scale: System Design"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 4 February 2019 (2019-02-04), XP081024907;;SANDRA SERVIA-RODRIGUEZ ET AL: ""Privacy-Preserving Personal Model Training"", 2018 IEEE/ACM THIRD INTERNATIONAL CONFERENCE ON INTERNET-OF-THINGS DESIGN AND IMPLEMENTATION (IOTDI), 3 April 2018 (2018-04-03), pages 153 - 164, XP055716191, ISBN: 978-1-5386-6312-7, DOI: 10.1109/IoTDI.2018.00024",DISCONTINUED
144,EP,A1,EP 3757817 A1,112-298-730-870-397,2020-12-30,2020,EP 19812106 A,2019-05-10,KR 20180061217 A;;KR 2019005604 W,2018-05-29,ELECTRONIC DEVICE AND CONTROL METHOD THEREFOR,"A method for controlling an electronic device is disclosed. The method for controlling an electronic device comprises the steps of: receiving a sketch drawn by a user; acquiring at least one machine-generated image on the basis of the sketch by using an artificial intelligence model learned by an artificial intelligence algorithm; displaying the acquired at least one machine-generated image; receiving a user command for selecting one of at least one displayed machine-generated image, and searching for at least one piece of content corresponding to the image selected according to the user command; and providing the searched for at least one piece of content.",SAMSUNG ELECTRONICS CO LTD,CHO EUNAE;;KIM JINHYUN;;PARK GIHOON,,https://lens.org/112-298-730-870-397,Patent Application,yes,0,0,6,6,0,G06F16/583;;G06F3/048;;G06N3/02;;G06F16/532;;G06F3/04883;;G06N20/00;;G06F16/583;;G06F16/55;;G06F16/5854;;G06T11/203;;G06V10/74;;G06V10/774,G06F16/583;;G06F3/048;;G06N3/02,,0,0,,,,DISCONTINUED
145,EP,B1,EP 3452787 B1,057-981-116-514-29X,2020-12-23,2020,EP 17906924 A,2017-04-27,CN 2017082176 W,2017-04-27,SYSTEMS AND METHODS FOR ROUTE PLANNING,,BEIJING DIDI INFINITY TECHNOLOGY & DEV CO LTD,WANG ZHENG;;WANG ZITENG;;ZHONG XIAOWEI,,https://lens.org/057-981-116-514-29X,Granted Patent,yes,8,0,16,16,0,G01C21/3446;;G01C21/20;;G01C21/3446;;G01C21/20;;G06N3/045;;G06N3/088,G01C21/34,,2,0,,,"MEHDI MOHAMMADI ET AL: ""Path Planning in Support of Smart Mobility Applications using Generative Adversarial Networks"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 23 April 2018 (2018-04-23), XP081228856,;;NORIAKI HIROSE ET AL: ""To Go or Not To Go? A Near Unsupervised Learning Approach For Robot Navigation"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 16 September 2017 (2017-09-16), XP080821665,",ACTIVE
146,EP,A1,EP 3754592 A1,092-055-117-239-951,2020-12-23,2020,EP 20190447 A,2018-12-26,KR 20170180036 A;;EP 18894837 A;;KR 2018016678 W,2017-12-26,IMAGE ACQUISITION DEVICE AND METHOD OF CONTROLLING THE SAME,"Provided are an artificial intelligence (AI) system that mimics functions, such as recognition and determination by human brains, by utilizing a machine learning algorithm and applications of the Al system. An image acquisition device is disclosed including a camera configured to acquire a first image, at least one processor configured to: input the first image to a first Al neural network; detect, by the first Al neural network from data corresponding to a plurality of object included the first image, first data corresponding to the main object and second data corresponding to the sub-object, and generate, using a second Al neural network, a second image by restoring third data corresponding to at least a portion of the main object hidden by the sub-object, wherein the third data replaces the second data; and a display configured to display at least one of the first image and the second image.",SAMSUNG ELECTRONICS CO LTD,JUNG JAEHO;;SUNG YEULTAK,,https://lens.org/092-055-117-239-951,Patent Application,yes,1,0,12,17,0,G06T7/0002;;G06N3/04;;G06N3/08;;G06T2207/10004;;G06T2207/20084;;G06T2207/20081;;G06T2207/20104;;G06T2207/30196;;G06T5/50;;G06T2207/10016;;G06T2207/20221;;G06T5/77;;G06T5/60;;G06T1/0007;;G06T7/11;;G06T7/20;;G06T2207/20084;;G06T5/00,G06T5/00,,1,0,,,"CHAO YANG ET AL: ""High-Resolution Image Inpainting using Multi-Scale Neural Patch Synthesis"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 30 November 2016 (2016-11-30), XP080735402, DOI: 10.1109/CVPR.2017.434",ACTIVE
147,EP,A2,EP 3748993 A2,177-215-601-733-187,2020-12-09,2020,EP 20181536 A,2019-04-10,JP 2018099553 A;;EP 19807568 A;;JP 2019015710 W,2018-05-24,INFORMATION PROCESSING DEVICE,"Provided is an information processing device that controls and presents sound information in an appropriate form to a user who acts in an environment on the basis of situation recognition including recognition of the environment and recognition of the actions of the user. The information processing device includes: a sensor that detects an object; an open ear style earpiece that is worn on an ear of a listener, and includes an acoustics generation unit, and a sound guide portion that transmits a sound generated by the acoustics generation unit into an earhole; and a processing unit that processes sound information of a sound source, the sound information being generated by the acoustics generation unit, the processing unit acquiring the sound information of the sound source corresponding to the object detected by the sensor, and a process of localizing a sound image of the acquired sound source while varying a position of the sound image in accordance with a position in a three-dimensional acoustic space, the position in the three-dimensional acoustic space corresponding to a position of the detected object.",SONY CORP,IGARASHI GO;;SUZUKI JUNYA;;NUMAOKA CHISATO,SONY GROUP CORPORATION (2021-07-28),https://lens.org/177-215-601-733-187,Patent Application,yes,3,0,13,13,0,G10K11/178;;H04R1/1016;;H04S7/304;;H04S3/004;;H04S2400/11;;G09B21/006;;H04S1/002;;G01S15/06;;H04R1/1016;;H04R2420/07,H04S1/00;;G09B21/00;;H04R1/10;;H04S3/00;;H04S7/00,,0,0,,,,PENDING
148,EP,B1,EP 3523649 B1,166-957-484-753-19X,2020-11-11,2020,EP 18796987 A,2018-11-13,EP 17201373 A;;EP 17210164 A;;EP 2018081030 W,2017-11-13,AUTOMATED NONINVASIVE DETERMINING THE FERTILITY OF A BIRD'S EGG,,UNIV MUENCHEN TECH,GÓMEZ PEDRO A;;MOLINA-ROMERO MIGUEL;;HAASE AXEL;;SCHUSSER BENJAMIN;;AIGNER MAXIMILIAN;;LAPARIDOU MARIA,,https://lens.org/166-957-484-753-19X,Granted Patent,yes,3,0,38,38,0,G01N24/085;;G01R33/3415;;G01R33/4835;;G01R33/5611;;G01N33/08;;G01N33/08;;G01R33/483;;G01N24/085;;G01R33/4835;;A01K43/04;;B07C5/344;;G01N24/085;;G01N33/08;;G01R33/3415;;G01R33/5608;;G01R33/561;;G01R33/307;;G01R33/5611,G01N33/08;;G01N24/08;;G01R33/483,,2,0,,,"A. Davenel ET AL: ""Attempts for early gender determination of chick embryos in ovo using Magnetic Resonance Imaging"", , 1 June 2015 (2015-06-01), XP055462402, Retrieved from the Internet: URL:http://www.wpsa.com/index.php/publicat ions/wpsa-proceedings/2015/xxii-european-s ymposium-on-the-quality-of-poultry-meat-an d-the-xvi-european-symposium-on-the-qualit y-of-eggs-and-egg-products/2196-attempts-f or-early-gender-determination-of-chick-emb ryos-in-ovo-using-magnetic-resonance-imagi ng/file [retrieved on 2018-03-23];;S. KLEIN ET AL: ""Localization of the fertilized germinal disc in the chicken egg before incubation"", POULTRY SCIENCE, vol. 81, no. 4, 1 April 2002 (2002-04-01), pages 529-536, XP055461661, Oxford ISSN: 0032-5791, DOI: 10.1093/ps/81.4.529",ACTIVE
149,EP,B1,EP 2854545 B1,101-756-876-696-076,2020-10-21,2020,EP 13724612 A,2013-05-29,EP 12169936 A;;EP 12197131 A;;EP 2013061026 W;;EP 13724612 A,2012-05-30,COMPOSITIONS COMPRISING A BIOLOGICAL CONTROL AGENT AND AN INSECTICIDE,,BAYER CROPSCIENCE AG,HELLWEGE ELKE;;ANDERSCH WOLFRAM;;STENZEL KLAUS;;SPRINGER BERND,,https://lens.org/101-756-876-696-076,Granted Patent,yes,2,0,25,180,0,A01N63/30;;A01N63/20;;A01N63/22;;A01N63/23;;A01N63/28;;A01N63/23;;A01N29/12;;A01N31/14;;A01N47/34;;A01N47/38;;A01N53/00;;A01N63/28;;Y10S435/832;;Y10S435/886;;A01N63/30;;A01N53/00;;A01N63/20;;A01N63/22;;A01N63/23;;A01N63/28,A01N29/12;;A01N31/14;;A01N47/34;;A01N47/38;;A01N53/00;;A01N63/20;;A01N63/22;;A01N63/23;;A01N63/28;;A01N63/30;;A01P7/04,,0,0,,,,ACTIVE
150,EP,A1,EP 3723001 A1,156-221-605-046-500,2020-10-14,2020,EP 20168908 A,2020-04-09,US 201916380180 A,2019-04-10,TRANSFERRING SYNTHETIC LIDAR SYSTEM DATA TO REAL WORLD DOMAIN FOR AUTONOMOUS VEHICLE TRAINING APPLICATIONS,"Methods and systems are disclosed for correlating synthetic LiDAR data to a real-world domain for use in training an autonomous vehicle in how to operate in an environment. To do this, the system will obtain a data set of synthetic LiDAR data, transfer the synthetic LiDAR data to a two-dimensional representation, use the two-dimensional representation to train a model of a real-world environment, and use the trained model of the real-world environment to train an autonomous vehicle.",ARGO AI LLC,CHEN KEVIN;;HAYS JAMES;;YUMER ERSIN,,https://lens.org/156-221-605-046-500,Patent Application,yes,2,3,6,6,0,G09B9/04;;G09B9/05;;G01S17/931;;G01S17/894;;G06T17/00;;G06F30/20;;G06T3/067;;G06V20/56;;G06V10/82;;G06V10/803;;G06V10/774;;G06F18/251;;G05D1/0088;;G05D1/0221;;G06F30/20;;G01S17/90;;G06V20/56;;G06V10/774;;G06V10/803;;G06V10/82,G06V10/774,,0,0,,,,PENDING
151,EP,B1,EP 3272096 B1,136-680-351-971-313,2020-09-30,2020,EP 16713748 A,2016-03-15,EP 15275068 A;;EP 2016055506 W,2015-03-17,LEARNED PROFILES FOR MALICIOUS ENCRYPTED NETWORK TRAFFIC IDENTIFICATION,,BRITISH TELECOMM,EL- MOUSSA FADI;;AZVINE BEN;;KALLOS GEORGE,,https://lens.org/136-680-351-971-313,Granted Patent,yes,3,0,7,7,0,H04L63/1416;;H04L63/1416;;G06F17/141;;G06N3/08;;H04L63/0428;;H04L63/1441,H04L29/06,,2,0,,,"Jean Goubault-Larrecq and Julien Olivain: ""Detecting Subverted Cryptographic Protocols by Entropy Checking"", research report LSV-06-13, Laboratoire Spécification et Vérification, June 2006 (2006-06), pages 1-19, XP055216893, FR Retrieved from the Internet: URL:http://www.lsv.ens-cachan.fr/Publis/RA PPORTS_LSV/PDF/rr-lsv-2006-13.pdf [retrieved on 2015-09-29];;ROBERT LYDA ET AL: ""Using Entropy Analysis to Find Encrypted and Packed Malware"", SECURITY & PRIVACY, IEEE, IEEE SERVICE CENTER, LOS ALAMITOS, CA, US, vol. 5, no. 2, March 2007 (2007-03), pages 40-45, XP011175986, ISSN: 1540-7993",ACTIVE
152,EP,A1,EP 3705367 A1,163-870-028-943-01X,2020-09-09,2020,EP 19160830 A,2019-03-05,EP 19160830 A,2019-03-05,TRAINING A GENERATOR UNIT AND A DISCRIMINATOR UNIT FOR COLLISION-AWARE TRAJECTORY PREDICTION,"An aspect of the invention describes a system for training a generator unit and a discriminator unit simultaneously, with said generator unit configured to determine a future trajectory of at least one other road in the environment of a vehicle considering an observed trajectory of the at least one other road user, with said discriminator unit configured to determine whether the determined future trajectory of the other road user is an actual future trajectory of the other road user, and with said system configured to train said generator unit and said discriminator unit simultaneously with gradient descent.",BAYERISCHE MOTOREN WERKE AG,VAN DER HEIDEN TESSA;;COCCIA GIUSEPPE,,https://lens.org/163-870-028-943-01X,Patent Application,yes,4,1,5,5,0,B60W30/095;;B60W40/00;;B60W40/02;;G06N3/04;;G08G1/166;;B60W30/0956;;G06N3/006;;G06N3/08;;G06N3/044;;G06N3/045;;G05D1/0289;;B60W60/0025;;B60W60/00272;;B60W60/0011;;B60W60/00274,B60W30/095;;G06N3/04;;G06N3/08;;G08G1/16,,0,0,,,,ACTIVE
153,EP,A2,EP 3699825 A2,147-492-940-178-090,2020-08-26,2020,EP 20158910 A,2020-02-23,US 201962809353 P;;US 202016797422 A,2019-02-22,SYSTEMS AND METHODS FOR DEPLOYING AND UPDATING NEURAL NETWORKS AT THE EDGE OF A NETWORK,"Methods, devices and system for updating a neural network on an edge device that has low-bandwidth uplink capability include a centralized site/device that is configured to train and send the neural network to the edge device. In response, the centralized site/device may receive neural network information from the edge device that includes all or portions of a dataset, output activations, and/or overall inference result that is collected or generated in the edge device. The centralized site/device may use the received neural network information to update all or a part of the trained neural network, generate updated neural network information based on the updated neural network, and send the updated neural network information to the edge device.",UBOTICA TECH LTD,DUNNE AUBREY;;BUCKLEY FINTAN,,https://lens.org/147-492-940-178-090,Patent Application,yes,0,15,3,3,0,G06N3/08;;G06N3/045;;G06N3/049;;G06N3/08;;G06F8/61;;G06F8/658;;G06F18/254;;G06F18/285;;G06N3/045;;G06N3/082;;G06N20/20,G06N3/00;;G06N3/04;;G06N3/08,,0,0,,,,PENDING
154,EP,A1,EP 3687193 A1,010-608-974-305-32X,2020-07-29,2020,EP 19807568 A,2019-04-10,JP 2018099553 A;;JP 2019015710 W,2018-05-24,INFORMATION PROCESSING DEVICE AND INFORMATION PROCESSING METHOD,"Provided is an information processing device that controls and presents sound information in an appropriate form to a user who acts in an environment on the basis of situation recognition including recognition of the environment and recognition of the actions of the user. The information processing device includes: a sensor that detects an object; an open ear style earpiece that is worn on an ear of a listener, and includes an acoustics generation unit, and a sound guide portion that transmits a sound generated by the acoustics generation unit into an earhole; and a processing unit that processes sound information of a sound source, the sound information being generated by the acoustics generation unit, the processing unit acquiring the sound information of the sound source corresponding to the object detected by the sensor, and a process of localizing a sound image of the acquired sound source while varying a position of the sound image in accordance with a position in a three-dimensional acoustic space, the position in the three-dimensional acoustic space corresponding to a position of the detected object.",SONY CORP,IGARASHI GO;;SUZUKI JUNYA;;NUMAOKA CHISATO,SONY GROUP CORPORATION (2021-07-28),https://lens.org/010-608-974-305-32X,Patent Application,yes,0,3,13,13,0,G10K11/178;;H04R1/1016;;H04S7/304;;H04S3/004;;H04S2400/11;;G09B21/006;;H04S1/002;;G01S15/06;;H04R1/1016;;H04R2420/07,H04S1/00;;G09B21/00;;G10K11/178;;H04R3/00;;H04R25/00;;H04S7/00,,0,0,,,,ACTIVE
155,EP,A1,EP 3675130 A1,169-779-766-380-272,2020-07-01,2020,EP 19219569 A,2019-12-23,US 201816233670 A,2018-12-27,SYSTEMS AND METHODS TO DETERMINE DISEASE PROGRESSION FROM ARTIFICIAL INTELLIGENCE DETECTION OUTPUT,"Apparatus, systems, and methods to improve automated identification, monitoring, processing, and control of a condition impacting a patient using image data and artificial intelligence classification are disclosed. An example image processing apparatus includes an artificial intelligence classifier to: process first image data for a patient from a first time to determine a first classification result indicating a first severity of a condition for the patient; and process second image data for the patient from a second time to determine a second classification result indicating a second severity of the condition for the patient. The example image processing apparatus includes a comparator to compare the first classification result and the second classification result to determine a change and a progression of the condition associated with the change. The example image processing apparatus includes an output generator to trigger an action when the progression corresponds to a worsening of the condition.",GEN ELECTRIC,NYE KATELYN;;RAO GIREESHA;;AVINASH GOPAL;;AUSTIN CHRISTOPHER,,https://lens.org/169-779-766-380-272,Patent Application,yes,1,1,7,7,0,G06F18/241;;G06F18/213;;G06N3/045;;G06T7/0012;;G06T2207/20081;;G06T2207/20084;;G06T2207/30061;;G06V2201/03;;G16H30/40;;G16H50/20;;G16H30/40;;G06T7/0016;;G06T7/11;;G16H50/20,G16H30/40;;G16H50/20,,0,0,,,,PENDING
156,EP,A2,EP 3670109 A2,140-299-999-003-800,2020-06-24,2020,EP 19211831 A,2019-11-27,KR 20180164091 A,2018-12-18,METHOD AND APPARATUS FOR CONTROLLING BEHAVIOR OF SERVICE ROBOT,"A method and apparatus for controlling an operation of a service robot is disclosed. The method includes measuring, by processing circuitry, an evaluation index of the service robot based on sensor data in a service mode; determining, by the processing circuitry, an operation mode of the service robot from a set of at least two operation modes based on the measured evaluation index; selecting, by the processing circuitry, a behavior to be applied to the operation of the service robot from a set of at least two behaviors based on the operation mode; and controlling, by the processing circuitry, the operation of the service robot based on the behavior.",SAMSUNG ELECTRONICS CO LTD,HA TAE SIN;;KIM KYUNG-ROCK;;JANG JUN-WON;;CHO JOON-KEE,,https://lens.org/140-299-999-003-800,Patent Application,yes,0,0,7,7,0,B25J9/16;;B25J9/1602;;B25J9/1679;;B25J9/1679;;B25J9/1602;;B25J9/163;;B25J11/008;;G05B2219/39254;;G05B2219/45084;;B25J9/1664;;B25J9/1602;;B25J9/163;;B25J19/02;;B25J11/001;;B25J9/1669,B25J9/16,,0,0,,,,ACTIVE
157,EP,A1,EP 3667609 A1,050-678-619-835-750,2020-06-17,2020,EP 19204868 A,2019-10-23,KR 20180159117 A,2018-12-11,METHOD AND APPARATUS FOR RECONSTRUCTING MEDICAL IMAGE,"Provided is a method and apparatus for reconstructing a medical image. The apparatus for reconstructing a medical image generates at least one base image by reducing a dimensionality of a three-dimensional (3D) medical image, generates at least one segmented image by reducing a dimensionality of a 3D image of a region of a tissue segmented from the 3D medical image or a 3D image of a region excluding the tissue from the 3D medical image, and trains, by using training data including the at least one base image and the at least one segmented image, an artificial intelligence (AI) model that separates at least one tissue from a medical image showing a plurality of tissues overlapping one another on the same plane.",MEDICALIP CO LTD,PARK SANG JOON;;LEE DOO HEE;;YOON SOON HO,,https://lens.org/050-678-619-835-750,Patent Application,yes,4,0,6,6,0,G16H30/20;;G06N3/045;;G06T3/067;;G06T7/10;;G06T2207/10081;;G06T2207/10088;;G06T2207/10116;;G06T5/50;;G06F18/2414;;G06T5/60;;G06T7/11;;G06T2207/10081;;G06T2207/10116;;G06T2207/20081;;G06T2207/20084;;G06T2207/30064;;G06V10/82;;A61B5/0035;;A61B5/055;;A61B6/032;;G16H30/40;;G06T5/50;;G06T7/0012;;G06T7/11;;G06T11/003;;G06T2207/10081;;G06T2207/10088;;G06T2207/10124;;G06T2207/20081;;G06T2207/20084;;G06T2207/30096;;G06V10/82,G06T5/50;;G06K9/62;;G06T7/11,,4,1,018-306-659-395-545,10.1007/978-3-030-00934-2_67,"OPHIR GOZES ET AL: ""Lung Structures Enhancement in Chest Radiographs via CT based FCNN Training"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 14 October 2018 (2018-10-14), XP081065454, DOI: 10.1007/978-3-030-00946-5_16;;ZHANG YUE ET AL: ""Task Driven Generative Modeling for Unsupervised Domain Adaptation: Application to X-ray Image Segmentation"", 26 September 2018, ROBOCUP 2008: ROBOCUP 2008: ROBOT SOCCER WORLD CUP XII; [LECTURE NOTES IN COMPUTER SCIENCE; LECT.NOTES COMPUTER], SPRINGER INTERNATIONAL PUBLISHING, CHAM, PAGE(S) 599 - 607, ISBN: 978-3-319-10403-4, XP047495980;;SHADI ALBARQOUNI ET AL: ""X-ray In-Depth Decomposition: Revealing The Latent Structures"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 19 December 2016 (2016-12-19), XP081362996, DOI: 10.1007/978-3-319-66179-7_51;;MATHIAS UNBERATH ET AL: ""DeepDRR -- A Catalyst for Machine Learning in Fluoroscopy-guided Procedures"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 23 March 2018 (2018-03-23), XP080862136",DISCONTINUED
158,EP,A1,EP 3649858 A1,001-487-121-665-740,2020-05-13,2020,EP 18204757 A,2018-11-06,EP 18204757 A,2018-11-06,AGROCHEMICAL FORMULATIONS CONTAINING A POLYMERIC CRYSTAL GROWTH INHIBITOR,"The disclosure provides for agrochemical compositions comprising a succinate dehydrogenase inhibitor and a polymeric crystal growth inhibitor. The disclosure further provides for methods of reducing crystal growth in agriculturally-active compounds in an agrochemical composition. In yet a further aspect, the disclosure provides for methods of utilizing an agrochemical composition comprising a succinate inhibitor and a polymeric crystal growth inhibitor to control pests in a plant or crop.",BAYER AG;;BAYER CROPSCIENCE LP,The designation of the inventor has not yet been filed,,https://lens.org/001-487-121-665-740,Patent Application,yes,6,0,9,12,0,A01N25/04;;A01N25/30;;A01N25/04;;A01N43/40;;A01N43/56;;A01N43/40;;A01N25/30;;A01N43/56;;A01N63/22;;A01N63/23,A01N25/04,,8,1,151-383-602-353-767,10.1016/0022-3697(61)90054-3,"LIFSHITZ, I.M.; SLYOZOV, V.V.: ""The Kinetics of Precipitation from Supersaturated Solid Solutions"", JOURNAL OF PHYSICS AND CHEMISTRY OF SOLIDS, vol. 19, no. 1-2, 1961, pages 35 - 50, XP024493541, DOI: doi:10.1016/0022-3697(61)90054-3;;BALDAN, A.: ""Review Progress in Ostwald ripening theories and their applications to nickel-base superalloys Part I: Ostwald ripening theories"", JOURNAL OF MATERIALS SCIENCE, vol. 37, no. 11, 2002, pages 2171 - 2202, XP019209547, DOI: doi:10.1023/A:1015388912729;;MCCUTCHEON'S: ""Emulsifiers & Detergents, McCutcheon's Directories"", vol. 1, 2008;;""Bergey's Manual of Systematic Bacteriology"", 1986;;CHEMICAL ABSTRACTS, Columbus, Ohio, US; abstract no. 382608-10-8;;CHEMICAL ABSTRACTS, Columbus, Ohio, US; abstract no. 272451-65-7;;CHEMICAL ABSTRACTS, Columbus, Ohio, US; abstract no. 185982-80-3;;CHEMICAL ABSTRACTS, Columbus, Ohio, US; abstract no. 185984-60-5",DISCONTINUED
159,EP,A1,EP 3650089 A1,126-281-260-809-707,2020-05-13,2020,EP 19202507 A,2019-10-10,GB 201818293 A,2018-11-09,DATA PROCESSING SYSTEM AND METHOD,"A data processing system comprises an information input unit operable to receive information relating to computer gameplay of the computer game, an error characterising unit operable to identify indicators of an error in the computer game based upon the received information, a playtest control unit operable to control one or more playtest bots in the computer game to generate playtest data, the playtest data comprising information relating to the identified indicators of an error, an error reporting unit operable to identify errors in dependence upon the playtest data.",SONY INTERACTIVE ENTERTAINMENT INC,CAPPELLO FABIO;;BEDWELL GREGORY JAMES;;CONRY BERNARD,,https://lens.org/126-281-260-809-707,Patent Application,yes,2,1,6,6,0,A63F13/60;;A63F13/67;;A63F13/497;;G06F11/3684;;G06F11/3684;;A63F13/77;;G06N20/00;;G06F11/302;;G06F11/3438;;G06F11/3495;;G06F11/3648;;G06F11/3664;;G06F11/3688;;G06N3/08;;G06N3/045,A63F13/60;;A63F13/497;;A63F13/67;;G06F11/36,,0,0,,,,PENDING
160,EP,A1,EP 3647936 A1,132-729-094-811-624,2020-05-06,2020,EP 19206720 A,2019-11-01,KR 20180132717 A;;KR 20190129837 A,2018-11-01,ELECTRONIC APPARATUS AND CONTROL METHOD THEREOF,"An electronic apparatus and a control method thereof are provided. A method of controlling an electronic apparatus according to an embodiment of the disclosure includes: receiving input of a first utterance, identifying a first task for the first utterance based on the first utterance, providing a response to the first task based on a predetermined response pattern, receiving input of a second utterance, identifying a second task for the second utterance based on the second utterance, determining the degree of association between the first task and the second task, and setting a response pattern for the first task based on the second task based on the determined degree of association satisfying a predetermined condition. The control method of an electronic apparatus may use an artificial intelligence model trained according to at least one of machine learning, a neural network, or a deep learning algorithm.",SAMSUNG ELECTRONICS CO LTD,LEE YEONHO;;LEE KYENGHUN;;JANG SAEBOM;;JEON SILAS,,https://lens.org/132-729-094-811-624,Patent Application,yes,3,1,5,9,0,G06F3/167;;G10L17/00;;G06N5/022;;G06N5/041;;G06N3/088;;G06N5/027;;G06N20/00;;G06N3/006;;G06N3/047;;G06N7/01;;G06N3/044;;G06N3/045;;G10L15/22;;G10L15/30;;G10L2015/227,G06F3/16;;G06N5/00;;G10L15/22,,0,0,,,,ACTIVE
161,EP,A1,EP 3627400 A1,012-150-026-622-529,2020-03-25,2020,EP 19197802 A,2019-09-17,US 201862734149 P,2018-09-20,CONTINUOUS LEARNING NEURAL NETWORK SYSTEM USING ROLLING WINDOW,"A disclosed method an analysis computer determining a rolling window associated with interaction data for interactions that occur over time. The analysis computer can retrieve interaction data for interactions occurring in the rolling window. The analysis computer can then generate pseudo interaction data based upon historical interaction data. The analysis computer can optionally embed the interaction data for the interactions occurring within the rolling window and the pseudo interaction data to form interaction data matrices. The analysis computer can then form a neural network model using the interaction data matrices, which is derived from the interaction data in the rolling window and the pseudo interaction data.",VISA INT SERVICE ASS,HARRIS THEODORE D;;KOROLEVSKAYA TATIANA;;LI YUE,,https://lens.org/012-150-026-622-529,Patent Application,yes,3,0,6,6,0,G06N3/044;;G06N3/084;;G06N20/10;;G06N3/084;;G06N3/045;;G06N20/20;;G06Q20/4016;;H04L63/1425;;H04L63/1441;;H04L63/1466;;H04L2463/102;;G06N3/08;;G06N3/04;;H04L63/1433,G06N3/04;;G06N3/08;;G06N20/20;;G06Q20/40;;H04L29/06,,7,5,046-590-838-651-248;;084-013-001-875-491;;069-552-634-797-138;;052-785-017-830-73X;;109-503-174-896-853,10.1016/j.jmsy.2017.08.003;;10.1016/j.asoc.2007.11.003;;10.1016/j.physrep.2009.11.002;;10.1145/3290353;;10.1145/1322432.1322433,"SAKTI SAURAV ET AL: ""Online anomaly detection with concept drift adaptation using recurrent neural networks"", DATA SCIENCE AND MANAGEMENT OF DATA, ACM, 2 PENN PLAZA, SUITE 701NEW YORKNY10121-0701USA, 11 January 2018 (2018-01-11), pages 78 - 87, XP058386105, ISBN: 978-1-4503-6341-9, DOI: 10.1145/3152494.3152501;;HAMMAMI ZEINEB ET AL: ""On-line self-adaptive framework for tailoring a neural-agent learning model addressing dynamic real-time scheduling problems"", JOURNAL OF MANUFACTURING SYSTEMS, SOCIETY OF MANUFACTURING ENGINEERS, DEARBORN, MI, US, vol. 45, 9 October 2017 (2017-10-09), pages 97 - 108, XP085301308, ISSN: 0278-6125, DOI: 10.1016/J.JMSY.2017.08.003;;DI YANG ET AL: ""Neighbor-based pattern detection for windows over streaming data"", EXTENDING DATABASE TECHNOLOGY, ACM, 2 PENN PLAZA, SUITE 701 NEW YORK NY 10121-0701 USA, 24 March 2009 (2009-03-24), pages 529 - 540, XP058352940, ISBN: 978-1-60558-422-5, DOI: 10.1145/1516360.1516422;;COHEN L ET AL: ""Info-fuzzy algorithms for mining dynamic data streams"", APPLIED SOFT COMPUTING, ELSEVIER, AMSTERDAM, NL, vol. 8, no. 4, 1 September 2008 (2008-09-01), pages 1283 - 1294, XP024520219, ISSN: 1568-4946, [retrieved on 20080326], DOI: 10.1016/J.ASOC.2007.11.003;;FORTUNATO, SANTO: ""Community detection in graphs"", PHYSICS REPORTS, vol. 486.3-5, 2010, pages 75 - 174;;ALON, URI ET AL.: ""code2vec: Learning distributed representations of code"", PROCEEDINGS OF THE ACM ON PROGRAMMING LANGUAGES 3.POPL, 2019, pages 40;;ANGLES, RENZOCLAUDIO GUTIERREZ: ""Survey of graph database models"", ACM COMPUTING SURVEYS (CSUR, vol. 40.1, 2008, pages 1",PENDING
162,EP,A1,EP 3582119 A1,189-486-404-876-592,2019-12-18,2019,EP 19179183 A,2019-06-07,US 201816008367 A,2018-06-14,SPOKEN LANGUAGE UNDERSTANDING SYSTEM AND METHOD USING RECURRENT NEURAL NETWORKS,"A system and method for spoken language understanding using recurrent neural networks (""RNNs"") is disclosed. The system and method jointly performs the following three functions when processing the word sequence of a user utterance: (1) classify a user's speech act into a dialogue act category, (2) identify a user's intent, and (3) extract semantic constituents from the word sequence. The system and method includes using a bidirectional RNN to convert a word sequence into a hidden state representation. By providing two different orderings of the word sequence, the bidirectional nature of the RNN improves the accuracy of performing the above-mentioned three functions. The system and method includes performing the three functions jointly. The system and method uses attention, which improves the efficiency and accuracy of the spoken language understanding system by focusing on certain parts of a word sequence. The three functions can be jointly trained, which increases efficiency.",ACCENTURE GLOBAL SOLUTIONS LTD,MADHUKAR WABGAONKAR HARSHAWARDHAN;;RAVILLA TIRUPAL RAO;;PATIL SUMITRAJ GANAPAT;;DEBNATH POULAMI;;G M SUSHRAVYA;;RAMNANI ROSHNI RAMESH;;SENGUPTA SHUBHASHIS;;MISHRA GURUDATTA;;MAHATO MOUSHUMI;;FIRDAUS MAUAJAMA,,https://lens.org/189-486-404-876-592,Patent Application,yes,0,2,3,3,0,G10L15/1822;;G06N3/006;;G06N3/084;;G06F40/216;;G06F40/35;;G06F40/30;;G06N3/048;;G06N3/044;;G06N3/045;;G06N3/08;;G10L15/063;;G10L15/16;;G10L15/1815;;G10L15/22,G06F17/27;;G06N3/04;;G10L15/18,,3,2,070-814-405-760-094;;052-722-388-090-066,10.21437/interspeech.2016-1352;;10.1007/978-3-319-73618-1_1,"BING LIU ET AL: ""Attention-Based Recurrent Neural Network Models for Joint Intent Detection and Slot Filling"", ARXIV.ORG, CORNELL UNIVERSITY LIBRARY, 201 OLIN LIBRARY CORNELL UNIVERSITY ITHACA, NY 14853, 6 September 2016 (2016-09-06), XP080724506, DOI: 10.21437/INTERSPEECH.2016-1352;;HUANG X., JIANG J., ZHAO D., FENG Y., HONG Y. (EDS.): ""Natural Language Processing and Chinese Computing. NLPCC 2017. Lecture Notes in Computer Science"", vol. 10619, 5 January 2018, SPRINGER, CHAM, Cham, China, ISBN: 978-3-319-73617-4, ISSN: 0302-9743, article LIYUN WEN ET AL: ""Jointly Modeling Intent Identification and Slot Filling with Contextual and Hierarchical Information"", pages: 3 - 15, XP055637909, DOI: 10.1007/978-3-319-73618-1_1;;XIAODONG ZHANG ET AL: ""A Joint Model of Intent Determination and Slot Filling for Spoken Language Understanding"", PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-16), 25 July 2016 (2016-07-25), New York, USA, pages 2993 - 2999, XP055637799, Retrieved from the Internet <URL:https://pdfs.semanticscholar.org/1f9e/2d6df1eaaf04aebf428d9fa9a9ffc89e373c.pdf> [retrieved on 20191031]",PENDING
163,EP,B1,EP 3318129 B1,168-073-317-726-900,2019-11-06,2019,EP 17201570 A,2013-12-03,EP 12195206 A;;EP 13798700 A;;EP 2013075351 W,2012-12-03,METHOD FOR PEST CONTROL BY APPLYING A COMBINATION OF PAECILOMYCES LILACINUS AND FLUOPYRAM,,BAYER CROPSCIENCE AG,WACHENDORFF-NEUMANN ULRIKE;;DAHMEN PETER;;SAWADA HARUKO,,https://lens.org/168-073-317-726-900,Granted Patent,yes,3,0,14,14,0,A01N63/30;;A01N63/30;;A01N43/40,A01N43/40;;A01N63/30;;A01P3/00;;A01P5/00,,0,0,,,,ACTIVE
164,EP,A1,EP 3557503 A1,100-340-130-590-253,2019-10-23,2019,EP 18201826 A,2018-10-22,US 201862660876 P;;US 201815967290 A;;US 2018/0042906 W,2018-04-20,GENERATING PERSONALIZED CONTENT SUMMARIES FOR USERS,"In one embodiment, a method includes receiving a user request for a summarization of a particular type of content objects from a client system associated with a first user, determining one or more modalities associated with the user request, selecting a plurality of content objects of the particular type based on a user profile of the first user, wherein the user profile comprises one or more confidence scores associated with one or more subjects associated with the first user, respectively, and wherein the plurality of content objects are selected based on the one or more confidence scores, generating a summary of each content object based on the user profile and the determined modalities, and sending, to the client system in response to the user request, instructions for presenting the summaries of the plurality of content objects, wherein the summaries are presented via one or more of the determined modalities.",FACEBOOK INC,PENG FUCHUN;;SHA FEI;;HAN KUN;;YANG WENHAI;;KUMAR ANUJ;;HANSON MICHAEL ROBERT;;DUMOULIN BENOIT F,,https://lens.org/100-340-130-590-253,Patent Application,yes,13,3,1,123,0,G06Q10/00,G06Q10/00,,0,0,,,,DISCONTINUED
165,EP,A1,EP 3552949 A1,084-070-310-887-542,2019-10-16,2019,EP 18783355 A,2018-02-19,BR 2018050036 W,2018-02-19,AEROSTAT REINFORCEMENT SYSTEM AND METHOD,"A fail-safe aerostat system is discussed, for structural support and network interconnection, applicable to many systems based on lighter-than-air lift. The invention describes a system with reinforced structure and optimized connection and an integration structure (reinforcement and integration structure (2)), reinforcing a hydrogen cell or cells with a fail-safe design. The theorized structure is strong enough to withstand explosive forces, avoiding propagation of shock wave damage and fire, and a hydrogen cell or cells (1) automatically self-controlled, operating independently to obtain lift strength and multiparameter control.",CEBALLOS MELO ANDRE AUGUSTO,CEBALLOS MELO ANDRÉ AUGUSTO,,https://lens.org/084-070-310-887-542,Patent Application,yes,0,0,16,16,0,B64B1/58;;Y02E60/36;;B64B1/58;;B64B1/00;;B64B1/60;;B64B1/58;;C01B3/08;;C25B1/04;;Y02E60/36;;B64B1/60,B64B1/58;;B64B1/00;;B64B1/60,,0,0,,,,ACTIVE
166,EP,B1,EP 2854532 B1,051-199-892-894-661,2019-08-07,2019,EP 13726744 A,2013-05-29,EP 12169936 A;;EP 12197135 A;;EP 2013061033 W;;EP 13726744 A,2012-05-30,COMPOSITIONS COMPRISING A BIOLOGICAL CONTROL AGENT AND AN INSECTICIDE,,BAYER CROPSCIENCE AG,HELLWEGE ELKE;;ANDERSCH WOLFRAM;;SPRINGER BERND;;STENZEL KLAUS,,https://lens.org/051-199-892-894-661,Granted Patent,yes,5,0,28,180,0,A01N63/00;;A01C1/08;;A01N43/08;;A01N47/06;;A01N25/00;;A01N63/22;;A01N63/28;;A01N63/23;;A01N25/00;;A01N43/08;;A01N43/12;;A01N47/06;;C12N1/20;;Y10S435/832;;A01N25/00;;A01N43/12;;A01N47/06;;A01N63/22;;A01N63/28,A01N25/00;;A01N43/12;;A01N47/06;;A01N63/22;;A01N63/28,,0,0,,,,ACTIVE
167,EP,A1,EP 3483620 A1,057-524-909-154-008,2019-05-15,2019,EP 17210164 A,2017-12-22,EP 17201373 A,2017-11-13,AUTOMATED NONINVASIVE DETERMINING THE FERTILITY OF A BIRD'S EGG,"Shown herein is a method of automated noninvasive determining the fertility of a bird's egg (14), comprising the following steps: conveying a plurality of bird eggs (14) sequentially or in parallel into an NMR apparatus (18), subjecting the bird eggs (14) to an NMR measurement, such as to generate a 3-D NMR image of at least a part of each of said eggs (14), said 3-D NMR image having a spatial resolution in at least one dimension of 1.0 mm or less, preferably of 0.50 mm or less, wherein said part of the egg (14) includes the germinal disc of the respective egg (14), determining a prediction of the fertility according to at least one of the following two procedures: (i) deriving at least one feature from each of said 3-D NMR images, and employing said at least one feature in a feature-based classifier for determining a prediction of the fertility, and (ii) using a deep learning algorithm, and in particular a deep learning algorithm based on convolutional neural networks, generative adversarial networks, recurrent neural networks or long short-term memory networks.",UNIV MUENCHEN TECH,GOMEZ PEDRO A;;MOLINA-ROMERO MIGUEL;;HAASE AXEL;;SCHUSSER BENJAMIN;;AIGNER MAXIMILLIAN;;LAPARIDOU MARIA,,https://lens.org/057-524-909-154-008,Patent Application,yes,10,1,38,38,0,G01N24/085;;G01R33/3415;;G01R33/4835;;G01R33/5611;;G01N33/08;;G01N33/08;;G01R33/483;;G01N24/085;;G01R33/4835;;A01K43/04;;B07C5/344;;G01N24/085;;G01N33/08;;G01R33/3415;;G01R33/5608;;G01R33/561;;G01R33/307;;G01R33/5611,G01R33/483;;G01N33/08;;G01N33/483,,34,24,015-150-806-920-227;;168-081-247-605-520;;093-536-335-207-599;;071-666-521-667-895;;034-377-320-403-84X;;162-407-472-929-002;;045-779-156-795-693;;007-729-398-347-160;;035-748-607-984-916;;186-498-104-767-924;;039-341-740-425-356;;129-244-763-388-47X;;033-728-135-090-728;;066-941-266-627-193;;082-209-393-192-885;;006-033-973-063-884;;026-755-922-345-486;;000-344-890-213-242;;013-662-727-978-128;;013-110-619-366-76X;;016-491-286-869-270;;039-324-478-997-10X;;062-273-537-239-533;;121-707-574-802-675,10.1093/ps/81.4.529;;11989753;;10.1017/cbo9780511801389;;10.1002/0471725293;;10.1007/0-387-25465-x_9;;10.1006/jcss.1997.1504;;10.1214/aos/1016120463;;10.1109/iccv.2005.194;;10.1002/mrm.1910150305;;2233218;;10.1016/j.jmr.2006.06.027;;16860581;;2663289;;1925560;;10.1126/science.1925560;;10.1088/0022-3719/9/15/004;;10.1002/mrm.10666;;14705048;;10.1016/0022-2364(86)90433-6;;10.1002/(sici)1522-2594(199911)42:5<952::aid-mrm16>3.3.co;2-j;;10.1002/(sici)1522-2594(199911)42:5<952::aid-mrm16>3.0.co;2-s;;10542355;;pmc4142121;;10.1002/mrm.24751;;23649942;;10.1109/tsp.2002.807005;;12111967;;10.1002/mrm.10171;;10.1371/journal.pone.0015710;;21187930;;pmc3004955;;17969013;;10.1002/mrm.21391;;10.1038/nature11971;;pmc3602925;;23486058;;10.1103/physrev.112.1693;;10.1016/j.neuroimage.2017.02.089;;28263925;;10.1145/3065386,"S. KLEIN ET AL: ""Localization of the fertilized germinal disc in the chicken egg before incubation"", POULTRY SCIENCE, vol. 81, no. 4, 1 April 2002 (2002-04-01), Oxford, pages 529 - 536, XP055461661, ISSN: 0032-5791, DOI: 10.1093/ps/81.4.529;;A. DAVENEL ET AL: ""Attempts for early gender determination of chick embryos in ovo using Magnetic Resonance Imaging"", 1 June 2015 (2015-06-01), XP055462402, Retrieved from the Internet <URL:http://www.wpsa.com/index.php/publications/wpsa-proceedings/2015/xxii-european-symposium-on-the-quality-of-poultry-meat-and-the-xvi-european-symposium-on-the-quality-of-eggs-and-egg-products/2196-attempts-for-early-gender-determination-of-chick-embryos-in-ovo-using-magnetic-resonance-imaging/file> [retrieved on 20180323];;CRISTIANINI, N.; SHAWE-TAYLOR, J.: ""An Introduction to Support Vector Machines and other kernel based learning methods"", AI MAGAZINE, vol. 22, 2000, pages 190;;TIPPING, M. E.: ""Sparse Bayesian Learning and the Relevance Vector Machine"", J. MACH. LEARN. RES., vol. 1, 2001, pages 1 - 244;;DEKEL, O.; SHALEV-SHWARTZ, S.; SINGER, Y.: ""The forgetron: α kernel-based perceptron on a budget"", SIAM J. COMPUT., vol. 37/5, 2008, pages 1342 - 1372, XP055218413, DOI: doi:10.1137/060666998;;MIKA, S.; RATSCH, G.; WESTON, J.; SCHBLKOPF, B.; MUTTER, K.-R.: ""Fisher discriminant analysis with kernels"", IEEE, 1999, pages 41 - 48, XP010348467, DOI: doi:10.1109/NNSP.1999.788121;;MCLACHLAN, G. J.: ""Discriminant analysis and statistical pattern recognition"", WILEY SERIES IN PROBABILITY AND STATISTICS, 2004;;ROKACH, L.; MAIMON, O.: ""Data mining with decision trees: Theory and applications"", 2008, WORLD SCIENTIFIC PUB CO INC;;BREIMAN, L., RANDOM FORESTS. MACH. LEARN., vol. 45, 2001, pages 5 - 32;;RISH, I.: ""An empirical study of the naive Bayes classifier"", EMPIR. METHODS ARTIF. INTELL. WORK. IJCAI 22230, 2001, pages 41 - 46;;FREUND, Y.; SCHAPIRE, R. E.: ""A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting"", J. COMPUT. SYST. SCI., vol. 55, 1997, pages 119 - 139;;JEROME FRIEDMAN; TREVOR HASTIE; ROBERT TIBSHIRANI: ""Additive logistic regression: a statistical view of boosting"", ANNALS OF STATISTICS, vol. 28, no. 2, 2000, pages 337 - 407, XP008149847, DOI: doi:10.1214/aos/1016218223;;TU, Z.: ""Probabilistic boosting-tree: Learning discriminative models for classification, recognition, and clustering"", PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION II, 2005, pages 1589 - 1596, XP010857003, DOI: doi:10.1109/ICCV.2005.194;;STEPISNIK, J.; ERZEN, V.; KOS, M.: ""NMR imaging in the earth's magnetic field"", MAGN. RESON. MED., vol. 15, 1990, pages 386 - 391, XP000170518;;ROBINSON, J. N. ET AL.: ""Two-dimensional NMR spectroscopy in Earth's magnetic field"", J. MAGN. RESON., vol. 182, 2006, pages 343 - 347, XP024919449, DOI: doi:10.1016/j.jmr.2006.06.027;;LAUTERBUR, P. C.: ""Image formation by induced local interactions. Examples employing nuclear magnetic resonance"", NATURE, vol. 242, 1973, pages 190 - 191, XP000615916, DOI: doi:10.1038/242190a0;;STEHLING, M.; TURNER, R.; MANSFIELD, P.: ""Echo-planar imaging: magnetic resonance imaging in a fraction of a second"", SCIENCE, vol. 254, no. 80, 1991, pages 43 - 50;;MANSFIELD, P.; MAUDSLEY, A. A.: ""Planar spin imaging by NMR"", J. PHYS. C SOLID STATE PHYS., vol. 9, 1976, pages L409 - L412;;HARGREAVES, B. A.; NISHIMURA, D. G.; CONOLLY, S. M.: ""Time-optimal multidimensional gradient waveform design for rapid imaging"", MAGN. RESON. MED., vol. 51, 2004, pages 81 - 92, XP007914338, DOI: doi:10.1002/mrm.10666;;HAASE, A.; FRAHM, J.; MATTHAEI, D.; HANICKE, W.; MERBOLDT, K. D.: ""FLASH imaging. Rapid NMR imaging using low flip-angle pulses"", J. MAGN. RESON., vol. 67, 1986, pages 258 - 266, XP023959986, DOI: doi:10.1016/0022-2364(86)90433-6;;GÓMEZ, P. A. ET AL.: ""Accelerated parameter mapping with compressed sensing: an alternative to MR Fingerprinting"", PROC INTL SOC MAG RESON MED, 2017;;PRUESSMANN, K. P.; WEIGER, M.; SCHEIDEGGER, M. B.; BOESIGER, P.: ""SENSE: sensitivity encoding for fast MRI"", MAGN. RESON. MED., vol. 42, 1999, pages 952 - 962, XP000866655, DOI: doi:10.1002/(SICI)1522-2594(199911)42:5<952::AID-MRM16>3.0.CO;2-S;;UECKER, M. ET AL.: ""ESPIRiT - An eigenvalue approach to autocalibrating parallel MRI: Where SENSE meets GRAPPA"", MAGN. RESON. MED., vol. 71, 2014, pages 990 - 1001, XP055357609, DOI: doi:10.1002/mrm.24751;;FESSLER, J. A.; SUTTON, B.: ""Nonuniform Fast Fourier Transforms Using Min-Max Interpolation"", IEEE TRANS. SIGNAL PROCESS., vol. 51, 2003, pages 560 - 574, XP055089679, DOI: doi:10.1109/TSP.2002.807005;;GRISWOLD, M. A. ET AL.: ""Generalized auto calibrating partially parallel acquisitions (GRAPPA)"", MAGN. RES. MED, vol. 47, 2002, pages 1202 - 1210;;FEINBERG, D. A. ET AL.: ""Multiplexed echo planar imaging for sub-second whole brain fmri and fast diffusion imaging"", PLOS ONE, vol. 5, 2010;;LUSTIG, M.; DONOHO, D.; PAULY, J. M.: ""Sparse MRI: The application of compressed sensing for rapid MR imaging"", MAGN. RESON. MED., vol. 58, 2007, pages 1182 - 1195, XP007907974, DOI: doi:10.1002/mrm.21391;;GOMEZ, P. A. ET AL.: ""Accelerated parameter mapping with compressed sensing: an alternative to MR Fingerprinting"", PROC INTL SOC MAG RESON MED, 2017;;MA, D. ET AL.: ""Magnetic resonance fingerprinting"", NATURE, vol. 495, 2013, pages 187 - 192;;CARR, H. Y.: ""Steady-state free precession in nuclear magnetic resonance"", PHYS. REV., vol. 112, 1958, pages 1693 - 1701;;ALEXANDER, D. C. ET AL.: ""Image quality transfer and applications in diffusion MRI"", NEUROIMAGE, vol. 152, 2017, pages 283 - 298, XP085020677, DOI: doi:10.1016/j.neuroimage.2017.02.089;;TANNO, R. ET AL.: ""Bayesian Image Quality Transfer with CNNs: Exploring Uncertainty"", DMRI SUPER-RESOLUTION, 2017, Retrieved from the Internet <URL:http://arxiv.org/abs/1705.00664>;;KRIZHEVSKY, A.; SUTSKEVER, L; HINTON, G. E.: ""ImageNet Classification with Deep Convolutional Neural Networks"", ADV. NEURAL INF. PROCESS. SYST., 2012, pages 1 - 9, Retrieved from the Internet <URL:http://dx.doi.org/10.1016/j.protcy.2014.09.007>;;GOODFELLOW, I. J. ET AL., GENERATIVE ADVERSARIAL NETWORKS, 2014, Retrieved from the Internet <URL:http://arxiv.org/abs/1406.2661>",DISCONTINUED
168,EP,A1,EP 3424322 A1,001-012-892-741-730,2019-01-09,2019,EP 18181442 A,2013-07-29,EP 12178637 A;;EP 13742230 A;;EP 2013065905 W,2012-07-31,COMPOSITIONS COMPRISING A PESTICIDAL TERPENE MIXTURE AND AN INSECTICIDE,"The present invention relates to a composition comprising a) a pesticidal terpene mixture comprising, as pesticidally active chemical compounds, ±-terpinene, p-cymene and limonene and b) at least one insecticide selected from the group consisting of Abamectin, Acephate, Acetamiprid, Acrinathrin, Afidopyropen, Alpha-Cypermethrin, Azadirachtin, Bacillus firmus, Beta-Cyfluthrin, Bifenthrin, Buprofezin, Clothianidin, Chlorantraniliprole, Chlorfenapyr, Chlorpyrifos, Carbofuran, Cyantraniliprole, Cyenopyrafen, Cyflumentofen, Cyfluthrin, Cypermethrin, Deltamethrin, Diafenthiuron, Dinotefuran, Emamectin-benzoate, Ethiprole, Fenpyroximate, Fipronil, Flometoquin, Flonicamid, Flubendiamide, Fluensulfone, Fluopyram, Flupyradifurone, Gamma-Cyhalothrin, Imidacloprid, Indoxacarb, Lambda-Cyhalothrin, Lufenuron, Metaflumizone, Methiocarb, Methoxyfenozide, Milbemectin, Profenofos, Pyflubumide, Pymetrozine, Pyrifluquinazone, Spinetoram, Spinosad, Spirodiclofen, Spiromesifen, Spirotetramate, Sulfoxaflor, Tebufenpyrad, Tefluthrin, Thiacloprid, Thiamethoxam, Thiodicarb, Triflumuron, 1-(3-chloropyridin-2-yl)-N-[4-cyano-2-methyl-6-(methylcarbamoyl)phenyl]-3-{[5-(trifluoromethyl)-1H-tetrazol-1-yl]methyl}-1H-pyrazole-5-carboxamide, 1-(3-chloropyridin-2-yl)-N-[4-cyano-2-methyl-6-(methylcarbamoyl)phenyl]-3-{[5-(trifluoromethyl)-2H-tetrazol-2-yl]methyl}-1H-pyrazole-5-carboxamide and 1-12-fluoro-4-methyl-5-[(2,2,2-trifluorethyl)sulfinyl]phenyl}-3-(trifluoromethyl)-1H-1,2,4-triazol-5-amine in a synergistically effective amount, and optionally a fungicide. Furthermore, the present invention relates to the use of this composition as well as a method for reducing overall damage of plants and plant parts.",BAYER CROPSCIENCE AG,HELLWEGE ELKE;;ANDERSCH WOLFRAM,,https://lens.org/001-012-892-741-730,Patent Application,yes,196,3,16,16,0,A01N27/00;;A01N27/00;;A01N43/12;;A01N43/22;;A01N43/40;;A01N43/56;;A01N43/653;;A01N43/90;;A01N47/06;;A01N47/22;;A01N47/24;;A01N51/00;;A01N27/00;;A01N41/10;;A01N43/12;;A01N43/40;;A01N43/56;;A01N43/653;;A01N43/78;;A01N43/90;;A01N45/02;;A01N47/06;;A01N47/22;;A01N51/00;;A01N53/00,A01N27/00;;A01N65/08;;A01P7/00,,12,3,056-357-183-925-763;;139-238-698-379-172;;065-669-388-721-050,10.1016/s0261-2194(97)00118-x;;10.2307/4041058;;10.1002/(sici)1096-9063(199710)51:2<131::aid-ps614>3.3.co;2-4,"""Enhancing Effect of Chenopodium Ambrosioides Essential Oil on the Selected Insecticides Penetration Through Cuticula of Plutella Xylostella Larvae"", CHINA PAPERS - PART B, 26 April 2010 (2010-04-26), XP055046481, Retrieved from the Internet <URL:http://mt.china-papers.com/1/?p=169406> [retrieved on 20121204];;""Development of 20% Chlorpyrifos Micro-emulsion with Chenopodium Ambrosioides Essential Oil as Auxiliary"", CHINA PAPERS - PART B, 1 May 2010 (2010-05-01), XP055046511, Retrieved from the Internet <URL:http://mt.china-papers.com/1/?p=166720> [retrieved on 20121204];;ERIC NATWICK ET AL: ""THRIPS MANAGEMENT IN LETTUCE"", IMPERIAL COUNTY AGRICULTURAL BRIEFS, 1 November 2009 (2009-11-01), pages 1 - 6, XP055046451, Retrieved from the Internet <URL:http://vric.ucdavis.edu/pdf/county newsletter_NR/ImperialAgBriefs_newsletter_2009_Nov.pdf> [retrieved on 20121204];;SILVIA RONDON: ""Thrips control in dry bulb onion"", 1 November 2009 (2009-11-01), Oregon State University, pages 1 - 38, XP055046459, Retrieved from the Internet <URL:http://www.pnva.org/files/files/ThripsControlinDryBulbOni.pdf> [retrieved on 20121204];;WILLIAM QUARLES: ""Botanical Pesticides from Chenopodium"", THE IPM PRACTITIONER, vol. XIV, no. 2, pages 11;;LORENZO SAGERO-NIEVES: ""Volatile Constituents from the Leaves of Chenopodium ambrosioides L."", J. ESSENT. OIL RES., vol. 7, March 1995 (1995-03-01), pages 221 - 223;;""The Pesticide Manual"", 2009, BRITISH CROP PROTECTION COUNCIL;;CHEMICAL ABSTRACTS, Columbus, Ohio, US; abstract no. 1204776-60-2;;COLBY, S.R.: ""Calculating Synergistic and antagonistic Responses of Herbicide Combinations"", WEEDS, vol. 15, 1967, pages 20 - 22, XP001112961;;""Pesticide Specifications"", vol. 173, 2004, FAO/WHO JOINT MEETING ON PESTICIDE SPECIFICATIONS, article ""Manual on development and use of FAO and WHO specifications for pesticides, FAO Plant Production and Protection Papers"";;BAUR ET AL., PESTICIDE SCIENCE, vol. 51, 1997, pages 131 - 152;;R. WEGLER: ""Chemie der Pflanzenschutz- und Schadlingsbekampfungsmittel"", vol. 2, 1970, SPRINGER VERLAG, pages: 401 - 412",DISCONTINUED
169,EP,B1,EP 2494496 B1,091-865-593-936-270,2018-11-14,2018,EP 10830466 A,2010-10-28,US 25581709 P;;US 26102809 P;;US 26463909 P;;US 26331809 P;;US 26696509 P;;US 28572609 P;;US 64038609 A;;US 2010/0054544 W,2009-10-28,"SENSOR-BASED MOBILE SEARCH, RELATED METHODS AND SYSTEMS",,DIGIMARC CORP,RHOADS GEOFFREY B;;RODRIGUEZ TONY F;;SHAW GILBERT B,,https://lens.org/091-865-593-936-270,Granted Patent,yes,7,2,23,134,0,H04W4/02;;G01C21/3629;;G06F3/011;;G06F3/016;;G06F18/24765;;G06Q30/02;;G06V10/765;;G06V10/96;;H04M2250/12;;H04M2250/52;;G01B11/14;;G01C21/3629;;G06F3/011;;G06F3/016;;G06Q30/02;;H04M2250/12;;H04M2250/52;;H04W4/02;;H04W4/02;;G01B11/14;;G01C21/3629;;G06F3/011;;G06F3/016;;G06F18/24765;;G06F2218/08;;G06Q30/02;;G06V10/765;;G06V10/96;;H04M2250/12;;H04M2250/52;;H04N23/00;;H04W4/029,G01C21/36;;H04W4/02;;G01B11/14;;G06F3/01;;G06F17/30;;G06K9/00;;G06K9/62;;G06Q30/02;;H04N5/225;;H04W4/029,,0,0,,,,ACTIVE
170,EP,B1,EP 2879493 B1,010-025-917-577-420,2018-09-19,2018,EP 13742230 A,2013-07-29,EP 12178637 A;;EP 2013065905 W;;EP 13742230 A,2012-07-31,PESTICIDAL COMPOSITIONS COMPRISING A TERPENE MIXTURE AND FLUPYRADIFURONE,,BAYER CROPSCIENCE AG,HELLWEGE ELKE;;ANDERSCH WOLFRAM,,https://lens.org/010-025-917-577-420,Granted Patent,yes,2,0,16,16,0,A01N27/00;;A01N27/00;;A01N43/12;;A01N43/22;;A01N43/40;;A01N43/56;;A01N43/653;;A01N43/90;;A01N47/06;;A01N47/22;;A01N47/24;;A01N51/00;;A01N27/00;;A01N41/10;;A01N43/12;;A01N43/40;;A01N43/56;;A01N43/653;;A01N43/78;;A01N43/90;;A01N45/02;;A01N47/06;;A01N47/22;;A01N51/00;;A01N53/00,A01N27/00;;A01N43/40;;A01P7/00,,4,0,,,"""Enhancing Effect of Chenopodium Ambrosioides Essential Oil on the Selected Insecticides Penetration Through Cuticula of Plutella Xylostella Larvae"", China Papers - Part B, 26 April 2010 (2010-04-26), XP055046481, Retrieved from the Internet: URL:http://mt.china-papers.com/1/?p=169406 [retrieved on 2012-12-04];;""Development of 20% Chlorpyrifos Micro-emulsion with Chenopodium Ambrosioides Essential Oil as Auxiliary"", China Papers - Part B, 1 May 2010 (2010-05-01), XP055046511, Retrieved from the Internet: URL:http://mt.china-papers.com/1/?p=166720 [retrieved on 2012-12-04];;Eric Natwick ET AL: ""THRIPS MANAGEMENT IN LETTUCE"", Imperial County Agricultural Briefs, 1 November 2009 (2009-11-01), pages 1-6, XP055046451, Retrieved from the Internet: URL:http://vric.ucdavis.edu/pdf/county newsletter_NR/ImperialAgBriefs_newsletter_ 2009_Nov.pdf [retrieved on 2012-12-04];;Silvia Rondon: ""Thrips control in dry bulb onion"", , 1 November 2009 (2009-11-01), pages 1-38, XP055046459, Oregon State University Retrieved from the Internet: URL:http://www.pnva.org/files/files/Thrips ControlinDryBulbOni.pdf [retrieved on 2012-12-04]",ACTIVE
171,EP,A2,EP 3363289 A2,084-204-554-332-106,2018-08-22,2018,EP 18160731 A,2013-05-29,EP 12169936 A;;EP 12197141 A;;EP 13725958 A;;EP 2013061023 W,2012-05-30,COMPOSITIONS COMPRISING A BIOLOGICAL CONTROL AGENT AND AN INSECTICIDE,"The present invention relates to a composition comprising at least one biological control agent selected from the group consisting of Bacillus subtilis AQ713 (NRRL Accession No. B-21661) and Bacillus subtilis AQ30002 (NRRL Accession No. B-50421), and Bacillus subtilis AQ 30004 (NRRL Accession No. B-50455) and/or a mutant of these strains having all the identifying characteristics of the respective strain, and/or a metabolite produced by the respective strain that exhibits activity against insects, mites, nematodes and/or phytopathogens and at least one insecticide selected from the group consisting of acetylcholinesterase (AChE) inhibitors, GABA-gated chloride channel antagonists, chloride channel activators and nicotinic acetylcholine receptor (nAChR) channel blockers in a synergistically effective amount. Furthermore, the present invention relates to the use of this composition as well as a method for reducing overall damage of plants and plant parts.",BAYER CROPSCIENCE AG,HELLWEGE ELKE;;ANDERSCH WOLFRAM;;STENZEL KLAUS;;SPRINGER BERND,,https://lens.org/084-204-554-332-106,Patent Application,yes,172,0,26,180,0,A01N63/00;;A01N43/56;;A01N43/90;;A01N47/24;;A01N57/16;;A01N63/22;;A01N63/28;;A01N63/23;;A01N43/56;;A01N43/90;;A01N47/22;;A01N47/24;;A01N57/16;;A01N63/28;;A01N63/22;;A01N43/90;;A01N47/02;;A01N47/22;;A01N47/24;;A01N63/28,A01N43/22;;A01N43/40;;A01N43/56;;A01N43/90;;A01N47/02;;A01N47/22;;A01N47/24;;A01N47/40;;A01N51/00;;A01N53/00;;A01N63/22;;A01N63/28;;A01P7/04,,5,3,056-357-183-925-763;;065-669-388-721-050;;139-238-698-379-172,10.1016/s0261-2194(97)00118-x;;10.1002/(sici)1096-9063(199710)51:2<131::aid-ps614>3.3.co;2-4;;10.2307/4041058,"""Current Protocols in Molecular Biology"", vol. 30, 1987;;""The Pesticide Manual"", 2006, BRITISH CROP PROTECTION COUNCIL;;BAUR ET AL., PESTICIDE SCIENCE, vol. 51, 1997, pages 131 - 152;;R. WEGLER: ""Chemie der Pflanzenschutz- und Schadlingsbekampftrngsmittel"", vol. 2, 1970, SPRINGER VERLAG, pages: 401 - 412;;COLBY, S.R.: ""Calculating Synergistic and antagonistic Responses of Herbicide Combinations"", WEEDS, vol. 15, 1967, pages 20 - 22, XP001112961",DISCONTINUED
172,EP,B1,EP 2854542 B1,187-308-916-179-163,2018-08-01,2018,EP 13725958 A,2013-05-29,EP 12169936 A;;EP 12197141 A;;EP 2013061023 W;;EP 13725958 A,2012-05-30,COMPOSITIONS COMPRISING A BIOLOGICAL CONTROL AGENT AND AN INSECTICIDE,,BAYER CROPSCIENCE AG,HELLWEGE ELKE;;ANDERSCH WOLFRAM;;STENZEL KLAUS;;SPRINGER BERND,,https://lens.org/187-308-916-179-163,Granted Patent,yes,4,0,26,180,0,A01N63/00;;A01N43/56;;A01N43/90;;A01N47/24;;A01N57/16;;A01N63/22;;A01N63/28;;A01N63/23;;A01N43/56;;A01N43/90;;A01N47/22;;A01N47/24;;A01N57/16;;A01N63/28;;A01N63/22;;A01N43/90;;A01N47/02;;A01N47/22;;A01N47/24;;A01N63/28,A01N43/90;;A01N47/02;;A01N47/22;;A01N47/24;;A01N63/22;;A01N63/28,,4,0,,,"ANNIE E.S. FOO, H.H. YAP: ""Interactive effects of Bacillus thuringiensis H-14 with Chlorpyrifos and Permethrin"", TROPICAL BIOMEDICINE, vol. 4, 1 January 1987 (1987-01-01), pages 47-50, XP009171556,;;V. A. VASSILIOU: ""Effectiveness of Insecticides in Controlling the First and Second Generations of the Lobesia botrana (Lepidoptera: Tortricidae) in Table Grapes"", JOURNAL OF ECONOMIC ENTOMOLOGY, vol. 104, no. 2, 1 April 2011 (2011-04-01) , pages 580-585, XP055073281, ISSN: 0022-0493, DOI: 10.1603/EC10343;;D.W. ATWOOD, S. Y. YOUNG III, T,J. KRING: ""Mortality of Tobacco Budworm Larvae"", J. ENTOMOL. SCI., vol. 33(2), 1 April 1998 (1998-04-01), pages 136-141, XP009171573,;;MORRIS O N: ""LONG TERM STUDY OF THE EFFECTIVENESS OF AERIAL APPLICATION OF BACILLUS THURINGIENSIS - ACEPHATE COMBINATIONS AGAIST THE SPRUCE BUDWORM, CHRORISTONEURA FUMIFERANA (LEPIDOPTERA: TORTRICIDAE)"", CANADIAN ENTOMOLOGIST, OTTAWA, CA, vol. 109, no. 9, 1 January 1977 (1977-01-01), pages 1239-1248, XP009171565, ISSN: 0008-347X",ACTIVE
173,EP,A1,EP 3318129 A1,065-267-462-057-142,2018-05-09,2018,EP 17201570 A,2013-12-03,EP 12195206 A;;EP 13798700 A;;EP 2013075351 W,2012-12-03,METHOD FOR PEST CONTROL BY APPLYING A COMBINATION OF PAECILOMYCES LILACINUS AND FLUOPYRAM,"The present invention relates to a composition comprising at least one biological control agent selected which is Paecilomyces lilacinus strain 251 (AGAL No. 89/030550) and at least one fungicide (I) selected from the group consisting of inhibitors of the respiratory chain at complex I, II and III in a synergistically effective amount. Furthermore, the present invention relates to a method conmprising applying said composition and the use of said composition.",BAYER CROPSCIENCE AG,WACHENDORFF-NEUMANN ULRIKE;;DAHMEN PETER;;SAWADA HARUKO,,https://lens.org/065-267-462-057-142,Patent Application,yes,129,0,14,14,0,A01N63/30;;A01N63/30;;A01N43/40,A01N43/40;;A01N63/30;;A01P3/00;;A01P5/00,,6,3,018-502-309-735-042;;118-084-146-725-427;;065-669-388-721-050,14568155;;10.1016/s0378-1097(03)00654-2;;10.1016/j.biocontrol.2005.12.006;;10.1002/(sici)1096-9063(199710)51:2<131::aid-ps614>3.3.co;2-4,"F. M. AUSUBEL ET AL.,: ""Current Protocols in Molecular Biology"", 1987, article ""Supplement 30, section 7. 7. 18, Table 7. 7. 1."";;A. KHAN ET AL., FEMS MICROBIOLOGY LETTERS, vol. 227, 2003, pages 107 - 111;;S. KIEWNICK, BIOLOGICAL CONTROL, vol. 38, 2006, pages 179 - 187;;FAO PLANT PRODUCTION AND PROTECTION PAPERS - 173, PREPARED BY THE FAO/WHO JOINT MEETING ON PESTICIDE SPECIFICATIONS, 2004;;BAUR ET AL., PESTICIDE SCIENCE, vol. 51, 1997, pages 131 - 152;;R. WEGLER: ""Chemie der Pflanzenschutz- und Schadlingsbekampfungsmittel"", vol. 2, 1970, SPRINGER VERLAG, pages: 401 - 412",ACTIVE
174,EP,B1,EP 2854534 B1,180-820-773-208-788,2018-04-11,2018,EP 13725674 A,2013-05-29,EP 12169936 A;;EP 12197132 A;;EP 2013061028 W;;EP 13725674 A,2012-05-30,COMPOSITIIONS COMPRISING A BIOLOGICAL CONTROL AGENT AND AN INSECTICIDE,,BAYER CROPSCIENCE AG,HELLWEGE ELKE;;ANDERSCH WOLFRAM;;STENZEL KLAUS;;SPRINGER BERND,,https://lens.org/180-820-773-208-788,Granted Patent,yes,4,0,26,180,0,A01N63/22;;A01N63/28;;Y02A50/30;;A01N63/23;;A01N43/22;;A01N43/40;;A01N45/00;;A01N47/40;;A01N51/00;;A01N63/28;;A01N63/22;;A01N43/22;;A01N43/50;;A01N43/88;;A01N45/02;;A01N47/40;;A01N47/44;;A01N51/00;;A01N63/28;;A01N65/00;;Y02A50/30,A01N43/50;;A01N43/22;;A01N43/88;;A01N45/02;;A01N47/40;;A01N47/44;;A01N51/00;;A01N63/22;;A01N63/28;;A01N65/00,,1,0,,,"SAMEEH A. MANSOUR ET AL: ""Mosquitocidal activity of two Bacillus bacterial endotoxins combined with plant oils and conventional insecticides"", INDUSTRIAL CROPS AND PRODUCTS, vol. 35, no. 1, 1 January 2012 (2012-01-01), pages 44-52, XP55072921, ISSN: 0926-6690, DOI: 10.1016/j.indcrop.2011.06.001",ACTIVE
175,EP,B1,EP 2879494 B1,037-340-047-681-530,2018-01-31,2018,EP 13745392 A,2013-08-01,EP 12179145 A;;EP 2013066178 W;;EP 13745392 A,2012-08-03,COMPOSITION COMPRISING A PESTICIDAL TERPENE MIXTURE AND A FUNGICIDE,,BAYER CROPSCIENCE AG,WACHENDORFF-NEUMANN ULRIKE;;DAHMEN PETER;;HELLWEGE ELKE,,https://lens.org/037-340-047-681-530,Granted Patent,yes,4,0,22,22,0,A01N27/00;;A01N65/00;;A23B7/154;;A23B9/26;;Y02A50/30;;A01N27/00;;A01N43/30;;A01N43/36;;A01N43/40;;A01N43/54;;A01N43/56;;A01N43/653;;A01N47/12;;A01N55/02;;A01N57/12;;A01N65/00;;A01N27/00;;A01N37/22;;A01N37/24;;A01N37/50;;A01N43/30;;A01N43/36;;A01N43/40;;A01N43/54;;A01N43/56;;A01N43/653;;A01N43/80;;A01N47/12;;A01N55/02;;A01N57/12;;A01N65/00;;A23B7/154;;A23B9/26;;Y02A50/30,A01N27/00;;A01N37/24;;A01N37/34;;A01N37/46;;A01N43/36;;A01N43/40;;A01N43/50;;A01N43/54;;A01N43/56;;A01N43/653;;A01N43/80;;A01N47/12;;A01N47/14;;A01N57/12;;A23B7/154,,2,0,,,"CHANDRA SHEKHAR PRASAD ET AL: ""In vitro and in vivo antifungal activity of essential oils of Cymbopogon martini and Chenopodium ambrosioides and their synergism against dermatophytes"", MYCOSES, vol. 53, no. 2, 1 March 2010 (2010-03-01), pages 123-129, XP055077920, ISSN: 0933-7407, DOI: 10.1111/j.1439-0507.2008.01676.x;;PRAMILA TRIPATHI ET AL: ""Use of some essential oils as post-harvest botanical fungicides in the management of grey mould of grapes caused by Botrytis cinerea"", WORLD JOURNAL OF MICROBIOLOGY AND BIOTECHNOLOGY, KLUWER ACADEMIC PUBLISHERS, DO, vol. 24, no. 1, 8 June 2007 (2007-06-08), pages 39-46, XP019582080, ISSN: 1573-0972",INACTIVE
176,EP,B1,EP 2925142 B1,168-922-408-805-309,2018-01-31,2018,EP 13798693 A,2013-12-03,EP 12195202 A;;EP 2013075321 W;;EP 13798693 A,2012-12-03,COMPOSITION COMPRISING A BIOLOGICAL CONTROL AGENT AND AN INSECTICIDE,,BAYER CROPSCIENCE AG,ANDERSCH WOLFRAM;;THIELERT WOLFGANG;;SPRINGER BERND;;LÜTH PETER;;EIBEN UTE,,https://lens.org/168-922-408-805-309,Granted Patent,yes,2,0,22,22,0,A01N43/22;;A01N43/56;;A01N47/22;;A01N47/40;;A01N51/00;;A01N25/00;;A01N63/30;;Y02A50/30;;A01N25/00;;A01N43/22;;A01N43/56;;A01N47/24;;A01N47/40;;A01N51/00;;A01N63/30;;Y02A50/30,A01N25/00;;A01N43/22;;A01N43/56;;A01N47/22;;A01N47/40;;A01N51/00;;A01N63/30;;A01P7/00,,9,0,,,"M. K. R. S. OLIVEIRA ET AL: ""Controle biológico de fitonematóides do gênero Pratylenchus através de inoculante natural em cana-de-açúcar"", REVISTA BRASILEIRA DE CIÊNCIAS AGRÁRIAS - BRAZILIAN JOURNAL OF AGRICULTURAL SCIENCES, vol. 6, no. 2, 7 June 2011 (2011-06-07), pages 203-207, XP055123279, DOI: 10.5039/agraria.v6i2a835;;DATABASE WPI Week 201252 Thomson Scientific, London, GB; AN 2012-E61744 XP002725774, & CN 102 405 939 A (DEQIANG BIO TECHNOLOGY CO LTD) 11 April 2012 (2012-04-11);;DATABASE WPI Week 201250 Thomson Scientific, London, GB; AN 2012-F19228 XP002725775, & CN 102 422 844 A (DEQIANG BIO TECHNOLOGY CO LTD) 25 April 2012 (2012-04-25);;M. A. PATHAN, S. H. SOOMRO, M. M. JISKANI, K. H. WAGAN & J. A. MEMON: ""Effect of Paecilomyces lilacinus and Furadan on plant growth, root nodulation and reproduction of Meloidogyne incognita in tomato."", PAKISTAN J. OF NEMATOLOGY, PAKISTAN SOCIETY OF NEMATOLOGISTS, KARACHI, PK, vol. 23, no. 1, 2005, pages 67-71, XP009178523, ISSN: 0255-7576;;DATABASE BIOSIS [Online] BIOSCIENCES INFORMATION SERVICE, PHILADELPHIA, PA, US; June 2001 (2001-06), SAIKIA M K ET AL: ""Integration of carbofuran with Paecilomyces lilacinus for the control of root-knot nematode Meloidogyne incognita on brinjal"", XP002725776, Database accession no. PREV200100239540 & SAIKIA M K ET AL: ""Integration of carbofuran with Paecilomyces lilacinus for the control of root-knot nematode Meloidogyne incognita on brinjal"", ANNALS OF BIOLOGY (HISSAR), vol. 17, no. 1, June 2001 (2001-06), pages 79-82, ISSN: 0970-0153;;R. V. VYAS, B. A. PATEL, D. J. PATEL & R. S. PATEL: ""Management of root-knot nematodes in chickpea"", PAKISTAN J. OF NEMATOLOGY, PAKISTAN SOCIETY OF NEMATOLOGISTS, KARACHI, PK, vol. 14, no. 2, 1996, pages 117-119, XP009178484, ISSN: 0255-7576;;EHTESHAMUL-HAQUE S ET AL: ""Effect of pesticides on the efficacy of biocontrol agents in the control of root rot and root knot disease complex of okra"", PAKISTAN JOURNAL OF NEMATOLOGY, PAKISTAN SOCIETY OF NEMATOLOGISTS, KARACHI, PK, vol. 13, no. 2, 1 January 1995 (1995-01-01), pages 129-134, XP009178450, ISSN: 0255-7576;;DATABASE BIOSIS [Online] BIOSCIENCES INFORMATION SERVICE, PHILADELPHIA, PA, US; December 2007 (2007-12), SHARMA H K ET AL: ""Management of Meloidogyne incognita with Paecilomyces lilacinus and neem cake on Okra"", XP002725777, Database accession no. PREV200800327136 & SHARMA H K ET AL: ""Management of Meloidogyne incognita with Paecilomyces lilacinus and neem cake on Okra"", PESTICIDE RESEARCH JOURNAL, vol. 19, no. 2, December 2007 (2007-12), pages 166-168, ISSN: 0970-6763;;JACOBS ET AL: ""Interactions between nematophagous fungi and consequences for their potential as biological agents for the control of potato cyst nematodes"", MYCOLOGICAL RESEARCH, ELSEVIER, GB, vol. 107, no. 1, 1 January 2003 (2003-01-01), pages 47-56, XP022443502, ISSN: 0953-7562, DOI: 10.1017/S0953756202007098",ACTIVE
177,EP,B1,EP 2854529 B1,099-949-271-833-120,2018-01-17,2018,EP 13725959 A,2013-05-29,EP 12169936 A;;EP 12197137 A;;EP 2013061036 W;;EP 13725959 A,2012-05-30,COMPOSITIONS COMPRISING A BIOLOGICAL CONTROL AGENT AND AN INSECTICIDE,,BAYER CROPSCIENCE AG,HELLWEGE ELKE;;ANDERSCH WOLFRAM;;STENZEL KLAUS;;SPRINGER BERND,,https://lens.org/099-949-271-833-120,Granted Patent,yes,5,0,28,180,0,A61P3/00;;A01N63/22;;A01N63/23;;A01N41/10;;A01N43/56;;A01N63/28;;C12N1/20;;Y10S435/832;;Y10S435/886;;A01N41/10;;A01N43/56;;A01N63/22;;A61P3/00,A01P7/04;;A01N63/22,,0,0,,,,ACTIVE
178,EP,B1,EP 2559030 B1,118-243-509-114-832,2017-06-21,2017,EP 11757077 A,2011-03-18,US 79750310 A;;US 31547510 P;;US 31821710 P;;US 2011/0029038 W,2010-03-19,INTUITIVE COMPUTING METHODS AND SYSTEMS,,DIGIMARC CORP,RHOADS GEOFFREY B;;RODRIGUEZ TONY F;;SHAW GILBERT B;;DAVIS BRUCE L;;ALLER JOSHUA V;;CONWELL WILLIAM Y,,https://lens.org/118-243-509-114-832,Granted Patent,yes,6,3,12,34,0,G10L15/22;;G06F18/40;;G10L15/24;;G10L21/0208;;G06F18/40;;G10L15/22;;G10L15/24;;G10L21/0208;;H04W88/02;;G10L15/22,G06F3/048;;G06K9/62;;G10L15/22;;G10L15/24;;G10L21/0208,,2,0,,,"JIE YANG ET AL: ""Smart Sight: a tourist assistant system"", WEARABLE COMPUTERS, 1999. DIGEST OF PAPERS. THE THIRD INTERNATIONAL SY MPOSIUM ON SAN FRANCISCO, CA, USA 18-19 OCT. 1999, LOS ALAMITOS, CA, USA,IEEE COMPUT. SOC, US, 18 October 1999 (1999-10-18), pages 73-78, XP032391410, DOI: 10.1109/ISWC.1999.806662 ISBN: 978-0-7695-0428-5;;XING XIE ET AL: ""Mobile Search With Multimodal Queries"", PROCEEDINGS OF THE IEEE, IEEE. NEW YORK, US, vol. 96, no. 4, 1 April 2008 (2008-04-01), pages 589-601, XP011205641, ISSN: 0018-9219",ACTIVE
179,EP,B1,EP 2782449 B1,140-857-213-310-766,2016-08-03,2016,EP 12795228 A,2012-11-16,US 201161562383 P;;US 201161562428 P;;US 2012/0065397 W,2011-11-21,ISOXAZOLINE DERIVATIVES USED IN THE CONTROL OF ECTOPARASITES,,ANACOR PHARMACEUTICALS INC,AKAMA TSUTOMU;;BALKO TERRY WILLIAM;;DEFAUW JEAN MARIE;;PLATTNER JACOB;;WHITE WILLIAM HUNTER;;WINKLE JOSEPH RAYMOND;;ZHANG YONG-KANG;;ZHOU YASHEEN,,https://lens.org/140-857-213-310-766,Granted Patent,yes,2,1,19,19,0,C07F5/02;;A01N55/08;;A01N55/08;;C07F5/04;;A61K31/69;;A61P33/00;;A61P33/06;;A61P33/10;;A61P33/14;;C07F5/025;;C07F5/04;;A01N55/08;;A61K31/69;;A61K45/06;;C07F5/025,A01N55/08;;A61K31/69;;A61P33/14;;C07F5/02,,0,0,,,,ACTIVE
180,EP,B1,EP 2540070 B1,027-149-952-534-698,2016-06-22,2016,EP 11748012 A,2011-02-23,US 71217610 A;;US 2011/0025946 W,2010-02-24,INTUITIVE COMPUTING METHODS AND SYSTEMS,,DIGIMARC CORP,RHOADS GEOFFREY B;;RODRIGUEZ TONY F;;SHAW GILBERT B;;CONWELL WILLIAM Y,,https://lens.org/027-149-952-534-698,Granted Patent,yes,11,0,34,34,0,G01C21/20;;G01C21/36;;G06F3/011;;G06Q10/10;;H04W4/029;;H04W4/027;;H04W4/02;;H04W88/02;;H04W4/029;;H04W4/024;;H04M2250/22;;H04M2250/74;;H04W4/029;;G01C21/20;;G01C21/36;;G06F3/011;;G06Q10/10;;H04M1/724;;H04M1/72403;;G06V20/20;;G06F18/24;;H04N23/00;;H04N23/80;;H04N23/667;;H04W4/02;;G06F3/005;;G09G5/00;;G06F3/023;;G06F3/04817;;G06F3/04842;;G06F3/04847;;G06F3/04886;;G06T19/006;;G06T2200/24;;G06F3/017;;G06F3/0482;;H04W4/027,H04W4/02;;H04M1/724;;H04M1/72403;;H04M11/00,,6,0,,,"Emiliano Miluzzo: ""Sensing Meets Mobile Social Networks: The Design, Implementation and Evaluation of the CenceMe Application"", , 7 November 2008 (2008-11-07), XP055026265, Retrieved from the Internet: URL:http://www.cs.dartmouth.edu/~sensorlab /pubs/cenceme_sensys08.pdf [retrieved on 2012-05-07];;KUBOTA Y ET AL: ""Design and Implementation of 3D Auditory Scene Visualizer towards Auditory Awareness with Face Tracking"", MULTIMEDIA, 2008. ISM 2008. TENTH IEEE INTERNATIONAL SYMPOSIUM ON, IEEE, PISCATAWAY, NJ, USA, 15 December 2008 (2008-12-15), pages 468-476, XP031403574, ISBN: 978-0-7695-3454-1;;Natalia Marmasse ET AL: ""WatchMe: communication and awareness between members of a closely-knit group"", UbiComp 2004: Ubiquitous Computing: 6th International Conference, Nottingham, UK, September 7-10, 2004, Lecture Notes in Computer Science, vol. 3205, 2 November 2004 (2004-11-02), XP055027532, Retrieved from the Internet: URL:http://luci.ics.uci.edu/websiteContent /weAreLuci/biographies/faculty/djp3/LocalC opy/WM_ubi04.pdf [retrieved on 2012-05-18];;KUBOTA ET AL.: 'Design and Implementation of 3D Auditory Scene Visualizer Towards Auditory Awareness With Face Tracking' TENTH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA, [Online] 17 December 2008, pages 468 - 476, XP031403574 Retrieved from the Internet: <URL:http://winnie.kuis.kyoto-u.ac.jp/membe rs/okuno/PubIiGISM08-Kubota.pdf> [retrieved on 2011-04-27];;ANDRO: 'Smartphone Voice Recording Apps (COP RECORDER)' ANDROGEEK, [Online] 29 January 2009, XP003033159 Retrieved from the Internet: <URL:http://androgeek.com/smartphone-voice- recording-apps-cop-recorder.html> [retrieved on 2011-04-27];;'Nine steps that reduce non-stationary mobile phone noise up to 25dB' MICROWAVE ENGINEERING, EUROPE, [Online] 14 April 2008, XP003033160 Retrieved from the Internet: <URL:http://www.mwee.com/en/tips_and_tricks -_nine_steps_that_reduce_non-_stationary_mo bile_phone_noise_up_to_25db?cmp_id=7&news_i d=207401104> [retrieved on 2011-04-27]",ACTIVE
181,EP,B1,EP 2699092 B1,092-584-555-440-19X,2015-10-07,2015,EP 12717192 A,2012-04-18,EP 11356006 A;;US 201161486475 P;;EP 2012001674 W;;EP 12717192 A,2011-04-22,ACTIVE COMPOSITIONS COMPRISING A FUNGICIDAL CARBOXAMIDE DERIVATIVE AND AN INSECTICIDAL OR ACARICIDAL OR NEMATICIDAL ACTIVE COMPOUND,,BAYER IP GMBH,DAHMEN PETER;;DESBORDES PHILIPPE;;DUBOST CHRISTOPHE;;GARY STÉPHANIE;;HELLWEGE ELKE;;HELMKE HENDRIK;;HUNGENBERG HEIKE;;WACHENDORFF-NEUMANN ULRIKE,"BAYER CROPSCIENCE AKTIENGESELLSCHAFT (2019-03-05);;BAYER CROPSCIENCE AKTIENGESELLSCHAFT, MONHEIM, DE (2019-05-27);;BAYER CROPSCIENCE AKTIENGESELLSCHAFT; DE (2019-02-08);;BAYER CROPSCIENCE AKTIENGESELLSCHAFT, DE (2019-04-05)",https://lens.org/092-584-555-440-19X,Granted Patent,yes,3,0,34,36,0,A01N43/56;;A01N37/46;;A01N41/10;;A01N43/22;;A01N43/40;;A01N43/713;;A01N47/02;;A01N47/06;;A01N47/22;;A01N47/24;;A01N47/40;;A01N53/00;;A01N57/16;;A01N43/56;;A01N43/56;;A01N41/10;;A01N43/22;;A01N47/02;;A01N51/00;;A01N53/00;;A01N43/56;;A01N43/40;;A01N43/50;;A01N43/78;;A01N43/88;;A01N57/16,A01P3/00;;A01N41/10;;A01N43/22;;A01N43/40;;A01N43/56;;A01N43/90;;A01N47/02;;A01N47/06;;A01N47/22;;A01N47/24;;A01N47/40;;A01N51/00;;A01N53/00;;A01N57/16;;A01P7/00,,0,0,,,,ACTIVE
182,EP,B1,EP 2117782 B1,188-421-756-284-669,2014-07-30,2014,EP 08700508 A,2008-01-11,CA 2008000041 W;;US 88005907 P,2007-01-12,METHOD AND SYSTEM FOR ROBOT GENERATION,,BALTES HANSJORG;;PETERSON JACK ELMIN;;SCHAERER SHAWN SAMUEL;;LIU XIAO-WEN TERRY;;MCKINNON BRIAN P;;EPP SARA;;KANNE VERGIL;;YANKE SHANE,BALTES HANSJORG;;PETERSON JACK ELMIN;;SCHAERER SHAWN SAMUEL;;LIU XIAO-WEN TERRY;;MCKINNON BRIAN P;;EPP SARA;;KANNE VERGIL;;YANKE SHANE,,https://lens.org/188-421-756-284-669,Granted Patent,yes,3,0,10,10,0,G05D1/0227;;G05D1/0246;;G05D1/0255;;G05D1/0261;;G05D1/0272;;G05D1/0278;;G05D1/0274;;G05D1/0227;;G05D1/0246;;G05D1/0255;;G05D1/0261;;G05D1/0272;;G05D1/0278;;G05D1/0274,B25J9/16;;B25J9/18;;G05D1/02,,4,0,,,"DIXON K ET AL: ""RAVE: a real and virtual environment for multiple mobile robot systems"", 17 October 1999 (1999-10-17), INTELLIGENT ROBOTS AND SYSTEMS, 1999. IROS '99. PROCEEDINGS. 1999 IEEE /RSJ INTERNATIONAL CONFERENCE ON KYONGJU, SOUTH KOREA 17-21 OCT. 1999, PISCATAWAY, NJ, USA,IEEE, US, PAGE(S) 1360 - 1367, XP010362379, ISBN: 978-0-7803-5184-4 * page 1361, paragraph 3.1 - page 1365, paragraph 5 * * figures 1,3,5,7 *;;HORNBY G S ET AL: ""Generative representations for the automated design of modular physical robots"", IEEE TRANSACTIONS ON ROBOTICS AND AUTOMATION, IEEE INC, NEW YORK, US, vol. 19, no. 4, 1 August 2003 (2003-08-01) , pages 703-719, XP011099589, ISSN: 1042-296X, DOI: 10.1109/TRA.2003.814502;;DIXON K. ET AL.: 'RAVE: a real and virtual environment for multiple mobile robot systems' INTELLIGENT ROBOTS AND SYSTEMS, 1999. IROS'99. PROCEEDINGS. 1999 IEEE RSJ INERNATIONAL CONFERENCE vol. 3, 1999, pages 1360 - 1367, XP010362379;;HORNBY G.S., LIPSON H., POLLACK J.B.: 'Generative representations for the automated design of modular physical robots' ROBOTICS AND AUTOMATION, IEEE TRANSACTIONS vol. 19, no. 4, August 2003, pages 703 - 71, XP011099589",ACTIVE
183,EP,A1,EP 2604118 A1,078-952-327-280-592,2013-06-19,2013,EP 11193829 A,2011-12-15,EP 11193829 A,2011-12-15,Active ingredient combinations having insecticidal and acaricidal properties,"Th e novel active ingredient which comprise a compound of the formula (I) in cimbination with further avtive insecticidal ingredients or biological control agents are very suitable for control of animals pests such as insects and / or unwanted acarids and indirectly improve plant helath. The compound of the formula (I) in combination with further active insecticidal ingredients or biological control agents can be used for reducing overall damage of plants and plant parts as well as losses in harvested fruits or vegetables caused by insects, nematodes and phytopathogens.",BAYER CROPSCIENCE AG,The designation of the inventor has not yet been filed,,https://lens.org/078-952-327-280-592,Patent Application,yes,39,26,19,19,0,A01N43/653;;A01N63/22;;A01N63/23;;A01N63/30;;A01N63/32;;Y02A50/30;;A01N43/653;;A01G13/10;;A01N37/34;;A01N43/08;;A01N43/40;;A01N43/50;;A01N43/56;;A01N43/707;;A01N43/78;;A01N43/90;;A01N47/40;;A01N57/16;;A01N43/653;;A01N37/34;;A01N43/08;;A01N43/40;;A01N43/50;;A01N43/56;;A01N43/707;;A01N43/78;;A01N43/90;;A01N47/40;;A01N57/16;;A01N63/22;;A01N63/23;;A01N63/30;;A01N63/32,A01N43/653;;A01N31/08;;A01N43/22;;A01N43/36;;A01N43/54;;A01N43/56;;A01N43/707;;A01N43/88;;A01N43/90;;A01N47/02;;A01N47/24;;A01N47/34;;A01N47/38;;A01N47/40;;A01N51/00;;A01N53/00;;A01N57/12;;A01N57/16;;A01N63/22;;A01N63/23;;A01N63/30;;A01N63/32;;A01P7/00,,6,4,056-357-183-925-763;;039-979-033-140-530;;126-196-060-474-539;;139-238-698-379-172,10.1016/s0261-2194(97)00118-x;;10.1016/j.biocontrol.2008.01.004;;10.1016/j.cropro.2005.08.001;;10.2307/4041058,"""The Pesticide Manual"", 2006, BRITISH CROP PROTECTION COUNCIL;;BIOLOGICAL CONTROL, vol. 45, 2008, pages 288 - 296;;CROP PROTECTION, vol. 25, 2006, pages 468 - 475;;ASH ET AL., LETT APPL MICROBIOLOGY, vol. 13, 1991, pages 202 - 206;;CROP PROTECTION, vol. 27, 2008, pages 352 - 361;;COLBY, S.R.: ""calculating Synergistic and antagonistic Responses of Herbicide Combinations"", WEEDS, vol. 15, 1967, pages 20 - 22, XP001112961",DISCONTINUED
184,EP,A2,EP 2571285 A2,109-237-535-470-374,2013-03-20,2013,EP 12181118 A,2012-08-21,JP 2011203585 A,2011-09-16,"Sound-reproducing apparatus, lighting apparatus, and suspended opening and closing apparatus","A sound-reproducing apparatus includes plural coupling portions, plural rods, plural shell portions, an actuator, and first, second, and third speakers. The coupling portions are disposed at positions corresponding to vertices of an assumed first regular tetrahedron and second regular tetrahedron in a duality relation. The rods connect adjacent coupling portions with each other among the coupling portions. The shell portions are joined to the rods. The actuator is disposed outside one coupling portion selected from the coupling portions with respect to a center of the first regular tetrahedron or second regular tetrahedron, and the actuator is connected with the one coupling portion. The first, second, and third speakers are disposed on, of the four coupling portions disposed at positions corresponding to the vertices of the one of the first and second regular tetrahedra including the one coupling portion, three coupling portions excluding the one coupling portion.",SONY CORP,FUKUMA YOHEI,,https://lens.org/109-237-535-470-374,Patent Application,yes,2,2,5,5,0,H04R1/028;;F21S8/061;;F21V1/12;;F21V33/0056;;F21Y2115/10;;H04R1/026;;H04R1/227;;H04R1/40;;Y10T74/18856;;H04R1/028;;F21S8/061;;F21V1/12;;F21V33/0056;;F21Y2115/10;;H04R1/026;;H04R1/227;;H04R1/40;;Y10T74/18856,H04R1/40;;F21V21/00;;F21V33/00;;H04R1/02;;H04R1/22;;H04R1/28,,0,0,,,,DISCONTINUED
185,EP,A1,EP 2544125 A1,006-991-363-270-375,2013-01-09,2013,EP 11382225 A,2011-07-04,EP 11382225 A,2011-07-04,Methods and systems for non-invasive measurement of blood pressure,"Methods and systems for determining a blood pressure value for a patient in a non-invasive manner are disclosed. A photoplethysmograph (PPG) signal is obtained from a patient's measurement location. Clinical parameters of the patient are also received. Based on measurement parameters extracted from the PPG signal and the clinical parameters, a fixed length vector is generated. The fixed length vector is analyzed using a deep belief network, and an estimated blood pressure reading is output.",SABIRMEDICAL S L,RIBAS RIPOLL VICENTE JORGE;;WOJDEL ANNA,,https://lens.org/006-991-363-270-375,Patent Application,yes,3,5,2,2,0,A61B5/14551;;A61B5/021;;A61B5/7267;;G06F18/217;;G06F18/2411;;G06F18/24323;;G06F2218/08;;G16H50/20;;A61B5/14551;;A61B5/021;;A61B5/7267;;G06F18/217;;G06F18/2411;;G06F18/24323;;G06F2218/08;;G16H50/20,G06K9/00;;A61B5/021;;A61B5/1455;;G06F19/00;;G06F19/24;;G06N3/02,,2,2,025-160-626-603-744;;082-945-313-450-254,10.1016/j.artmed.2011.05.001;;21696930;;10.1162/neco.2006.18.7.1527;;16764513,"ENRIC MONTE-MORENO: ""Non-invasive estimate of blood glucose and blood pressure from a photoplethysmograph by means of machine learning techniques"", ARTIFICIAL INTELLIGENCE IN MEDICINE, vol. 53, no. 2, 22 June 2011 (2011-06-22), pages 127 - 138, XP055013563, ISSN: 0933-3657, DOI: 10.1016/j.artmed.2011.05.001;;GEOFFREY E. HINTON ET AL: ""A Fast Learning Algorithm for Deep Belief Nets"", NEURAL COMPUTATION, vol. 18, no. 7, 1 July 2006 (2006-07-01), pages 1527 - 1554, XP055013559, ISSN: 0899-7667, DOI: 10.1162/neco.2006.18.7.1527",DISCONTINUED
186,EP,A1,EP 2481948 A1,105-375-303-968-35X,2012-08-01,2012,EP 10818757 A,2010-09-17,JP 2009218648 A;;JP 2010066172 W,2009-09-24,SHIFT DEVICE FOR VEHICLE,"Provided is a vehicle transmission apparatus including dual clutch transmission capable of improving travel stability even when running on a rough road. The apparatus comprises input shafts and output shafts to which rotational power from the input shafts is transmitted in a gear-shiftable manner; clutches that disengageably transmit rotational power from engine to the input shafts; rotational sensors that detect number of revolutions of wheels differentially driven through a differential device connected to both the output shafts to be capable of transmitting rotational power; a motor generator that rotates integrally with an input shaft and a controller that controls engagement/disengagement of the clutches, gear shifting between an input shaft and an output shaft and between another input shaft and another output shaft, and a regenerative operation of the motor generator according to signals from the rotational sensors.",AISIN SEIKI;;AISIN AI CO LTD,OMURA MASAHIRO;;TABATA MITSUHIRO;;FUKUHARA YUICHI;;SASAKI KAN;;TANBA TOSHIO,"AISIN SEIKI KABUSHIKI KAISHA (2016-04-13);;AISIN AI CO., LTD. (2016-04-13)",https://lens.org/105-375-303-968-35X,Patent Application,yes,0,4,8,8,0,B60K6/48;;B60K28/16;;B60K2006/4825;;B60L7/18;;B60L50/16;;B60L2220/14;;B60L2240/441;;B60L2240/461;;B60L2270/145;;B60W10/02;;B60W10/08;;B60W10/113;;B60W20/00;;B60W30/18127;;B60W30/18172;;B60W2520/28;;B60Y2400/428;;F16H3/006;;Y02T10/62;;Y02T10/7072;;B60W20/40;;B60W10/02,B60K6/48;;B60K28/16;;B60L7/18;;B60L50/16;;B60W10/02;;B60W10/08;;B60W10/113;;B60W20/00;;B60W30/18;;F16H3/093,,0,0,,,,ACTIVE
187,EP,A2,EP 2360629 A2,033-305-360-930-231,2011-08-24,2011,EP 11002179 A,2006-05-08,EP 06752398 A;;US 67885605 P,2005-05-07,Device for the autonomous bootstrapping of useful information,"A discovery system employing a neural network, training within this system, that is stimulated to generate novel output patterns through various forms of perturbation applied to it, a critic neural network likewise capable of training in situ within this system, that learns to associate such novel patterns with their utility or value while triggering reinforcement learning of the more useful or valuable of these patterns within the former net. The device is capable of bootstrapping itself to progressively higher levels of adaptive or creative competence, starting from no learning whatsoever, through cumulative cycles of experimentation and learning. Optional feedback mechanisms between the latter and former self-learning artificial neural networks are used to accelerate the convergence of this system toward useful concepts or plans of action.",THALER STEPHEN L,THALER STEPHEN L,,https://lens.org/033-305-360-930-231,Patent Application,yes,9,1,10,10,0,G06N3/08;;G06N3/045;;G06V10/774;;G06N3/08;;G06F18/214;;G06N3/045;;G06V10/774,G06N3/04;;G06N3/08;;G06V10/774,,0,0,,,,DISCONTINUED
188,EP,A2,EP 2172887 A2,181-919-389-292-459,2010-04-07,2010,EP 09171632 A,2009-09-29,US 24252508 A;;US 24252908 A;;US 24254408 A;;US 24254608 A;;US 24255208 A,2008-09-30,"System and method for dynamic multi-objective optimization of machine selection, integration and utilization","The invention provides control systems and methodologies for controlling a process having computer-controlled equipment, which provide for optimized process performance according to one or more performance criteria, such as efficiency, component life expectancy, safety, emissions, noise, vibration, operational cost, or the like. More particularly, the subject invention provides for employing machine diagnostic and/or prognostic information in connection with optimizing an overall business operation over a time horizon.",ROCKWELL AUTOMATION TECH INC,SUSTAETA ANGEL;;LIN KA-HING;;SNYDER RIC;;THERON JOHN CHRISTOPHER;;FUNDERBURK MARK;;SUGARS MICHAEL EUGENE;;DISCENZO FREDERICK M;;BAIER JOHN J,,https://lens.org/181-919-389-292-459,Patent Application,yes,4,39,3,26,0,G06Q10/04;;G05B23/0283,G06Q10/00,,0,0,,,,DISCONTINUED
189,EP,B1,EP 1657607 B1,196-203-015-289-520,2009-05-13,2009,EP 06002177 A,1995-11-09,EP 02002809 A;;EP 95936762 A;;US 33811394 A;;US 38636995 A,1994-11-09,Bending apparatus comprising a control means,,AMADA CO LTD;;AMADA LTD US,BOURNE DAVID ALAN;;WILLIAMS DUANE THOMAS;;KIM KYOUNG HUNG;;KRISHNAN SIVARAJ SIVARAMA;;HAZAMA KENSUKE,,https://lens.org/196-203-015-289-520,Granted Patent,yes,1,0,16,33,0,B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02;;B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02,B21D5/01;;G05B19/4097;;B21D5/02;;B25J9/16;;G05B19/4069;;G05B19/418;;G06F17/50,,1,0,,,"WEULE H ET AL: ""RECHNERINTEGRIERTE FERTIGUNG VON ABKANTTEILEN"" VDI Z, VDI VERLAG GMBH. DUSSELDORF, DE, vol. 130, no. 9, 1 September 1988 (1988-09-01), pages 101-106, XP000027002 ISSN: 0042-1766",EXPIRED
190,EP,B1,EP 1684140 B1,029-875-499-732-782,2009-04-29,2009,EP 06009075 A,1995-11-09,EP 02002809 A;;EP 95936762 A;;US 33811394 A;;US 38636995 A,1994-11-09,Bending apparatus comprising a control means and corresponding method,,AMADA CO LTD;;AMADA LTD US,BOURNE DAVID ALAN;;WILLIAMS DUANE THOMAS;;KIM KYOUNG HUNG;;KRISHNAN SIVARAJ SIVARAMA;;HAZAMA KENSUKE,,https://lens.org/029-875-499-732-782,Granted Patent,yes,1,0,16,33,0,B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02;;B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02,B21D5/01;;G05B19/4097;;B21D5/00;;B21D5/02;;B25J9/16;;G05B19/4069;;G05B19/418;;G06F17/50,,2,0,,,"REISSNER J: ""INNOVATIONSSCHUB BEI RECHNERINTEGRIERTEN UMFORMSYSTEMEN"" TECHNISCHE RUNDSCHAU, HALLWAG VERLAG. BERN, CH, vol. 85, no. 5, 5 February 1993 (1993-02-05), pages 20-25, XP000342593 ISSN: 1023-0823;;WEULE H ET AL: ""RECHNERINTEGRIERTE FERTIGUNG VON ABKANTTEILEN"" VDI Z, SPRINGER VDI VERLAG, DUSSELDORF, DE, vol. 130, no. 9, 1 September 1988 (1988-09-01), pages 101-106, XP000027002 ISSN: 0042-1766",EXPIRED
191,EP,B1,EP 1681607 B1,118-722-432-699-788,2008-01-09,2008,EP 06009079 A,1995-11-09,EP 02002809 A;;EP 95936762 A;;US 33811394 A;;US 38636995 A,1994-11-09,Bending apparatus comprising means for performing setup operations,,AMADA CO LTD;;AMADA LTD US,BOURNE DAVID ALAN;;WILLIAMS DUANE THOMAS;;KIM KYOUNG HUNG;;KRISHNAN SIVARAJ SIVARAMA;;HAZAMA KENSUKE,,https://lens.org/118-722-432-699-788,Granted Patent,yes,2,0,16,33,0,B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02;;B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02,B21D5/01;;G05B19/4097;;B21D5/02;;B25J9/16;;G05B19/4069;;G05B19/418;;G06F17/50,,1,0,,,"DATABASE DIALOG Information Access Co. 0134529; File 621: IAC New Product Announcements, 07/1986 COMMUNIGRAPHICS INC.: ""LVD INTRODUCES NEW CNC/DNC/CAD/CAM CONTROL SYSTEM FOR PRESS BRAKES AT IMTS '86"" XP002010528",EXPIRED
192,EP,B1,EP 0719432 B1,020-063-598-368-110,2007-05-23,2007,EP 94912345 A,1994-03-21,US 9403445 W;;US 3994993 A,1993-03-29,METHOD AND APPARATUS FOR CONFIGURING SYSTEMS,,TRILOGY DEV GROUP,LYNCH JOHN;;FRANKE DAVID,"VERSATA DEVELOPMENT GROUP, INC., US (2013-02-04)",https://lens.org/020-063-598-368-110,Granted Patent,yes,4,2,17,20,0,G06F30/00;;G06F2111/04;;G06F13/00;;G06F30/00;;G06F2111/04,G06F13/00;;G06F15/177;;G06F17/50,,1,0,,,"COMPUTERS IN INDUSTRY, vol. 19, no. 3, June 1992 AMSTERDAM NL, pages 257-270, CHUNG ET AL 'ILLUSTRATION OF OBJECT-ORIENTED DATABASES FOR THE STRUCTURE OF A BILL OF MATERIALS'",EXPIRED
193,EP,A2,EP 1684140 A2,023-871-545-247-889,2006-07-26,2006,EP 06009075 A,1995-11-09,EP 02002809 A;;EP 95936762 A;;US 33811394 A;;US 38636995 A,1994-11-09,Bending apparatus comprising a control means and corresponding method,"The present invention refers to a bending apparatus comprising a control means being configured for selecting a workpiece holding gripper, wherein means for reading information from a geometry-determined library are used, undesired grippers are excluded and a gripper is selected to be used in response of its geometrical data.",AMADA CO LTD;;AMADA LTD US,BOURNE DAVID ALAN;;WILLIAMS DUANE THOMAS;;KIM KYOUNG HUNG;;KRISHNAN SIVARAJ SIVARAMA;;HAZAMA KENSUKE,,https://lens.org/023-871-545-247-889,Patent Application,yes,0,0,16,33,0,B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02;;B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02,B21D5/01;;G05B19/4097;;B21D5/00;;B21D5/02;;B25J9/16;;G05B19/4069;;G05B19/418;;G06F17/50,,0,0,,,,EXPIRED
194,EP,A2,EP 1681607 A2,188-961-689-481-706,2006-07-19,2006,EP 06009079 A,1995-11-09,EP 02002809 A;;EP 95936762 A;;US 33811394 A;;US 38636995 A,1994-11-09,Bending apparatus comprising means for performing setup operations,"The present invention relates to a bending apparatus comprising a means for performing setup operations, wherein a tooling stage (1,2,3) position detecting mechanism is provided and a means for receiving said information and a control means (75) for controlling the position of a guide member along at least one of a die rail (22) and a tool punch holding mechanism (20) to position a resulting tooling stage (1,2,3) at a desired location.",AMADA CO LTD;;AMADA LTD US,BOURNE DAVID ALAN;;WILLIAMS DUANE THOMAS;;KIM KYOUNG HUNG;;KRISHNAN SIVARAJ SIVARAMA;;HAZAMA KENSUKE,,https://lens.org/188-961-689-481-706,Patent Application,yes,0,2,16,33,0,B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02;;B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02,B21D5/01;;G05B19/4097;;B21D5/02;;B25J9/16;;G05B19/4069;;G05B19/418;;G06F17/50,,0,0,,,,EXPIRED
195,EP,A2,EP 1657607 A2,176-285-390-421-155,2006-05-17,2006,EP 06002177 A,1995-11-09,EP 02002809 A;;EP 95936762 A;;US 33811394 A;;US 38636995 A,1994-11-09,Bending apparatus comprising a control means,"In order to present a computerized system for generating and executing a sheet metal bend plan, that allows evaluation of a bending operation more effectively, a system for generating a plan is disclosed, which comprises a system for generating a plan which comprises a sequence of operations to be performed by a bending apparatus for bending workpieces comprising sheets of malleable material, the bending apparatus having a gripper for gripping a workpiece while performing a bend, said sequence of operations comprising a set of N bends for forming a finished workpiece from a stock sheet of malleable material, said system comprising: proposing means for proposing, for an mth operation within the sequence of operations, a plurality of proposed operations including a plurality of proposed bends to be performed by said apparatus; subplan means for providing a proposed subplan that accompanies each proposed bend; and generating means for generating a plan including a sequence of bends from a first bend through an Nth bend, by choosing each bend in the sequence of operations based upon the proposed bends and the proposed subplan that accompanies each proposed bend, wherein the system further comprises estimating means for estimating a cost to be associated with each proposed bend. Moreover, a respective computer is disclosed..",AMADA CO LTD;;AMADA LTD US,BOURNE DAVID ALAN;;WILLIAMS DUANE THOMAS;;KIM KYOUNG HUNG;;KRISHNAN SIVARAJ SIVARAMA;;HAZAMA KENSUKE,,https://lens.org/176-285-390-421-155,Patent Application,yes,0,3,16,33,0,B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02;;B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02,B21D5/01;;G05B19/4097;;B21D5/02;;B25J9/16;;G05B19/4069;;G05B19/418;;G06F17/50,,0,0,,,,EXPIRED
196,EP,A2,EP 1657693 A2,188-089-240-206-916,2006-05-17,2006,EP 05109793 A,2005-10-20,US 62826704 P;;US 17179105 A,2004-11-16,Traffic forecasting employing modeling and analysis of probabilistic interdependencies and contextual data,"Systems and methods are described for constructing predictive models, based on statistical machine learning, that can make forecasts about traffic flows and congestions, based on an abstraction of a traffic system into a set of random variables, including variables that represent the amount of time until there will be congestion at key troublespots and the time until congestions will resolve. Observational data includes traffic flows and dynamics, and other contextual data such as the time of day and day of week, holidays, school status, the timing and nature of major gatherings such as sporting events, weather reports, traffic incident reports, and construction and closure reports. The forecasting methods are used in alerting, the display graphical information about predictions about congestion on desktop on mobile devices, and in offline and real-time automated route recommendations and planning.",MICROSOFT CORP,HORVITZ ERIC J;;APACIBLE JOHNSON T;;SARIN RAMAN K,,https://lens.org/188-089-240-206-916,Patent Application,yes,0,21,6,20,0,G08G1/0104;;G08G1/0104;;G06Q50/40;;G08G1/0104,G08G1/01,,0,0,,,,DISCONTINUED
197,EP,B1,EP 1253496 B1,092-010-335-072-740,2006-05-03,2006,EP 02002809 A,1995-11-09,EP 95936762 A;;US 33811394 A;;US 38636995 A,1994-11-09,Bending apparatus comprising a control means being configured to generate and execute a sheetmetal bending plan,,AMADA CO LTD;;AMADA LTD US,BOURNE DAVID ALAN;;WILLIAMS DUANE THOMAS;;KIM KYOUNG HUNG;;KRISHNAN SIVARAJ SIVARAMA;;HAZAMA KENSUKE,,https://lens.org/092-010-335-072-740,Granted Patent,yes,6,0,16,33,0,B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02;;B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02,B21D5/01;;G05B19/4097;;B21D5/02;;B25J9/16;;G05B19/4069;;G05B19/418;;G06F17/50,,4,0,,,"WEULE H ET AL: ""RECHNERINTEGRIERTE FERTIGUNG VON ABKANTTEILEN"" VDI Z, VDI VERLAG GMBH. DUSSELDORF, DE, vol. 130, no. 9, 1 September 1988 (1988-09-01), pages 101-106, XP000027002 ISSN: 0042-1766;;REISSNER J: ""INNOVATIONSSCHUB BEI RECHNERINTEGRIERTEN UMFORMSYSTEMEN"" TECHNISCHE RUNDSCHAU, HALLWAG VERLAG. BERN, CH, vol. 85, no. 5, 5 February 1993 (1993-02-05), pages 20-25, XP000342593 ISSN: 1023-0823;;DATABASE DIALOG [Online] Information Access Co. 0134529; File 621: IAC New Product Announcements, 07/1986, COMMUNIGRAPHICS INC.: ""LVD INTRODUCES NEW CNC/DNC/CAD/CAM CONTROL SYSTEM FOR PRESS BRAKES AT IMTS '86"" XP002010528;;GEIGER M ET AL: ""INFERENZMASCHINE FUER EIN BIEGESTADIENPLANUNGSSYSTEM"" ZWF ZEITSCHRIFT FUR WIRTSCHAFTLICHE FERTIGUNG, CARL HANSER VERLAG. MUNCHEN, DE, vol. 87, no. 5, 1 May 1992 (1992-05-01), pages 261-264, XP000271922",EXPIRED
198,EP,A2,EP 1630723 A2,190-329-686-406-05X,2006-03-01,2006,EP 05107713 A,2005-08-23,US 92745204 A,2004-08-26,Spatial recognition and grouping of text and graphics,"The present invention leverages spatial relationships to provide a systematic means to recognize text and / or graphics. This allows augmentation ofa sketched shape with its symbolic meaning, enabling numerous features including smart editing, beautification, and interactive simulation of visual languages. The spatial recognition method obtains a search-based optimization over a large space of possible groupings from simultaneously grouped and recognized sketched shapes. The optimization utilizes a classifier that assigns a class label to a collection of strokes. The overall grouping optimization assumes the properties of the classifier so that if the classifier is scale and rotation invariant the optimization will be as well. Instances of the present invention employ a variant of AdaBoost to facilitate in recognizing/classifying symbols. Instances of the present invention employ dynamic programming and / or A-star search to perform optimization. The present invention applies to both hand-sketched shapes and printed handwritten text, and even heterogeneous mixtures of the two.",MICROSOFT CORP,CHELLAPILLA KUMAR H;;SHILMAN MICHAEL;;VIOLA PAUL A,"MICROSOFT TECHNOLOGY LICENSING, LLC (2015-03-18)",https://lens.org/190-329-686-406-05X,Patent Application,yes,0,4,6,6,0,G06V30/153;;G06V30/10;;G06V30/18029;;G06V30/274;;G06V30/32;;G06V30/153;;G06V30/10;;G06V30/18029;;G06V30/274;;G06V30/32,G06V30/10;;G06V30/32,,4,3,106-811-543-128-995;;026-703-087-514-375;;064-666-145-719-474,10.1109/icassp.1997.595518;;10.1109/icdar.1999.791895;;10.1007/pl00013549,"WINKLER, H. J. ET AL.: ""Online symbol segmentation and recognition in handwritten mathematical expressions"", ACOUSTICS, SPEECH AND SIGNAL PROCESSING, 1997, ICASSP-97, 1997 IEEE INTERNATIONAL CONFERENCE IN MUNICH, GERMANY, vol. 4, 21 April 1997 (1997-04-21), pages 3377 - 3380;;CHEONG, C. E. ET AL.: ""Handwritten numeral string recognition with stroke grouping"", ICDAR '99, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE IN BANGALORE, INDIA, 20 September 1999 (1999-09-20), pages 745 - 748;;MILLER, E. G. ET AL.: ""Proceedings Fifteenth National Conference on Artificial Intelligence (AAAI-98"", 1998, AAAI PRESS/MIT PRESS, article ""Ambiguity and constraint in mathematical expression recognition"", pages: 784 - 791;;CHAN, K. ET AL.: ""Mathematical expression recognition: a survey"", INTERNATIONAL JOURNAL ON DOCUMENT ANALYSIS AND RECOGNITION, vol. 3, no. 1, August 2000 (2000-08-01), pages 3 - 15",DISCONTINUED
199,EP,A2,EP 1615160 A2,191-307-724-933-248,2006-01-11,2006,EP 05254130 A,2005-06-30,KR 20040052643 A;;US 98334604 A,2004-07-07,Apparatus for and method of feature extraction for image recognition,"An apparatus for and method of performing a most informative feature extraction (MIFE) method in which a facial image is separated into sub-regions, and each sub-region makes individual contribution for performing facial recognition. Specifically, each sub-region is subjected to a sub-region based adaptive gamma (SadaGamma) correction or sub-region based histogram equalization (SHE) in order to account for different illuminations and expressions. A set of reference images is also divided into sub-regions and subjected to the SadaGamma correction or SHE. A comparison is made between the each corrected sub-region and each corresponding sub-region of the reference images. Based upon the comparisons made individually for the sub-regions of the facial image, one of the stored reference images having the greatest correspondence is chosen. While usable individually, using the MIFE and/or SadaGamma correction or SHE together achieves a lower error ratio in face recognition under different expressions, illuminations and occlusions.",SAMSUNG ELECTRONICS CO LTD,KEE SEOKCHEOL;;REN HAIBING;;ZHAO JIALI;;WANG DEJUN,"SAMSUNG ELECTRONICS CO., LTD. (2012-09-26)",https://lens.org/191-307-724-933-248,Patent Application,yes,0,5,2,8,0,G06V40/168;;G06V10/50;;G06V10/751;;G06V40/168;;G06V10/50;;G06V10/751,G06V10/50,,8,8,019-183-007-691-217;;030-420-854-855-803;;107-232-423-198-104;;046-304-946-983-717;;041-699-998-254-900;;106-274-504-173-442;;024-996-574-146-361;;029-429-938-775-048,10.1109/cvpr.1991.139758;;10.1109/34.598228;;10.1109/iccv.2003.1238370;;11125149;;10.1126/science.290.5500.2319;;10.1109/afgr.2004.1301569;;10.1109/ijcnn.2003.1223739;;10.1016/j.patrec.2004.05.005;;10.1016/s0004-3702(02)00366-1,"M. TURK; PENTLAND, FACE RECOGNITION USING EIGENFACES (IEEE 1991);;P.N. BELHUMEUR; J.P. HESPANDA; D. J. KRIEGMAN: ""Eigenfaces vs. Fisherfaces: Recognition Using Class Specific Projection"", IEEE TRANS PAMI, vol. 19, no. 7, 1997, pages 711 - 720;;XIAOFEI HE; SHUICHENG YAN; YUXIAO HU; HONG-JIANG ZHANG: ""Learning a Locality Preserving Subspace for Visual Recognition"", PROCEEDINGS OF THE NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, 2003, pages 385 - 392;;JOSHUA B TENENBAUM; VIN DE SILVA; JOHN C. LANGFORD: ""A Global Geometric Framework for Nonlinear Dimensional Reduction"", SCIENCE, vol. 290, 22 December 2000 (2000-12-22);;IVANOV Y ET AL: ""Using component features for face recognition"", AUTOMATIC FACE AND GESTURE RECOGNITION, 2004. PROCEEDINGS. SIXTH IEEE INTERNATIONAL CONFERENCE ON, IEEE, PISCATAWAY, NJ, USA, 17 May 2004 (2004-05-17), pages 421 - 426, XP010949469, ISBN: 978-0-7695-2122-0;;ARTIKLAR M ET AL: ""Local voting networks for human face recognition"", IJCNN 2003. PROCEEDINGS OF THE INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS 2003. PORTLAND, OR, JULY 20 - 24, 2003; [INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS], NEW YORK, NY : IEEE, US, vol. 3, 20 July 2003 (2003-07-20), pages 2140 - 2145, XP010652436, ISBN: 978-0-7803-7898-8, DOI: 10.1109/IJCNN.2003.1223739;;TOYGAR O ET AL: ""Multiple classifier implementation of a divide-and-conquer approach using appearance-based statistical methods for face recognition"", PATTERN RECOGNITION LETTERS, ELSEVIER, AMSTERDAM, NL, vol. 25, no. 12, 1 September 2004 (2004-09-01), pages 1421 - 1430, XP004527233, ISSN: 0167-8655, DOI: 10.1016/J.PATREC.2004.05.005;;LIANG CHEN ET AL: ""Robustness of regional matching scheme over global matching scheme"", ARTIFICIAL INTELLIGENCE, vol. 144, no. 1-2, 1 March 2003 (2003-03-01), pages 213 - 232, XP055043692, ISSN: 0004-3702, DOI: 10.1016/S0004-3702(02)00366-1",DISCONTINUED
200,EP,B1,EP 0744046 B1,085-915-811-348-182,2003-02-12,2003,EP 95936762 A,1995-11-09,JP 9502291 W;;US 33811394 A;;US 38636995 A,1994-11-09,INTELLIGENT SYSTEM FOR GENERATING AND EXECUTING A SHEET METAL BENDING PLAN,,AMADA CO LTD;;AMADA LTD US,BOURNE DAVID ALAN;;WILLIAMS DUANE THOMAS;;KIM KYOUNG HUNG;;KRISHNAN SIVARAJ SIVARAMA;;HAZAMA KENSUKE,,https://lens.org/085-915-811-348-182,Granted Patent,yes,5,1,17,33,0,B21D5/02;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/35189;;G05B2219/39105;;G05B2219/39467;;G05B2219/45143;;Y02P90/02;;Y02P90/80;;B21D5/02;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/35189;;G05B2219/39105;;G05B2219/39467;;G05B2219/45143;;Y02P90/02,B21D5/01;;B21D5/02;;G05B19/4069;;G05B19/4097;;G05B19/418;;G06F17/50,,4,0,,,"VDI Z, vol. 130, no. 9, September 1988, pages 101-106, XP000027002 WEULE H ET AL: ""RECHNERINTEGRIERTE FERTIGUNG VON ABKANTTEILEN"";;TECHNISCHE RUNDSCHAU, vol. 85, no. 5, 5 February 1993, pages 20-25, XP000342593 REISSNER J: ""INNOVATIONSSCHUB BEI RECHNERINTEGRIERTEN UMFORMSYSTEMEN"";;GEIGER M ET AL: ""INFERENZMASCHINE FUER EIN BIEGESTADIENPLANUNGSSYSTEM"" 1 May 1992 , ZWF ZEITSCHRIFT FUR WIRTSCHAFTLICHE FERTIGUNG UND AUTOMATISIERUNG, VOL. 87, NR. 5, PAGE(S) 261 - 264 XP000271922 see page 261, right-hand column Section ""Verarbeitung der Bewertungskriterien nach graphentheoretischen Grundlagen"";;DATABASE DIALOG Information Access Co File 621, Access No. 0134529, COMMUNIGRAPHICS INC: ""LVD Introduces new CNC/DNC/CAD/CAM control system for press brakes at IMTS '86"" XP002010528 & NEW PRODUCT ANNOUCEMENTS, no. 0134529, July 1986, PLAINVILLE, CT, USA, COMMUNIGRAPHICS INC: ""LVD intorduces new CNC/DNC/CAD/CAM control system for press brakes at IMTS '86 """,EXPIRED
201,EP,A1,EP 1253496 A1,065-472-479-859-195,2002-10-30,2002,EP 02002809 A,1995-11-09,EP 95936762 A;;US 33811394 A;;US 38636995 A,1994-11-09,Bending apparatus comprising a control means being configured to generate and execute a sheetmetal bending plan,"In order to present a system for generating a plan, that allows evaluation of a bending operation more effectively, a system for generating a plan is disclosed, which comprises a system for generating a plan which comprises a sequence of operations to be performed by a bending apparatus for bending workpieces comprising sheets of malleable material, the bending apparatus having a gripper for gripping a workpiece while performing a bend, said sequence of operations comprising a set of N bends for forming a finished workpiece from a stock sheet of malleable material, said system comprising: proposing means for proposing, for an mth operation within the sequence of operations, a plurality of proposed operations including a plurality of proposed bends to be performed by said apparatus; subplan means for providing a proposed subplan that accompanies each proposed bend; and generating means for generating a plan including a sequence of bends from a first bend through an Nth bend, by choosing each bend in the sequence of operations based upon the proposed bends and the proposed subplan that accompanies each proposed bend, wherein the system further comprises estimating means for estimating a cost to be associated with each proposed bend. <IMAGE>",AMADA CO LTD;;AMADA LTD US,BOURNE DAVID ALAN;;WILLIAMS DUANE THOMAS;;KIM KYOUNG HUNG;;KRISHNAN SIVARAJ SIVARAMA;;HAZAMA KENSUKE,,https://lens.org/065-472-479-859-195,Patent Application,yes,6,1,16,33,0,B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02;;B21D37/145;;B21D5/02;;B25J9/1666;;G05B19/4069;;G05B19/4097;;G05B19/41825;;G05B2219/31352;;G05B2219/33002;;G05B2219/35189;;G05B2219/35192;;G05B2219/36268;;G05B2219/36304;;G05B2219/39105;;G05B2219/39467;;G05B2219/40054;;G05B2219/40501;;G05B2219/45143;;G05B2219/49068;;Y02P90/02,B21D5/01;;B21D5/02;;B25J9/16;;G05B19/4069;;G05B19/4097;;G05B19/418;;G06F17/50,,4,0,,,"WEULE H ET AL: ""RECHNERINTEGRIERTE FERTIGUNG VON ABKANTTEILEN"", VDI Z, VDI VERLAG GMBH. DUSSELDORF, DE, vol. 130, no. 9, 1 September 1988 (1988-09-01), pages 101 - 106, XP000027002, ISSN: 0042-1766;;REISSNER J: ""INNOVATIONSSCHUB BEI RECHNERINTEGRIERTEN UMFORMSYSTEMEN"", TECHNISCHE RUNDSCHAU, HALLWAG VERLAG. BERN, CH, vol. 85, no. 5, 5 February 1993 (1993-02-05), pages 20 - 25, XP000342593, ISSN: 1023-0823;;DATABASE DIALOG Information Access Co. 0134529; COMMUNIGRAPHICS INC.: ""LVD INTRODUCES NEW CNC/DNC/CAD/CAM CONTROL SYSTEM FOR PRESS BRAKES AT IMTS '86"", XP002010528;;GEIGER M ET AL: ""INFERENZMASCHINE FUER EIN BIEGESTADIENPLANUNGSSYSTEM"", ZWF ZEITSCHRIFT FUR WIRTSCHAFTLICHE FERTIGUNG, CARL HANSER VERLAG. MUNCHEN, DE, vol. 87, no. 5, 1 May 1992 (1992-05-01), pages 261 - 264, XP000271922",EXPIRED
202,EP,B1,EP 0519049 B1,181-830-719-478-977,1998-03-18,1998,EP 92903412 A,1991-12-30,US 63640090 A;;US 9109761 W,1990-12-31,MACHINE TRANSLATION AND TELECOMMUNICATIONS SYSTEM,,TRANS LINK INT CORP,CHONG LEIGHTON K;;KAMPRATH CHRISTINE K,,https://lens.org/181-830-719-478-977,Granted Patent,yes,13,0,11,13,0,G06F40/151;;G06F40/268;;G06F40/284;;G06F40/55;;G06F40/58;;Y10S379/905;;G06F40/55;;G06F40/151;;G06F40/268;;G06F40/284;;G06F40/58;;Y10S379/905,G06F17/22;;G06F17/27;;G06F17/28;;H04L29/10,,9,0,,,"PATENT ABSTRACTS OF JAPAN, Vol. 14, No. 489, 10 August 1990; & JP,A,02 202 143 (HASHIMOTO);;PATENT ABSTRACTS OF JAPAN, Vol. 11, No. 319, 18 May 1987; & JP,A,62 107 376 (IKEGAMI);;PATENT ABSTRACTS OF JAPAN, Vol. 12, No. 62, 11 September 1987; & JP,A,62 203 273 (MIIKE et al.);;PATENT ABSTRACTS OF JAPAN, NEC (DRP), Vol. 12, No. 100, 12 October 1987; & JP,A,62 23 2 087;;PATENT ABSTRACTS OF JAPAN, Vol. 12, No. 187, 18 December 1987; & JP,A,62 291 25 0 (KENBO et al.);;PATENT ABSTRACTS OF JAPAN, Vol. 12, No. 238, 08 February 1988; & JP,A,63 029 88 1 (KOBE et al.);;PATENT ABSTRACTS OF JAPAN, Vol. 14, No. 249, 05 March 1990; & JP,A,02 064 767;;Analyzing Language in Restricted Domains, 1986, Associated Pub., Hillsdale, NJ, ERLBAUM et al., preface pages x-xvii.;;PATENT ABSTRACTS OF JAPAN, Vol. 11, No. 284, 16 April 1987; & JP,A,62 082853 (HATAKEYAMA)",EXPIRED
